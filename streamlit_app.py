"""
Aplica√ß√£o Streamlit para Consulta e An√°lise de Dados SPAECE

Esta aplica√ß√£o permite consultar dados da API SPAECE (Sistema Permanente de Avalia√ß√£o da Educa√ß√£o B√°sica do Cear√°)
e realizar an√°lises visuais dos dados de profici√™ncia, participa√ß√£o, desempenho e habilidades dos estudantes.

Funcionalidades principais:
- Consulta de dados por c√≥digo de agregado
- An√°lise de taxa de participa√ß√£o
- Visualiza√ß√£o de profici√™ncia m√©dia
- Distribui√ß√£o por padr√£o de desempenho
- An√°lise de habilidades espec√≠ficas
- Dados contextuais por etnia, NSE e sexo
- Exporta√ß√£o de dados em CSV e JSON

Autor: Sistema SPAECE
Data: 2024
"""

import streamlit as st
import requests
import pandas as pd
import json
import base64
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime

# Paleta de cores personalizada
PALETA_CORES = [
    "#26a737",  # Verde m√©dio vibrante
    "#f59c00",  # Laranja forte / dourado
    "#e94f0e",  # Laranja avermelhado intenso
    "#5db12f",  # Verde claro natural
    "#46ac33",  # Verde m√©dio
    "#45b16e",  # Verde esmeralda suave
    "#e06a0c",  # Laranja queimado
    "#e4a500",  # Amarelo-ouro escuro
    "#2db39e",  # Verde √°gua / turquesa
    "#fccf05"   # Amarelo vibrante
]

# Cores principais do sistema
COR_PRIMARIA = PALETA_CORES[0]  # Verde m√©dio vibrante
COR_SECUNDARIA = PALETA_CORES[1]  # Laranja forte / dourado
COR_ACENTO = PALETA_CORES[2]  # Laranja avermelhado intenso
COR_SUCESSO = PALETA_CORES[3]  # Verde claro natural
COR_AVISO = PALETA_CORES[4]  # Verde m√©dio
COR_INFO = PALETA_CORES[5]  # Verde esmeralda suave
COR_DANGER = PALETA_CORES[6]  # Laranja queimado
COR_WARNING = PALETA_CORES[7]  # Amarelo-ouro escuro
COR_LIGHT = PALETA_CORES[8]  # Verde √°gua / turquesa
COR_BRIGHT = PALETA_CORES[9]  # Amarelo vibrante

import io
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from config_api import API_URL, INDICADORES, HEADERS, criar_payload

# ==================== FUN√á√ÉO DE PROCESSAMENTO DE MARKDOWN COM RAG ====================

def extrair_texto_md(caminho_arquivo):
    """
    Extrai texto de um arquivo Markdown (.md)
    """
    try:
        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo:
            texto_completo = arquivo.read()
        return texto_completo
    except Exception as e:
        st.error(f"Erro ao processar arquivo Markdown {caminho_arquivo}: {e}")
        return None

def processar_md_com_rag(texto_md):
    """
    Processa o arquivo Markdown usando t√©cnicas de RAG para extrair informa√ß√µes relevantes
    """
    try:
        # Dividir o texto em chunks menores para melhor processamento
        chunks = dividir_em_chunks(texto_md, tamanho_chunk=1000, sobreposicao=200)
        
        # Extrair tabelas do final do arquivo
        tabelas = extrair_tabelas_do_md(texto_md)
        
        # Extrair se√ß√µes importantes
        secoes_importantes = extrair_secoes_importantes(texto_md)
        
        # Criar √≠ndice de similaridade
        indice_similaridade = criar_indice_similaridade(chunks)
        
        return {
            'chunks': chunks,
            'tabelas': tabelas,
            'secoes_importantes': secoes_importantes,
            'indice_similaridade': indice_similaridade,
            'texto_completo': texto_md
        }
    except Exception as e:
        st.error(f"Erro ao processar arquivo Markdown: {e}")
        return None

def dividir_em_chunks(texto, tamanho_chunk=1000, sobreposicao=200):
    """
    Divide o texto em chunks menores para processamento RAG
    """
    palavras = texto.split()
    chunks = []
    
    for i in range(0, len(palavras), tamanho_chunk - sobreposicao):
        chunk = ' '.join(palavras[i:i + tamanho_chunk])
        if chunk.strip():
            chunks.append({
                'texto': chunk,
                'indice': len(chunks),
                'posicao_inicial': i
            })
    
    return chunks

def extrair_tabelas_do_md(texto_md):
    """
    Extrai tabelas do arquivo Markdown usando regex
    """
    try:
        # Procurar por padr√µes de tabelas no arquivo Markdown
        # Padr√£o para encontrar tabelas com dados num√©ricos
        padrao_tabela = r'(\d+(?:\.\d+)?(?:\s+\d+(?:\.\d+)?)*)'
        
        # Dividir o texto em se√ß√µes para encontrar tabelas
        secoes = texto_md.split('\n---')
        ultimas_secoes = secoes[-5:] if len(secoes) > 5 else secoes
        
        tabelas_encontradas = []
        
        for secao in ultimas_secoes:
            # Procurar por padr√µes de tabela
            matches = re.findall(padrao_tabela, secao)
            if matches:
                # Criar conte√∫do da tabela com os dados encontrados
                conteudo_tabela = f"Dados num√©ricos encontrados: {', '.join(matches[:10])}"
                tabelas_encontradas.append({
                    'conteudo': conteudo_tabela,
                    'secao': secao[:200] + '...' if len(secao) > 200 else secao,
                    'dados_numericos': matches[:10]  # Limitar a 10 matches por tabela
                })
        
        return tabelas_encontradas
    except Exception as e:
        st.error(f"Erro ao extrair tabelas do Markdown: {e}")
        return []

def extrair_secoes_importantes(texto_md):
    """
    Extrai se√ß√µes importantes do arquivo Markdown como metodologia, indicadores, etc.
    """
    secoes = {}
    
    # Padr√µes para encontrar se√ß√µes importantes
    padroes_secoes = {
        'metodologia': r'(metodologia|m√©todo|procedimento)',
        'indicadores': r'(indicador|m√©trica|medida)',
        'resultados': r'(resultado|conclus√£o|achado)',
        'recomendacoes': r'(recomenda|sugest√£o|orienta√ß√£o)',
        'tabelas': r'(tabela|quadro|dados)',
        'graficos': r'(gr√°fico|figura|chart)',
        'habilidades': r'(habilidade|compet√™ncia|capacidade)',
        'componentes': r'(componente|disciplina|√°rea)',
        'relacoes': r'(rela√ß√£o|relacionamento|conex√£o|vincula√ß√£o)',
        'proficiencia': r'(profici√™ncia|desempenho|rendimento)',
        'avaliacao': r'(avalia√ß√£o|teste|exame)',
        'curriculo': r'(curr√≠culo|conte√∫do|programa)',
        'bncc_competencias': r'(compet√™ncia geral|compet√™ncia espec√≠fica|habilidade essencial)',
        'bncc_campos': r'(campo de experi√™ncia|√°rea de conhecimento)',
        'bncc_objetivos': r'(objetivo de aprendizagem|expectativa de aprendizagem)',
        'bncc_etapas': r'(educa√ß√£o infantil|ensino fundamental|ensino m√©dio)',
        'bncc_areas': r'(linguagens|matem√°tica|ci√™ncias|humanas)',
        'bncc_objetivos_gerais': r'(objetivo geral|finalidade|prop√≥sito)',
        'bncc_principios': r'(princ√≠pio|fundamento|base)',
        'bncc_organizacao': r'(organiza√ß√£o|estrutura|distribui√ß√£o)',
        'bncc_avaliacao': r'(avalia√ß√£o formativa|avalia√ß√£o diagn√≥stica|avalia√ß√£o somativa)',
        'dcrc_competencias_especificas': r'(compet√™ncia espec√≠fica|habilidade espec√≠fica|descri√ß√£o da habilidade)',
        'dcrc_descricoes_habilidades': r'(descri√ß√£o|caracteriza√ß√£o|defini√ß√£o.*habilidade)',
        'dcrc_relacoes_habilidades': r'(rela√ß√£o.*habilidade|vincula√ß√£o.*compet√™ncia|conex√£o.*componente)'
    }
    
    for nome_secao, padrao in padroes_secoes.items():
        matches = re.finditer(padrao, texto_md, re.IGNORECASE)
        for match in matches:
            # Extrair contexto ao redor da palavra-chave
            inicio = max(0, match.start() - 500)
            fim = min(len(texto_md), match.end() + 500)
            contexto = texto_md[inicio:fim]
            
            if nome_secao not in secoes:
                secoes[nome_secao] = []
            secoes[nome_secao].append(contexto)
    
    return secoes

def criar_indice_similaridade(chunks):
    """
    Cria um √≠ndice de similaridade usando TF-IDF para busca sem√¢ntica
    """
    try:
        if not chunks:
            return None
        
        # Extrair textos dos chunks
        textos = [chunk['texto'] for chunk in chunks]
        
        # Criar vetorizador TF-IDF
        vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,  # Manter palavras em portugu√™s
            ngram_range=(1, 2)
        )
        
        # Vetorizar textos
        tfidf_matrix = vectorizer.fit_transform(textos)
        
        return {
            'vectorizer': vectorizer,
            'tfidf_matrix': tfidf_matrix,
            'chunks': chunks
        }
    except Exception as e:
        print(f"Erro ao criar √≠ndice de similaridade: {e}")
        return None


def comparar_habilidades_competencias(dados_rag, nome_habilidade=""):
    """
    Compara descri√ß√µes de habilidades com compet√™ncias espec√≠ficas do DCRC
    """
    try:
        if not dados_rag or not dados_rag.get('secoes_importantes'):
            return ""
        
        secoes = dados_rag['secoes_importantes']
        comparacao = ""
        
        # Extrair compet√™ncias espec√≠ficas do DCRC
        competencias_especificas = secoes.get('dcrc_competencias_especificas', [])
        descricoes_habilidades = secoes.get('dcrc_descricoes_habilidades', [])
        relacoes_habilidades = secoes.get('dcrc_relacoes_habilidades', [])
        
        if competencias_especificas or descricoes_habilidades:
            comparacao = "\n\n===== AN√ÅLISE DE HABILIDADES COM BASE NAS RELA√á√ïES E COMPET√äNCIAS BNCC/DCRC =====\n"
            
            # Adicionar compet√™ncias espec√≠ficas encontradas
            if competencias_especificas:
                comparacao += "\nüéØ COMPET√äNCIAS ESPEC√çFICAS IDENTIFICADAS NOS DOCUMENTOS BNCC/DCRC:\n"
                for i, comp in enumerate(competencias_especificas[:3], 1):
                    # Identificar se √© do BNCC ou DCRC
                    fonte = "BNCC" if "BNCC" in comp or "Base Nacional Comum Curricular" in comp else "DCRC"
                    comparacao += f"{i}. [{fonte}] {comp[:400]}...\n\n"
            
            # Adicionar descri√ß√µes de habilidades
            if descricoes_habilidades:
                comparacao += "\nüìù DESCRI√á√ïES DE HABILIDADES ENCONTRADAS NOS DOCUMENTOS BNCC/DCRC:\n"
                for i, desc in enumerate(descricoes_habilidades[:3], 1):
                    # Identificar se √© do BNCC ou DCRC
                    fonte = "BNCC" if "BNCC" in desc or "Base Nacional Comum Curricular" in desc else "DCRC"
                    comparacao += f"{i}. [{fonte}] {desc[:400]}...\n\n"
            
            # Adicionar rela√ß√µes entre habilidades
            if relacoes_habilidades:
                comparacao += "\nüîó RELA√á√ïES ENTRE HABILIDADES IDENTIFICADAS NOS DOCUMENTOS BNCC/DCRC:\n"
                for i, rel in enumerate(relacoes_habilidades[:2], 1):
                    # Identificar se √© do BNCC ou DCRC
                    fonte = "BNCC" if "BNCC" in rel or "Base Nacional Comum Curricular" in rel else "DCRC"
                    comparacao += f"{i}. [{fonte}] {rel[:400]}...\n\n"
            
            # Instru√ß√µes espec√≠ficas para an√°lise de habilidades com foco em rela√ß√µes
            comparacao += """
üîß INSTRU√á√ïES OBRIGAT√ìRIAS PARA AN√ÅLISE DE HABILIDADES:

1. PROXIMIDADE ENTRE HABILIDADES:
   - IDENTIFIQUE habilidades que aparecem pr√≥ximas nos dados
   - ANALISE se habilidades com desempenho similar est√£o relacionadas
   - EXPLIQUE por que certas habilidades t√™m padr√µes similares
   - SUGIRA interven√ß√µes que trabalhem habilidades relacionadas juntas

2. RELA√á√ÉO DENTRO DO PR√ìPRIO COMPONENTE:
   - FOQUE nas habilidades que pertencem ao mesmo componente
   - IDENTIFIQUE hierarquias dentro do componente
   - ANALISE depend√™ncias entre habilidades do mesmo componente
   - SUGIRA sequ√™ncias de ensino baseadas nas rela√ß√µes internas

3. RELA√á√ÉO ENTRE COMPONENTES:
   - MAPEIE como habilidades de diferentes componentes se conectam
   - IDENTIFIQUE compet√™ncias que dependem de m√∫ltiplos componentes
   - ANALISE transfer√™ncias de conhecimento entre componentes
   - SUGIRA abordagens interdisciplinares baseadas nas rela√ß√µes

4. COMPET√äNCIAS ESPEC√çFICAS:
   - RELACIONE cada habilidade com compet√™ncias espec√≠ficas do DCRC
   - IDENTIFIQUE quais compet√™ncias s√£o mais cr√≠ticas
   - ANALISE lacunas entre habilidades e compet√™ncias esperadas
   - SUGIRA desenvolvimento de compet√™ncias espec√≠ficas

5. DESCRI√á√ïES DAS HABILIDADES:
   - USE as descri√ß√µes do DCRC para entender o que cada habilidade envolve
   - COMPARE descri√ß√µes com desempenho real nos dados
   - IDENTIFIQUE habilidades mal compreendidas pelos estudantes
   - SUGIRA reformula√ß√µes pedag√≥gicas baseadas nas descri√ß√µes

6. AN√ÅLISE INTEGRADA:
   - COMBINE proximidade, rela√ß√µes e compet√™ncias na an√°lise
   - IDENTIFIQUE padr√µes complexos de desempenho
   - SUGIRA interven√ß√µes sist√™micas baseadas nas rela√ß√µes
   - MONITORE progresso considerando as interconex√µes
"""
        
        return comparacao
    except Exception as e:
        print(f"Erro na compara√ß√£o habilidades-compet√™ncias: {e}")
        return ""

def analisar_percursos_aprendizado(dados_rag, nome_habilidade=""):
    """
    Analisa percursos de aprendizado, depend√™ncias e rela√ß√µes entre habilidades de forma CIR√öRGICA
    """
    try:
        if not dados_rag or not dados_rag.get('indice_similaridade'):
            return ""
        
        # Buscar informa√ß√µes espec√≠ficas sobre percursos de aprendizado
        consultas_percurso = [
            f"percurso aprendizado progress√£o sequ√™ncia {nome_habilidade}",
            f"depend√™ncia pr√©-requisito hierarquia habilidade {nome_habilidade}",
            f"rela√ß√£o conex√£o vincula√ß√£o habilidade componente {nome_habilidade}",
            f"compet√™ncia espec√≠fica objetivo aprendizagem {nome_habilidade}",
            f"metodologia estrat√©gia ensino habilidade {nome_habilidade}"
        ]
        
        contexto_percursos = "\n\n===== AN√ÅLISE HIER√ÅRQUICA DE PERCURSOS DE APRENDIZADO =====\n"
        
        for consulta in consultas_percurso:
            informacoes = buscar_informacoes_relevantes(consulta, dados_rag, top_k=3)
            if informacoes:
                contexto_percursos += f"\nüîç INFORMA√á√ïES SOBRE: {consulta.upper()}\n"
                for info in informacoes:
                    fonte = info.get('fonte', 'Documento')
                    contexto_percursos += f"[{fonte}] {info['texto'][:300]}...\n\n"
        
        # Instru√ß√µes HIER√ÅRQUICAS para an√°lise de percursos
        contexto_percursos += """
üéØ INSTRU√á√ïES HIER√ÅRQUICAS PARA AN√ÅLISE DE PERCURSOS DE APRENDIZADO:

**AN√ÅLISE HIER√ÅRQUICA OBRIGAT√ìRIA - PERSPECTIVA POR N√çVEL EDUCACIONAL:**

1. MAPEAMENTO HIER√ÅRQUICO DE DEPEND√äNCIAS:
   - IDENTIFIQUE EXATAMENTE quais habilidades s√£o pr√©-requisito para outras conforme BNCC/DCRC
   - MAPEIE a hierarquia ESPEC√çFICA: habilidades b√°sicas ‚Üí intermedi√°rias ‚Üí avan√ßadas
   - ANALISE habilidades "gargalo" ESPEC√çFICAS que bloqueiam o desenvolvimento de outras
   - IDENTIFIQUE habilidades que se refor√ßam mutuamente de forma CONCRETA
   - SUGIRA sequ√™ncias de ensino ESPEC√çFICAS baseadas nas depend√™ncias identificadas
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

2. PERCURSOS HIER√ÅRQUICOS ESTRUTURADOS:
   - DESENHE percursos de aprendizado ESPEC√çFICOS: quais habilidades devem ser desenvolvidas primeiro
   - MAPEIE pontos de converg√™ncia CONCRETOS onde m√∫ltiplas habilidades se encontram
   - IDENTIFIQUE compet√™ncias ESPEC√çFICAS que dependem de m√∫ltiplos componentes
   - ANALISE transfer√™ncias de conhecimento ESPEC√çFICAS entre componentes
   - SUGIRA abordagens interdisciplinares ESPEC√çFICAS baseadas nos percursos
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

3. RELA√á√ïES HIER√ÅRQUICAS ENTRE HABILIDADES:
   - IDENTIFIQUE habilidades que aparecem pr√≥ximas nos dados ESPEC√çFICOS
   - ANALISE se habilidades com desempenho similar est√£o relacionadas de forma CONCRETA
   - EXPLIQUE por que certas habilidades t√™m padr√µes similares de forma ESPEC√çFICA
   - MAPEIE como habilidades de diferentes componentes se conectam de forma CONCRETA
   - SUGIRA interven√ß√µes ESPEC√çFICAS que trabalhem habilidades relacionadas juntas
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

4. COMPET√äNCIAS E OBJETIVOS HIER√ÅRQUICOS:
   - RELACIONE cada habilidade com compet√™ncias espec√≠ficas do BNCC/DCRC de forma CONCRETA
   - IDENTIFIQUE objetivos de aprendizagem ESPEC√çFICOS para cada habilidade
   - ANALISE lacunas ESPEC√çFICAS entre habilidades e compet√™ncias esperadas
   - MAPEIE compet√™ncias gerais da BNCC desenvolvidas atrav√©s das habilidades de forma CONCRETA
   - SUGIRA desenvolvimento de compet√™ncias ESPEC√çFICO baseado nos documentos
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

5. METODOLOGIAS E ESTRAT√âGIAS HIER√ÅRQUICAS:
   - USE metodologias ESPEC√çFICAS sugeridas nos documentos BNCC/DCRC para cada habilidade
   - IDENTIFIQUE recursos e materiais ESPEC√çFICOS recomendados nos documentos
   - MAPEIE estrat√©gias ESPEC√çFICAS para desenvolvimento de cada habilidade
   - SUGIRA reformula√ß√µes pedag√≥gicas ESPEC√çFICAS baseadas nas descri√ß√µes dos documentos
   - IDENTIFIQUE pr√°ticas de linguagem e campos de experi√™ncia ESPEC√çFICOS relevantes
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

6. INTERVEN√á√ïES HIER√ÅRQUICAS SIST√äMICAS:
   - DESENHE planos de a√ß√£o ESPEC√çFICOS baseados nos percursos de aprendizado identificados
   - IDENTIFIQUE pontos de interven√ß√£o mais eficazes de forma CONCRETA baseado nas depend√™ncias
   - MAPEIE como melhorar uma habilidade impacta outras habilidades de forma ESPEC√çFICA
   - SUGIRA interven√ß√µes sist√™micas ESPEC√çFICAS baseadas nas rela√ß√µes identificadas
   - MONITORE progresso considerando as interconex√µes de forma CONCRETA conforme BNCC/DCRC
   - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores

**REFERENCIAMENTO HIER√ÅRQUICO OBRIGAT√ìRIO:**
- REFERENCIE SEMPRE: "Conforme a BNCC", "Segundo o DCRC", "Baseado nos percursos identificados"
- CITE compet√™ncias espec√≠ficas e objetivos de aprendizagem mencionados nos documentos de forma CONCRETA
- REFERENCIE metodologias e recursos sugeridos nos documentos de forma ESPEC√çFICA
- IDENTIFIQUE campos de experi√™ncia e pr√°ticas de linguagem dos documentos de forma CONCRETA
- DIFERENCIE entre informa√ß√µes dos documentos vs. an√°lises gen√©ricas de forma CLARA
- SEJA ESPEC√çFICO: evite generaliza√ß√µes, foque nos dados espec√≠ficos da entidade
- **CITE OBRIGATORIAMENTE BNCC E DCRC**: Sempre que poss√≠vel, referencie tanto a BNCC quanto o DCRC como fontes principais das metodologias, compet√™ncias e diretrizes curriculares
- **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
"""
        
        return contexto_percursos
        
    except Exception as e:
        print(f"Erro na an√°lise de percursos de aprendizado: {e}")
        return ""

def gerar_analise_personalizada(dados_rag, df_info, nome_grafico, contexto_especifico=""):
    """
    Gera an√°lise personalizada baseada nos dados espec√≠ficos da entidade e gr√°fico
    """
    try:
        if not dados_rag or not dados_rag.get('secoes_importantes'):
            return ""
        
        secoes = dados_rag['secoes_importantes']
        analise_personalizada = ""
        
        # Extrair dados espec√≠ficos do DataFrame
        estatisticas = df_info.get('estatisticas', {})
        amostra_dados = df_info.get('amostra_dados', [])
        debug_info = df_info.get('debug_info', {})
        
        # Identificar padr√µes espec√≠ficos nos dados
        padroes_identificados = []
        if estatisticas:
            for coluna, stats in estatisticas.items():
                if isinstance(stats, dict):
                    if 'mean' in stats and stats['mean'] < 50:
                        padroes_identificados.append(f"Baixo desempenho em {coluna} (m√©dia: {stats['mean']:.1f})")
                    elif 'mean' in stats and stats['mean'] > 80:
                        padroes_identificados.append(f"Alto desempenho em {coluna} (m√©dia: {stats['mean']:.1f})")
        
        # Extrair recomenda√ß√µes espec√≠ficas dos documentos DCRC + BNCC
        recomendacoes = secoes.get('recomendacoes', [])
        metodologia = secoes.get('metodologia', [])
        bncc_competencias = secoes.get('bncc_competencias', [])
        bncc_objetivos = secoes.get('bncc_objetivos', [])
        dcrc_competencias_especificas = secoes.get('dcrc_competencias_especificas', [])
        dcrc_descricoes_habilidades = secoes.get('dcrc_descricoes_habilidades', [])
        
        if padroes_identificados or recomendacoes or metodologia:
            analise_personalizada = "\n\n===== AN√ÅLISE PERSONALIZADA COM BASE NOS DOCUMENTOS DCRC + BNCC =====\n"
            
            # Padr√µes identificados nos dados
            if padroes_identificados:
                analise_personalizada += "\nüîç PADR√ïES IDENTIFICADOS NOS DADOS:\n"
                for padrao in padroes_identificados[:5]:
                    analise_personalizada += f"‚Ä¢ {padrao}\n"
            
            # Informa√ß√µes espec√≠ficas dos documentos encontradas
            if recomendacoes or metodologia or bncc_competencias or dcrc_competencias_especificas:
                analise_personalizada += "\nüìö INFORMA√á√ïES ESPEC√çFICAS DOS DOCUMENTOS ENCONTRADAS:\n"
                
                if recomendacoes:
                    analise_personalizada += f"‚Ä¢ DCRC - Recomenda√ß√µes: {len(recomendacoes)} se√ß√µes encontradas\n"
                if metodologia:
                    analise_personalizada += f"‚Ä¢ DCRC - Metodologia: {len(metodologia)} se√ß√µes encontradas\n"
                if bncc_competencias:
                    analise_personalizada += f"‚Ä¢ BNCC - Compet√™ncias: {len(bncc_competencias)} se√ß√µes encontradas\n"
                if dcrc_competencias_especificas:
                    analise_personalizada += f"‚Ä¢ DCRC - Compet√™ncias Espec√≠ficas: {len(dcrc_competencias_especificas)} se√ß√µes encontradas\n"
                if dcrc_descricoes_habilidades:
                    analise_personalizada += f"‚Ä¢ DCRC - Descri√ß√µes de Habilidades: {len(dcrc_descricoes_habilidades)} se√ß√µes encontradas\n"
            
            # Recomenda√ß√µes espec√≠ficas baseadas nos padr√µes E documentos
            if padroes_identificados:
                analise_personalizada += "\nüí° RECOMENDA√á√ïES ESPEC√çFICAS (BASEADAS NOS DOCUMENTOS):\n"
                for padrao in padroes_identificados[:3]:
                    if "Baixo desempenho" in padrao:
                        analise_personalizada += f"‚Ä¢ Para {padrao}: Implementar interven√ß√£o pedag√≥gica espec√≠fica baseada nas compet√™ncias espec√≠ficas do DCRC identificadas\n"
                    elif "Alto desempenho" in padrao:
                        analise_personalizada += f"‚Ä¢ Para {padrao}: Manter e expandir pr√°ticas exitosas, compartilhar com outras √°reas usando metodologias do DCRC\n"
            
            # A√ß√µes espec√≠ficas baseadas no tipo de gr√°fico, dados E documentos
            if 'habilidade' in nome_grafico.lower():
                analise_personalizada += """
üéØ A√á√ïES ESPEC√çFICAS PARA HABILIDADES (BASEADAS NOS DOCUMENTOS):
‚Ä¢ Analisar quais habilidades espec√≠ficas t√™m baixo desempenho nos dados
‚Ä¢ Criar planos de interven√ß√£o direcionados usando as compet√™ncias espec√≠ficas do DCRC
‚Ä¢ Desenvolver atividades pr√°ticas baseadas nas descri√ß√µes de habilidades do DCRC
‚Ä¢ Estabelecer grupos de estudo focados nas habilidades com menor desempenho
‚Ä¢ Monitorar progresso usando indicadores espec√≠ficos do DCRC
‚Ä¢ Alinhar com compet√™ncias gerais e espec√≠ficas da BNCC identificadas
"""
            elif 'profici√™ncia' in nome_grafico.lower():
                analise_personalizada += """
üìä A√á√ïES ESPEC√çFICAS PARA PROFICI√äNCIA (BASEADAS NOS DOCUMENTOS):
‚Ä¢ Identificar n√≠veis de profici√™ncia espec√≠ficos nos dados
‚Ä¢ Criar planos de interven√ß√£o usando metodologias do DCRC
‚Ä¢ Estabelecer metas de profici√™ncia baseadas nos objetivos da BNCC
‚Ä¢ Implementar avalia√ß√£o formativa cont√≠nua com foco nas compet√™ncias espec√≠ficas
‚Ä¢ Desenvolver estrat√©gias de recupera√ß√£o baseadas nas recomenda√ß√µes do DCRC
‚Ä¢ Alinhar com campos de experi√™ncia da BNCC identificados
"""
            elif 'participa√ß√£o' in nome_grafico.lower():
                analise_personalizada += """
üë• A√á√ïES ESPEC√çFICAS PARA PARTICIPA√á√ÉO (BASEADAS NOS PDFs):
‚Ä¢ Analisar taxa de participa√ß√£o espec√≠fica nos dados
‚Ä¢ Identificar fatores que impactam a participa√ß√£o usando metodologias do DCRC
‚Ä¢ Criar estrat√©gias de engajamento baseadas nos princ√≠pios da BNCC
‚Ä¢ Estabelecer parcerias com fam√≠lias usando orienta√ß√µes do DCRC
‚Ä¢ Monitorar participa√ß√£o com indicadores espec√≠ficos do DCRC
‚Ä¢ Alinhar com objetivos de aprendizagem da BNCC
"""
            
            # Instru√ß√µes espec√≠ficas para an√°lise personalizada COM PDFs
            analise_personalizada += """
üîß INSTRU√á√ïES PARA AN√ÅLISE PERSONALIZADA COM PDFs:
1. FOQUE nos dados espec√≠ficos da entidade analisada
2. IDENTIFIQUE padr√µes √∫nicos nos dados apresentados
3. RELACIONE os dados com as compet√™ncias espec√≠ficas do DCRC encontradas
4. SUGIRA a√ß√µes baseadas nos dados reais E nas informa√ß√µes dos PDFs
5. CONSIDERE o contexto espec√≠fico da entidade
6. MONITORE indicadores espec√≠ficos identificados nos dados
7. ADAPTE as a√ß√µes conforme os dados espec√≠ficos E os PDFs
8. AVALIE o progresso com base nos dados apresentados E nas metodologias do DCRC
9. REFERENCIE explicitamente as informa√ß√µes dos PDFs nas an√°lises
10. DIFERENCIE claramente quando est√° usando informa√ß√µes dos PDFs vs. an√°lises gen√©ricas
"""
        
        return analise_personalizada
    except Exception as e:
        print(f"Erro na gera√ß√£o de an√°lise personalizada: {e}")
        return ""

def gerar_acoes_escola_baseadas_pdfs(dados_rag, tipo_grafico, contexto_especifico=""):
    """
    Gera a√ß√µes espec√≠ficas que a escola deve tomar baseadas nos PDFs, com foco na educa√ß√£o b√°sica
    """
    try:
        if not dados_rag or not dados_rag.get('secoes_importantes'):
            return ""
        
        secoes = dados_rag['secoes_importantes']
        acoes_escola = ""
        
        # Extrair recomenda√ß√µes e orienta√ß√µes dos PDFs
        recomendacoes = secoes.get('recomendacoes', [])
        metodologia = secoes.get('metodologia', [])
        bncc_competencias = secoes.get('bncc_competencias', [])
        bncc_objetivos = secoes.get('bncc_objetivos', [])
        bncc_principios = secoes.get('bncc_principios', [])
        
        if recomendacoes or metodologia or bncc_competencias:
            acoes_escola = "\n\n===== A√á√ïES ESPEC√çFICAS PARA A ESCOLA (BASEADAS NOS PDFs) =====\n"
            
            # A√ß√µes baseadas no DCRC
            if recomendacoes or metodologia:
                acoes_escola += "\nüìã A√á√ïES BASEADAS NO DCRC:\n"
                if recomendacoes:
                    for i, rec in enumerate(recomendacoes[:2], 1):
                        acoes_escola += f"‚Ä¢ {rec[:300]}...\n"
                if metodologia:
                    for i, met in enumerate(metodologia[:2], 1):
                        acoes_escola += f"‚Ä¢ {met[:300]}...\n"
            
            # A√ß√µes baseadas na BNCC
            if bncc_competencias or bncc_objetivos:
                acoes_escola += "\nüìö A√á√ïES BASEADAS NA BNCC:\n"
                if bncc_competencias:
                    for i, comp in enumerate(bncc_competencias[:2], 1):
                        acoes_escola += f"‚Ä¢ {comp[:300]}...\n"
                if bncc_objetivos:
                    for i, obj in enumerate(bncc_objetivos[:2], 1):
                        acoes_escola += f"‚Ä¢ {obj[:300]}...\n"
            
            # A√ß√µes espec√≠ficas por tipo de gr√°fico
            if 'habilidade' in tipo_grafico.lower():
                acoes_escola += """
üéØ A√á√ïES ESPEC√çFICAS PARA HABILIDADES:
‚Ä¢ Implementar atividades pr√°ticas baseadas nas compet√™ncias espec√≠ficas do DCRC
‚Ä¢ Criar sequ√™ncias did√°ticas que desenvolvam habilidades inter-relacionadas
‚Ä¢ Estabelecer momentos de reflex√£o sobre o desenvolvimento das compet√™ncias
‚Ä¢ Organizar grupos de estudo para habilidades com baixo desempenho
‚Ä¢ Desenvolver materiais did√°ticos alinhados com as compet√™ncias da BNCC
"""
            elif 'profici√™ncia' in tipo_grafico.lower():
                acoes_escola += """
üìä A√á√ïES ESPEC√çFICAS PARA PROFICI√äNCIA:
‚Ä¢ Alinhar pr√°ticas pedag√≥gicas com os objetivos de aprendizagem da BNCC
‚Ä¢ Implementar avalia√ß√£o formativa cont√≠nua baseada nas compet√™ncias
‚Ä¢ Criar planos de interven√ß√£o para n√≠veis de profici√™ncia cr√≠ticos
‚Ä¢ Estabelecer metas de profici√™ncia por compet√™ncia espec√≠fica
‚Ä¢ Desenvolver estrat√©gias de recupera√ß√£o baseadas nas compet√™ncias
"""
            elif 'participa√ß√£o' in tipo_grafico.lower():
                acoes_escola += """
üë• A√á√ïES ESPEC√çFICAS PARA PARTICIPA√á√ÉO:
‚Ä¢ Implementar estrat√©gias de engajamento baseadas nos princ√≠pios da BNCC
‚Ä¢ Criar ambientes de aprendizagem que promovam participa√ß√£o ativa
‚Ä¢ Desenvolver atividades que conectem com os campos de experi√™ncia
‚Ä¢ Estabelecer parcerias com fam√≠lias baseadas nas orienta√ß√µes do DCRC
‚Ä¢ Organizar momentos de protagonismo estudantil
"""
            
            # Instru√ß√µes espec√≠ficas para a√ß√µes pr√°ticas
            acoes_escola += """
üîß INSTRU√á√ïES PARA IMPLEMENTA√á√ÉO:
1. PRIORIZE: A√ß√µes que desenvolvam compet√™ncias b√°sicas fundamentais
2. SEQUENCIE: Implemente a√ß√µes em ordem de complexidade crescente
3. MONITORE: Acompanhe o progresso baseado nas compet√™ncias espec√≠ficas
4. ADAPTE: Ajuste as a√ß√µes conforme o contexto da escola
5. COLABORE: Envolva toda a comunidade escolar nas a√ß√µes
6. DOCUMENTE: Registre as a√ß√µes e seus resultados
7. AVALIE: Use os indicadores do DCRC para avaliar o progresso
8. REFLITA: Promova reflex√£o coletiva sobre as pr√°ticas implementadas
"""
        
        return acoes_escola
    except Exception as e:
        print(f"Erro na gera√ß√£o de a√ß√µes para escola: {e}")
        return ""

def buscar_informacoes_relevantes(consulta, dados_rag, top_k=5):
    """
    Busca informa√ß√µes relevantes no PDF usando RAG
    """
    try:
        if not dados_rag or not dados_rag.get('indice_similaridade'):
            return []
        
        indice = dados_rag['indice_similaridade']
        vectorizer = indice['vectorizer']
        tfidf_matrix = indice['tfidf_matrix']
        chunks = indice['chunks']
        
        # Expandir consulta com termos relacionados espec√≠ficos
        if 'habilidade' in consulta.lower() or 'compet√™ncia' in consulta.lower():
            consulta_expandida = f"{consulta} habilidade compet√™ncia capacidade componente rela√ß√£o entre componentes proximidade habilidades SPAECE DCRC BNCC avalia√ß√£o profici√™ncia compet√™ncia geral compet√™ncia espec√≠fica habilidade essencial descri√ß√£o da habilidade caracteriza√ß√£o habilidade espec√≠fica vincula√ß√£o compet√™ncia conex√£o componente rela√ß√£o dentro pr√≥prio componente compet√™ncias espec√≠ficas descri√ß√µes habilidades rela√ß√µes habilidades objeto de conhecimento campo de experi√™ncia pr√°tica de linguagem percurso aprendizado progress√£o sequ√™ncia depend√™ncia pr√©-requisito hierarquia metodologia estrat√©gia ensino objetivo aprendizagem expectativa aprendizagem direito aprendizagem base nacional comum curricular documento curricular referencial"
        elif 'profici√™ncia' in consulta.lower() or 'desempenho' in consulta.lower():
            consulta_expandida = f"{consulta} profici√™ncia desempenho rendimento SPAECE DCRC BNCC avalia√ß√£o compet√™ncia objetivo de aprendizagem compet√™ncia espec√≠fica"
        elif 'participa√ß√£o' in consulta.lower():
            consulta_expandida = f"{consulta} participa√ß√£o frequ√™ncia presen√ßa SPAECE DCRC BNCC educa√ß√£o b√°sica"
        else:
            consulta_expandida = f"{consulta} educa√ß√£o avalia√ß√£o SPAECE DCRC BNCC metodologia indicadores compet√™ncia geral compet√™ncia espec√≠fica habilidade essencial descri√ß√£o habilidade"
        
        # Vetorizar a consulta
        consulta_vector = vectorizer.transform([consulta_expandida])
        
        # Calcular similaridade
        similaridades = cosine_similarity(consulta_vector, tfidf_matrix).flatten()
        
        # Obter top-k resultados mais similares
        top_indices = np.argsort(similaridades)[::-1][:top_k]
        
        resultados = []
        for idx in top_indices:
            if similaridades[idx] > 0.05:  # Threshold mais baixo para capturar mais informa√ß√µes
                chunk_texto = chunks[idx]['texto']
                # Identificar se o chunk √© do BNCC ou DCRC
                if "BNCC" in chunk_texto or "Base Nacional Comum Curricular" in chunk_texto or "BNCC_20dez_site" in chunk_texto:
                    fonte_documento = "BNCC"
                elif "DCRC" in chunk_texto or "Documento Curricular Referencial" in chunk_texto or "dcrc" in chunk_texto.lower():
                    fonte_documento = "DCRC"
                else:
                    # Se n√£o conseguir identificar, usar contexto do texto combinado
                    # Alternar entre BNCC e DCRC para dar equil√≠brio
                    fonte_documento = "BNCC" if idx % 2 == 0 else "DCRC"
                
                resultados.append({
                    'chunk': chunks[idx],
                    'similaridade': similaridades[idx],
                    'texto': chunk_texto,
                    'fonte': fonte_documento
                })
        
        # Busca espec√≠fica para habilidades e rela√ß√µes com foco em BNCC e DCRC
        if 'habilidade' in consulta.lower() or 'compet√™ncia' in consulta.lower():
            palavras_habilidade = ['habilidade', 'compet√™ncia', 'capacidade', 'componente', 'rela√ß√£o', 'vincula√ß√£o', 'conex√£o', 'descri√ß√£o', 'caracteriza√ß√£o', 'espec√≠fica', 'geral', 'essencial', 'dcrc', 'documento curricular', 'bncc', 'base nacional comum curricular']
            for i, chunk in enumerate(chunks):
                texto_chunk = chunk['texto'].lower()
                if any(palavra in texto_chunk for palavra in palavras_habilidade):
                    # Verificar se j√° n√£o est√° nos resultados
                    if not any(r['chunk']['indice'] == chunk['indice'] for r in resultados):
                        # Identificar fonte para habilidades
                        if "BNCC" in chunk['texto'] or "Base Nacional Comum Curricular" in chunk['texto']:
                            fonte_habilidade = "BNCC"
                        elif "DCRC" in chunk['texto'] or "Documento Curricular Referencial" in chunk['texto']:
                            fonte_habilidade = "DCRC"
                        else:
                            # Alternar entre BNCC e DCRC para dar equil√≠brio
                            fonte_habilidade = "BNCC" if i % 2 == 0 else "DCRC"
                        
                        resultados.append({
                            'chunk': chunk,
                            'similaridade': 0.4,  # Similaridade alta para habilidades
                            'texto': chunk['texto'],
                            'fonte': fonte_habilidade
                        })
                        if len(resultados) >= top_k * 2:  # Mais resultados para habilidades
                            break
        
        # Se n√£o encontrou resultados espec√≠ficos, buscar por palavras-chave gerais
        if not resultados:
            palavras_chave = consulta.lower().split()
            for i, chunk in enumerate(chunks):
                texto_chunk = chunk['texto'].lower()
                if any(palavra in texto_chunk for palavra in palavras_chave):
                    resultados.append({
                        'chunk': chunk,
                        'similaridade': 0.3,  # Similaridade artificial para palavras-chave
                        'texto': chunk['texto']
                    })
                    if len(resultados) >= top_k:
                        break
        
        return resultados
    except Exception as e:
        print(f"Erro na busca RAG: {e}")
        return []

def analisar_pdf_com_rag_groq(dados_rag, contexto_analise="", consulta_especifica=""):
    """
    Analisa o PDF usando RAG + Groq para encontrar informa√ß√µes espec√≠ficas
    """
    try:
        # Configurar a API do Groq
        groq_api_key = st.secrets.get("GROQ_API_KEY")
        if not groq_api_key:
            return "‚ùå Chave da API Groq n√£o configurada"
        
        headers = {
            "Authorization": f"Bearer {groq_api_key}",
            "Content-Type": "application/json"
        }
        
        # Buscar informa√ß√µes relevantes usando RAG
        if consulta_especifica:
            informacoes_relevantes = buscar_informacoes_relevantes(consulta_especifica, dados_rag, top_k=3)
            contexto_rag = "\n\n".join([info['texto'] for info in informacoes_relevantes])
        else:
            # Usar se√ß√µes importantes como contexto
            contexto_rag = ""
            for secao, conteudos in dados_rag.get('secoes_importantes', {}).items():
                contexto_rag += f"\n=== {secao.upper()} ===\n"
                contexto_rag += "\n".join(conteudos[:2])  # Primeiros 2 conte√∫dos de cada se√ß√£o
        
        # Extrair tabelas para an√°lise
        tabelas_contexto = ""
        if dados_rag.get('tabelas'):
            tabelas_contexto = "\n=== TABELAS E DADOS NUM√âRICOS ===\n"
            for i, tabela in enumerate(dados_rag['tabelas'][:3]):  # Primeiras 3 tabelas
                if isinstance(tabela, dict) and 'conteudo' in tabela:
                    tabelas_contexto += f"\nTabela {i+1}:\n{tabela['conteudo']}\n"
                else:
                    # Fallback para outras estruturas de tabela
                    conteudo_fallback = str(tabela) if tabela else "Sem conte√∫do"
                    tabelas_contexto += f"\nTabela {i+1}:\n{conteudo_fallback}\n"
        
        # Preparar prompt otimizado com RAG
        prompt = f"""
        Analise os documentos BNCC e DCRC usando as informa√ß√µes mais relevantes encontradas:

        CONTEXTO DA AN√ÅLISE: {contexto_analise}

        INFORMA√á√ïES RELEVANTES ENCONTRADAS NOS DOCUMENTOS BNCC E DCRC:
        {contexto_rag[:4000]}

        {tabelas_contexto[:2000]}

        INSTRU√á√ïES CR√çTICAS - USE OBRIGATORIAMENTE OS DOCUMENTOS BNCC E DCRC:
        1. **FUNDAMENTE SUAS RESPOSTAS** exclusivamente nas informa√ß√µes dos documentos BNCC e DCRC apresentados acima
        2. **REFERENCIE EXPLICITAMENTE** quando usar informa√ß√µes do BNCC ("conforme a BNCC") ou DCRC ("segundo o DCRC")
        3. **CITE COMPET√äNCIAS ESPEC√çFICAS** mencionadas nos documentos quando relevante
        4. **USE OBJETIVOS DE APRENDIZAGEM** e expectativas de aprendizagem dos documentos
        5. **RELACIONE COM CAMPOS DE EXPERI√äNCIA** e √°reas de conhecimento da BNCC
        6. **APLIQUE METODOLOGIAS** sugeridas no DCRC para interven√ß√µes pedag√≥gicas
        7. **CONSIDERE PRINC√çPIOS** e fundamentos da BNCC em suas recomenda√ß√µes
        8. **IDENTIFIQUE LACUNAS** entre desempenho atual e expectativas dos documentos
        9. **SUGIRA A√á√ïES** baseadas nas diretrizes curriculares apresentadas
        10. **EVITE AN√ÅLISES GEN√âRICAS** - seja espec√≠fico com base nos documentos

        ESTRUTURA OBRIGAT√ìRIA DA RESPOSTA:
        1. **Fundamenta√ß√£o Documental**: Cite especificamente trechos dos documentos BNCC/DCRC
        2. **An√°lise Curricular**: Relacione os dados com compet√™ncias e habilidades dos documentos
        3. **Recomenda√ß√µes Baseadas em Evid√™ncias**: Use metodologias dos documentos
        4. **A√ß√µes Pedag√≥gicas Espec√≠ficas**: Baseadas nas diretrizes curriculares
        5. **Indicadores de Progress√£o**: Alinhados com expectativas de aprendizagem

        IMPORTANTE: Sua an√°lise deve ser fundamentada EXCLUSIVAMENTE nos documentos BNCC e DCRC apresentados. Evite an√°lises gen√©ricas ou baseadas em conhecimento geral.

        Responda em portugu√™s brasileiro de forma clara, objetiva e acion√°vel.
        """
        
        data = {
            "model": "llama3-8b-8192",
            "messages": [
                {
                    "role": "system",
                    "content": "Voc√™ √© um especialista em an√°lise de dados educacionais e avalia√ß√£o da educa√ß√£o b√°sica. Sua fun√ß√£o √© analisar dados SPAECE fundamentando-se EXCLUSIVAMENTE nos documentos BNCC (Base Nacional Comum Curricular) e DCRC (Documento Curricular Referencial do Cear√°) fornecidos. Voc√™ deve citar explicitamente trechos dos documentos, referenciar compet√™ncias espec√≠ficas, habilidades e metodologias mencionadas nos documentos. Evite an√°lises gen√©ricas - seja espec√≠fico e fundamentado nos documentos curriculares apresentados."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 3000,
            "temperature": 0.7
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return f"‚ùå Erro na API Groq: {response.status_code} - {response.text}"
            
    except Exception as e:
        return f"‚ùå Erro na an√°lise RAG do PDF: {str(e)}"

def analisar_pdf_com_groq(texto_pdf, contexto_analise=""):
    """
    Analisa o conte√∫do de um PDF usando Groq (vers√£o simples)
    """
    try:
        # Configurar a API do Groq
        groq_api_key = st.secrets.get("GROQ_API_KEY")
        if not groq_api_key:
            return "‚ùå Chave da API Groq n√£o configurada"
        
        headers = {
            "Authorization": f"Bearer {groq_api_key}",
            "Content-Type": "application/json"
        }
        
        # Preparar prompt para an√°lise do PDF
        prompt = f"""
        Analise o seguinte documento PDF e forne√ßa insights relevantes para an√°lise educacional:

        CONTEXTO DA AN√ÅLISE: {contexto_analise}

        CONTE√öDO DO PDF:
        {texto_pdf[:8000]}  # Limitar tamanho para evitar token limit

        Por favor, forne√ßa:
        1. Resumo dos principais pontos do documento
        2. M√©tricas e indicadores mencionados
        3. Recomenda√ß√µes ou insights educacionais
        4. Padr√µes ou tend√™ncias identificadas
        5. Sugest√µes para an√°lise de dados SPAECE baseadas no documento

        Responda em portugu√™s brasileiro de forma clara e objetiva.
        """
        
        data = {
            "model": "llama3-8b-8192",
            "messages": [
                {
                    "role": "system",
                    "content": "Voc√™ √© um especialista em an√°lise de dados educacionais e avalia√ß√£o da educa√ß√£o b√°sica. Sua fun√ß√£o √© analisar dados SPAECE fundamentando-se EXCLUSIVAMENTE nos documentos BNCC (Base Nacional Comum Curricular) e DCRC (Documento Curricular Referencial do Cear√°) fornecidos. Voc√™ deve citar explicitamente trechos dos documentos, referenciar compet√™ncias espec√≠ficas, habilidades e metodologias mencionadas nos documentos. Evite an√°lises gen√©ricas - seja espec√≠fico e fundamentado nos documentos curriculares apresentados."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 2000,
            "temperature": 0.7
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            return f"‚ùå Erro na API Groq: {response.status_code} - {response.text}"
            
    except Exception as e:
        return f"‚ùå Erro na an√°lise do PDF: {str(e)}"

# ==================== FUN√á√ÉO PARA OBTER CONTEXTO DOS BANNERS ====================

def obter_contexto_seduc_spaece():
    """
    Retorna contexto espec√≠fico da SEDUC-CE e SPAECE para fundamentar an√°lises
    """
    return """
    CONTEXTO SEDUC-CE E SPAECE - FUNDAMENTA√á√ÉO DAS AN√ÅLISES:
    
    **SISTEMA PERMANENTE DE AVALIA√á√ÉO DA EDUCA√á√ÉO B√ÅSICA DO CEAR√Å (SPAECE):**
    - Criado em 1992, √© um dos sistemas de avalia√ß√£o mais antigos e consolidados do Brasil
    - Avalia anualmente estudantes do 2¬∫, 5¬∫ e 9¬∫ anos do Ensino Fundamental e 3¬™ s√©rie do Ensino M√©dio
    - Foco nas disciplinas de L√≠ngua Portuguesa e Matem√°tica
    - Utiliza escalas de profici√™ncia: 500 pontos (2¬∫ ano) e 1000 pontos (5¬∫, 9¬∫ anos e 3¬™ s√©rie EM)
    - Padr√µes de Desempenho: Cr√≠tico, Intermedi√°rio, Adequado (5¬∫ e 9¬∫ anos)
    - Padr√µes de Desempenho 2¬∫ ano: N√£o Alfabetizado, Alfabetiza√ß√£o Incompleta, Intermedi√°rio, Suficiente, Desej√°vel
    
    **PROGRAMA DE ALFABETIZA√á√ÉO NA IDADE CERTA (PAIC):**
    - Implementado desde 2007, √© refer√™ncia nacional em alfabetiza√ß√£o
    - Foco na alfabetiza√ß√£o at√© o 2¬∫ ano do Ensino Fundamental
    - Estrutura: 5 eixos (Gest√£o Municipal, Gest√£o Escolar, Avalia√ß√£o, Forma√ß√£o de Professores, Material Did√°tico)
    - Resultado: Cear√° saltou de 22¬∫ para 1¬∫ lugar no IDEB entre 2005-2017
    
    **POL√çTICAS EDUCACIONAIS DO CEAR√Å:**
    - B√¥nus por Resultado: Sistema de premia√ß√£o baseado em desempenho
    - Aprender Pra Valer: Programa de fortalecimento da aprendizagem
    - Mais Paic: Expans√£o do PAIC para o 3¬∫ ao 5¬∫ ano
    - Jovem de Futuro: Parceria com Instituto Unibanco para Ensino M√©dio
    
    **INDICADORES DE REFER√äNCIA DO CEAR√Å:**
    - IDEB 2021: 4¬∫ lugar nacional (5¬∫ ano: 6,4; 9¬∫ ano: 5,1; EM: 4,2)
    - Taxa de Aprova√ß√£o: 95,2% (5¬∫ ano), 92,8% (9¬∫ ano)
    - Taxa de Abandono: 0,8% (5¬∫ ano), 2,1% (9¬∫ ano)
    - Profici√™ncia M√©dia SPAECE 2022: 5¬∫ ano LP: 225,8; MAT: 230,1
    - Profici√™ncia M√©dia SPAECE 2022: 9¬∫ ano LP: 275,3; MAT: 280,7
    
    **BENEF√çCIOS DA ALTA PARTICIPA√á√ÉO NO SPAECE:**
    - **Recursos Financeiros:** Munic√≠pios com alta participa√ß√£o podem receber mais recursos do FUNDEB e programas federais
    - **Melhoria da Estrutura:** Escolas com boa participa√ß√£o s√£o priorizadas em investimentos em infraestrutura
    - **Planos de Carreira:** Altas taxas de participa√ß√£o servem de subs√≠dio para implementar planos de cargos e carreiras
    - **Aumento Salarial:** Professores de escolas com boa participa√ß√£o podem ter aumentos salariais baseados em resultados
    - **Programas Especiais:** Acesso a programas como PAIC, Mais Paic e outros baseados em indicadores de qualidade
    - **Reputa√ß√£o Educacional:** Munic√≠pios com alta participa√ß√£o ganham reconhecimento e atraem mais investimentos
    - **IDEB Elevado:** Participa√ß√£o alta contribui para melhor IDEB, resultando em mais recursos e prest√≠gio
    - **Pol√≠ticas P√∫blicas:** Dados de alta participa√ß√£o fundamentam pol√≠ticas educacionais e aloca√ß√£o de recursos
    
    **METAS E PADR√ïES DE REFER√äNCIA:**
    - Meta IDEB 2024: 5¬∫ ano: 6,5; 9¬∫ ano: 5,2; EM: 4,3
    - Padr√£o Adequado SPAECE: 5¬∫ ano LP: ‚â•200; MAT: ‚â•225
    - Padr√£o Adequado SPAECE: 9¬∫ ano LP: ‚â•275; MAT: ‚â•300
    - Taxa de Participa√ß√£o M√≠nima: 80% (cr√≠tico), 90% (adequado), **100% (IDEAL)**
    - **Meta de Participa√ß√£o Ideal:** 100% - m√°xima participa√ß√£o garante dados representativos e traz benef√≠cios
    
    **CARACTER√çSTICAS SOCIOECON√îMICAS DO CEAR√Å:**
    - Popula√ß√£o: 9,2 milh√µes de habitantes
    - PIB per capita: R$ 15.847 (2021)
    - √çndice de Desenvolvimento Humano: 0,754 (2010)
    - Taxa de Pobreza: 25,8% (2021)
    - 184 munic√≠pios, 20 CREDEs (Coordenadorias Regionais de Desenvolvimento da Educa√ß√£o)
    
    **FATORES DE SUCESSO EDUCACIONAL:**
    - Continuidade das pol√≠ticas p√∫blicas (16 anos de PAIC)
    - Foco na alfabetiza√ß√£o e anos iniciais
    - Sistema de avalia√ß√£o permanente e diagn√≥stico
    - Forma√ß√£o continuada de professores
    - Material did√°tico espec√≠fico e contextualizado
    - Gest√£o baseada em resultados e evid√™ncias
    - Parceria Estado-Munic√≠pios (regime de colabora√ß√£o)
    
    **DESAFIOS ATUAIS:**
    - Redu√ß√£o do abandono escolar no Ensino M√©dio
    - Melhoria da profici√™ncia em Matem√°tica
    - Equidade entre regi√µes e grupos sociais
    - Impacto da pandemia na aprendizagem
    - Forma√ß√£o de professores em √°reas espec√≠ficas
    - Infraestrutura escolar em munic√≠pios menores
    
    **FONTES OFICIAIS:**
    - Site SEDUC-CE: https://www.seduc.ce.gov.br/
    - Portal SPAECE: https://spaece.seduc.ce.gov.br/
    - Relat√≥rios anuais de resultados SPAECE
    - Documentos do PAIC e programas correlatos
    - Estat√≠sticas educacionais do INEP/MEC
    """

def obter_contexto_banner(nome_grafico):
    """
    Retorna o contexto espec√≠fico do banner 'Como analisar este gr√°fico' para nortear a an√°lise IA
    """
    contextos = {
        "Taxa de Participa√ß√£o": """
        **CONTEXTO T√âCNICO DO GR√ÅFICO DE PARTICIPA√á√ÉO:**
        - Tipo: Gauge (medidor circular) com escala de 0% a 100%
        - Cores: Verde (90-100%), Amarelo (80-89%), Vermelho (<80%)
        - F√≥rmula: Taxa de participa√ß√£o = (Alunos Efetivos √∑ Alunos Previstos) √ó 100
        - Interpreta√ß√£o: Ponteiro indica taxa atual, zonas coloridas mostram classifica√ß√£o
        - Significado: Percentual de alunos que efetivamente participaram da avalia√ß√£o
        - **Meta Ideal:** 100% de participa√ß√£o para garantir dados representativos e trazer benef√≠cios
        
        **FOQUE APENAS NESTE GR√ÅFICO DE PARTICIPA√á√ÉO:**
        - Analise exclusivamente os dados de taxa de participa√ß√£o apresentados
        - N√£o mencione outros gr√°ficos (profici√™ncia, habilidades, desempenho, etc.)
        - Concentre-se apenas nos dados de participa√ß√£o e seus benef√≠cios
        
        BENEF√çCIOS DA ALTA PARTICIPA√á√ÉO:
        - Recursos financeiros para o munic√≠pio (FUNDEB, programas federais)
        - Melhoria da estrutura escolar (prioriza√ß√£o em investimentos)
        - Subs√≠dio para planos de cargos e carreiras dos profissionais
        - Aumento salarial baseado em resultados
        - Acesso a programas especiais (PAIC, Mais Paic)
        - Reputa√ß√£o educacional e reconhecimento
        - IDEB elevado e mais investimentos
        - Fundamenta√ß√£o para pol√≠ticas p√∫blicas educacionais
        """,
        
        "Profici√™ncia M√©dia": """
        **CONTEXTO T√âCNICO DO GR√ÅFICO DE PROFICI√äNCIA:**
        - Tipo: Cards com m√©tricas e banners coloridos
        - Escalas: 500 (2¬∫ ano) e 1000 (5¬∫ e 9¬∫ anos)
        - Cores: Verde (Adequado), Amarelo (Intermedi√°rio), Vermelho (Cr√≠tico)
        - Interpreta√ß√£o: Valores num√©ricos de profici√™ncia por entidade
        - Significado: N√≠vel de conhecimento dos estudantes em cada entidade
        
        **FOQUE APENAS NESTE GR√ÅFICO DE PROFICI√äNCIA:**
        - Analise exclusivamente os dados de profici√™ncia m√©dia apresentados
        - N√£o mencione outros gr√°ficos (participa√ß√£o, habilidades, desempenho, etc.)
        - Concentre-se apenas nos dados de profici√™ncia e suas implica√ß√µes pedag√≥gicas
        """,
        
        "Distribui√ß√£o por Desempenho": """
        **CONTEXTO T√âCNICO DO GR√ÅFICO DE DESEMPENHO:**
        - Tipo: Gr√°fico de barras empilhadas (stacked bar chart)
        - Eixo X: Entidades (Estado, CREDE, Munic√≠pio, Escola)
        - Eixo Y: Percentual de alunos (0% a 100%)
        - Barras: Divididas em 5 segmentos (N√≠veis 1-5)
        - Padr√µes por etapa:
          * 2¬∫ Ano: N√£o Alfabetizado ‚Üí Alfabetiza√ß√£o Incompleta ‚Üí Intermedi√°rio ‚Üí Suficiente ‚Üí Desej√°vel
          * 5¬∫/9¬∫ Ano: Muito Cr√≠tico ‚Üí Cr√≠tico ‚Üí Intermedi√°rio ‚Üí Adequado
        - Interpreta√ß√£o: Altura total = 100% dos alunos, segmentos = propor√ß√£o por n√≠vel
        
        **FOQUE APENAS NESTE GR√ÅFICO DE DESEMPENHO:**
        - Analise exclusivamente os dados de distribui√ß√£o por desempenho apresentados
        - N√£o mencione outros gr√°ficos (participa√ß√£o, profici√™ncia, habilidades, etc.)
        - Concentre-se apenas nos dados de desempenho e estrat√©gias por n√≠vel
        """,
        
        "Taxa de Acerto por Habilidade": """
        CONTEXTO T√âCNICO DO GR√ÅFICO:
        - Tipo: Gr√°fico de barras agrupadas (grouped bar chart)
        - Eixo X: C√≥digo da Habilidade (identificador √∫nico)
        - Eixo Y: Taxa de acerto (0% a 100%)
        - Barras: Agrupadas por tipo de entidade (Cear√°, CREDE, Munic√≠pio, Escola)
        - Interpreta√ß√£o: Altura da barra = taxa de acerto, cores = tipo de entidade
        - Significado: Percentual de quest√µes corretas por habilidade espec√≠fica
        - Hierarquia: Habilidades t√™m pr√©-requisitos - b√°sicas s√£o fundamentais para avan√ßadas
        """,
        
        "Profici√™ncia por Etnia": """
        CONTEXTO SOCIOL√ìGICO E T√âCNICO DO GR√ÅFICO:
        - Tipo: Gr√°fico de barras agrupadas (grouped bar chart)
        - Eixo X: Grupos √©tnicos (Branca, Preta, Parda, Amarela, Ind√≠gena)
        - Eixo Y: Profici√™ncia m√©dia (escalas 500 ou 1000)
        - Barras: Agrupadas por tipo de entidade
        - Interpreta√ß√£o: Altura da barra = profici√™ncia m√©dia do grupo √©tnico
        - Significado: N√≠vel de conhecimento por grupo √©tnico-racial
        
        PERSPECTIVA SOCIOL√ìGICA - EQUIDADE EDUCACIONAL:
        - FOCO PRINCIPAL: Identificar e analisar desigualdades educacionais entre grupos √©tnicos
        - QUEST√ÉO CENTRAL: Como o sistema educacional reproduz ou combate desigualdades raciais?
        - INDICADORES DE EQUIDADE: Proximidade dos resultados entre grupos √©tnicos
        - AN√ÅLISE CR√çTICA: Fatores sociais, hist√≥ricos e estruturais que influenciam o desempenho
        - CONTEXTO HIST√ìRICO: Heran√ßa de exclus√£o e discrimina√ß√£o racial no Brasil
        - POL√çTICAS P√öBLICAS: A√ß√µes afirmativas e pol√≠ticas de equidade racial
        - INTERSECCIONALIDADE: Como ra√ßa se cruza com classe, g√™nero e territ√≥rio
        """,
        
        "Profici√™ncia por NSE": """
        CONTEXTO SOCIOL√ìGICO E T√âCNICO DO GR√ÅFICO:
        - Tipo: Gr√°fico de barras agrupadas (grouped bar chart)
        - Eixo X: N√≠veis Socioecon√¥micos (A, B, C, D, E)
        - Eixo Y: Profici√™ncia m√©dia (escalas 500 ou 1000)
        - Barras: Agrupadas por tipo de entidade
        - Interpreta√ß√£o: Altura da barra = profici√™ncia m√©dia do NSE
        - Significado: N√≠vel de conhecimento por n√≠vel socioecon√¥mico
        
        PERSPECTIVA SOCIOL√ìGICA - EQUIDADE EDUCACIONAL:
        - FOCO PRINCIPAL: Analisar como a origem socioecon√¥mica impacta o desempenho educacional
        - QUEST√ÉO CENTRAL: Como o sistema educacional reproduz ou combate desigualdades de classe?
        - INDICADORES DE EQUIDADE: Redu√ß√£o das diferen√ßas entre NSEs (A, B, C, D, E)
        - AN√ÅLISE CR√çTICA: Fatores estruturais que perpetuam desigualdades socioecon√¥micas
        - CONTEXTO HIST√ìRICO: Heran√ßa de exclus√£o social e concentra√ß√£o de renda no Brasil
        - CAPITAL CULTURAL: Como recursos familiares influenciam o desempenho escolar
        - POL√çTICAS P√öBLICAS: A√ß√µes de democratiza√ß√£o do acesso e qualidade educacional
        - MOBILIDADE SOCIAL: Educa√ß√£o como instrumento de transforma√ß√£o social
        """,
        
        "Profici√™ncia por Sexo": """
        CONTEXTO SOCIOL√ìGICO E T√âCNICO DO GR√ÅFICO:
        - Tipo: Gr√°fico de barras agrupadas (grouped bar chart)
        - Eixo X: G√™neros (Feminino, Masculino)
        - Eixo Y: Profici√™ncia m√©dia (escalas 500 ou 1000)
        - Barras: Agrupadas por tipo de entidade
        - Interpreta√ß√£o: Altura da barra = profici√™ncia m√©dia por g√™nero
        - Significado: N√≠vel de conhecimento por g√™nero
        
        PERSPECTIVA SOCIOL√ìGICA - EQUIDADE EDUCACIONAL:
        - FOCO PRINCIPAL: Analisar diferen√ßas de desempenho entre g√™neros na educa√ß√£o
        - QUEST√ÉO CENTRAL: Como o sistema educacional reproduz ou combate desigualdades de g√™nero?
        - INDICADORES DE EQUIDADE: Proximidade dos resultados entre g√™neros
        - AN√ÅLISE CR√çTICA: Fatores sociais e culturais que influenciam o desempenho por g√™nero
        - CONTEXTO HIST√ìRICO: Heran√ßa de desigualdades de g√™nero na sociedade brasileira
        - ESTERE√ìTIPOS: Como expectativas sociais afetam o desempenho educacional
        - POL√çTICAS P√öBLICAS: A√ß√µes de promo√ß√£o da equidade de g√™nero na educa√ß√£o
        - INTERSECCIONALIDADE: Como g√™nero se cruza com ra√ßa, classe e territ√≥rio
        - REPRESENTA√á√ÉO: Papel da representatividade e modelos de refer√™ncia
        """
    }
    
    return contextos.get(nome_grafico, "")

# ==================== FUN√á√ÉO DE AN√ÅLISE COM GROQ ====================

def analisar_dataframe_com_groq(df, nome_grafico, contexto="", entidade_consultada="", df_concatenado=None):
    """
    Analisa um DataFrame usando a API da Groq e retorna insights considerando a hierarquia educacional
    Usa df_concatenado para identificar corretamente a entidade e sua hierarquia
    Inclui contexto do PDF de refer√™ncia quando dispon√≠vel
    """
    try:
        # Verificar se a API key est√° configurada
        if 'groq' not in st.secrets or 'api_key' not in st.secrets.groq:
            return "‚ö†Ô∏è API key da Groq n√£o configurada no secrets.toml"
        
        api_key = st.secrets.groq.api_key
        if api_key == "gsk_your_groq_api_key_here":
            return "‚ö†Ô∏è Configure sua API key da Groq no arquivo secrets.toml"
        
        # Importar groq apenas quando necess√°rio
        from groq import Groq
        
        # Inicializar cliente Groq
        client = Groq(api_key=api_key)
        
        # Determinar tipo de entidade e hierarquia
        tipo_entidade = "Desconhecida"
        nivel_hierarquico = ""
        entidades_superiores = []
        nome_entidade_consultada = entidade_consultada  # Usar c√≥digo como fallback
        
        # Usar df_concatenado se dispon√≠vel, sen√£o usar df
        df_para_identificacao = df_concatenado if df_concatenado is not None and not df_concatenado.empty else df
        
        if not df_para_identificacao.empty:
            # Tentar obter nome da entidade consultada da coluna CD_ENTIDADE
            if 'CD_ENTIDADE' in df_para_identificacao.columns and not df_para_identificacao['CD_ENTIDADE'].isna().all():
                # Converter entidade_consultada para string para compara√ß√£o
                entidade_consultada_str = str(entidade_consultada)
                # Buscar a linha que corresponde √† entidade consultada
                entidade_filtrada = df_para_identificacao[df_para_identificacao['CD_ENTIDADE'].astype(str) == entidade_consultada_str]
                if not entidade_filtrada.empty:
                    # Tentar obter nome da entidade de diferentes colunas
                    if 'NM_ENTIDADE' in df_para_identificacao.columns and not entidade_filtrada['NM_ENTIDADE'].isna().iloc[0]:
                        nome_entidade_consultada = f"{entidade_consultada} - {entidade_filtrada['NM_ENTIDADE'].iloc[0]}"
                    elif 'DC_TIPO_ENTIDADE' in df_para_identificacao.columns and not entidade_filtrada['DC_TIPO_ENTIDADE'].isna().iloc[0]:
                        nome_entidade_consultada = f"{entidade_consultada} - {entidade_filtrada['DC_TIPO_ENTIDADE'].iloc[0]}"
            
            # Verificar colunas de tipo de entidade - usar DC_TIPO_ENTIDADE para identificar o tipo
            if 'DC_TIPO_ENTIDADE' in df_para_identificacao.columns and 'CD_ENTIDADE' in df_para_identificacao.columns:
                # Converter entidade_consultada para string para compara√ß√£o
                entidade_consultada_str = str(entidade_consultada)
                # Buscar o tipo de entidade espec√≠fico da entidade consultada
                entidade_filtrada = df_para_identificacao[df_para_identificacao['CD_ENTIDADE'].astype(str) == entidade_consultada_str]
                if not entidade_filtrada.empty:
                    dc_tipo_entidade = str(entidade_filtrada['DC_TIPO_ENTIDADE'].iloc[0]).upper()
                    # Mapear DC_TIPO_ENTIDADE para tipos de entidade baseado na descri√ß√£o
                    if 'ESTADO' in dc_tipo_entidade or 'CEAR√Å' in dc_tipo_entidade:
                        tipo_entidade = "Estado"
                        nivel_hierarquico = "N√≠vel Estadual"
                    elif 'CREDE' in dc_tipo_entidade or 'REGIONAL' in dc_tipo_entidade:
                        tipo_entidade = "CREDE/Regional"
                        nivel_hierarquico = "N√≠vel Regional"
                        entidades_superiores = ["Estado"]
                    elif 'MUNIC√çPIO' in dc_tipo_entidade or 'MUNICIPIO' in dc_tipo_entidade:
                        tipo_entidade = "Munic√≠pio"
                        nivel_hierarquico = "N√≠vel Municipal"
                        entidades_superiores = ["Estado", "CREDE/Regional"]
                    elif 'ESCOLA' in dc_tipo_entidade or 'EEIEF' in dc_tipo_entidade or 'EEM' in dc_tipo_entidade:
                        tipo_entidade = "Escola"
                        nivel_hierarquico = "N√≠vel Escolar"
                        entidades_superiores = ["Estado", "CREDE/Regional", "Munic√≠pio"]
                    else:
                        # Fallback para TP_ENTIDADE se DC_TIPO_ENTIDADE n√£o for reconhecido
                        if 'TP_ENTIDADE' in df.columns:
                            tp_entidade = entidade_filtrada['TP_ENTIDADE'].iloc[0]
                            if tp_entidade == 1:
                                tipo_entidade = "Estado"
                                nivel_hierarquico = "N√≠vel Estadual"
                            elif tp_entidade == 2:
                                tipo_entidade = "CREDE/Regional"
                                nivel_hierarquico = "N√≠vel Regional"
                                entidades_superiores = ["Estado"]
                            elif tp_entidade == 3:
                                tipo_entidade = "Munic√≠pio"
                                nivel_hierarquico = "N√≠vel Municipal"
                                entidades_superiores = ["Estado", "CREDE/Regional"]
                            elif tp_entidade == 4:
                                tipo_entidade = "Escola"
                                nivel_hierarquico = "N√≠vel Escolar"
                                entidades_superiores = ["Estado", "CREDE/Regional", "Munic√≠pio"]
            
            # Verificar se h√° dados de entidades superiores na hierarquia - usar dados da entidade consultada
            if 'CD_ENTIDADE' in df_para_identificacao.columns:
                # Converter entidade_consultada para string para compara√ß√£o
                entidade_consultada_str = str(entidade_consultada)
                entidade_filtrada = df_para_identificacao[df_para_identificacao['CD_ENTIDADE'].astype(str) == entidade_consultada_str]
                if not entidade_filtrada.empty:
                    if 'NM_ESTADO' in df_para_identificacao.columns and not entidade_filtrada['NM_ESTADO'].isna().iloc[0]:
                        entidades_superiores.append(f"Estado: {entidade_filtrada['NM_ESTADO'].iloc[0]}")
                    if 'NM_REGIONAL' in df_para_identificacao.columns and not entidade_filtrada['NM_REGIONAL'].isna().iloc[0]:
                        entidades_superiores.append(f"CREDE: {entidade_filtrada['NM_REGIONAL'].iloc[0]}")
                    if 'NM_MUNICIPIO' in df_para_identificacao.columns and not entidade_filtrada['NM_MUNICIPIO'].isna().iloc[0]:
                        entidades_superiores.append(f"Munic√≠pio: {entidade_filtrada['NM_MUNICIPIO'].iloc[0]}")
        
        # Preparar dados para an√°lise - limpeza inteligente de valores faltantes
        # Valores faltantes indicam que a coluna n√£o tem registro para aquela linha espec√≠fica
        # Para an√°lise, manter linhas que tenham pelo menos alguns dados v√°lidos
        df_limpo = df.copy()
        
        # Se o DataFrame est√° completamente vazio ap√≥s dropna(), usar estrat√©gia alternativa
        if df.dropna().empty and not df.empty:
            # Manter linhas que tenham pelo menos 50% das colunas com dados v√°lidos
            threshold = len(df.columns) * 0.5
            df_limpo = df.dropna(thresh=threshold)
            
            # Se ainda estiver vazio, manter linhas com pelo menos 25% das colunas
            if df_limpo.empty:
                threshold = len(df.columns) * 0.25
                df_limpo = df.dropna(thresh=threshold)
                
            # Se ainda estiver vazio, usar o DataFrame original
            if df_limpo.empty:
                df_limpo = df
        else:
            df_limpo = df.dropna()
        
        df_info = {
            "nome_grafico": nome_grafico,
            "contexto": contexto,
            "entidade_consultada": nome_entidade_consultada,
            "tipo_entidade": tipo_entidade,
            "nivel_hierarquico": nivel_hierarquico,
            "entidades_superiores": entidades_superiores,
            "shape_original": df.shape,
            "shape_limpo": df_limpo.shape,
            "colunas": df.columns.tolist(),
            "tipos_dados": df.dtypes.to_dict(),
            "amostra_dados": df_limpo.head(10).to_dict('records') if not df_limpo.empty else [],
            "estatisticas": df_limpo.describe().to_dict() if not df_limpo.empty else {},
            "debug_info": {
                "entidade_consultada_original": entidade_consultada,
                "entidade_consultada_str": str(entidade_consultada),
                "cd_entidade_values": df_para_identificacao['CD_ENTIDADE'].unique().tolist()[:5] if 'CD_ENTIDADE' in df_para_identificacao.columns else "Coluna n√£o encontrada",
                "dc_tipo_entidade_values": df_para_identificacao['DC_TIPO_ENTIDADE'].unique().tolist()[:5] if 'DC_TIPO_ENTIDADE' in df_para_identificacao.columns else "Coluna n√£o encontrada",
                "nm_entidade_values": df_para_identificacao['NM_ENTIDADE'].unique().tolist()[:5] if 'NM_ENTIDADE' in df_para_identificacao.columns else "Coluna n√£o encontrada",
                "entidade_encontrada": not df_para_identificacao.empty and 'CD_ENTIDADE' in df_para_identificacao.columns and str(entidade_consultada) in df_para_identificacao['CD_ENTIDADE'].astype(str).values,
                "dc_tipo_entidade_da_entidade": entidade_filtrada['DC_TIPO_ENTIDADE'].iloc[0] if not df_para_identificacao.empty and 'CD_ENTIDADE' in df_para_identificacao.columns and 'DC_TIPO_ENTIDADE' in df_para_identificacao.columns and not df_para_identificacao[df_para_identificacao['CD_ENTIDADE'].astype(str) == str(entidade_consultada)].empty else "N√£o encontrado",
                "nm_entidade_da_entidade": entidade_filtrada['NM_ENTIDADE'].iloc[0] if not df_para_identificacao.empty and 'CD_ENTIDADE' in df_para_identificacao.columns and 'NM_ENTIDADE' in df_para_identificacao.columns and not df_para_identificacao[df_para_identificacao['CD_ENTIDADE'].astype(str) == str(entidade_consultada)].empty else "N√£o encontrado"
            }
        }
        
        # Criar prompt para an√°lise
        # Adicionar contexto dos documentos usando RAG se dispon√≠vel
        contexto_documentos = ""
        if st.session_state.get('documentos_carregados', False) and st.session_state.get('dados_rag'):
            dados_rag = st.session_state['dados_rag']
            
            # Usar RAG para encontrar informa√ß√µes relevantes
            consulta_especifica = f"{nome_grafico} {contexto} {tipo_entidade}"
            informacoes_relevantes = buscar_informacoes_relevantes(consulta_especifica, dados_rag, top_k=3)
            
            # Adicionar informa√ß√µes das tabelas se dispon√≠veis
            tabelas_contexto = ""
            if dados_rag.get('tabelas'):
                tabelas_contexto = "\n\nDADOS DAS TABELAS DO DCRC:\n"
                for i, tabela in enumerate(dados_rag['tabelas'][:2], 1):
                    if isinstance(tabela, dict) and 'conteudo' in tabela:
                        tabelas_contexto += f"Tabela {i}:\n{tabela['conteudo'][:500]}...\n\n"
                    else:
                        # Fallback para outras estruturas de tabela
                        conteudo_fallback = str(tabela)[:500] if tabela else "Sem conte√∫do"
                        tabelas_contexto += f"Tabela {i}:\n{conteudo_fallback}...\n\n"
            
            # Adicionar se√ß√µes importantes
            secoes_contexto = ""
            if dados_rag.get('secoes_importantes'):
                secoes_contexto = "\n\nSE√á√ïES IMPORTANTES DO DCRC:\n"
                for secao, conteudos in dados_rag['secoes_importantes'].items():
                    if conteudos:
                        secoes_contexto += f"{secao.upper()}:\n{conteudos[0][:300]}...\n\n"
            
            # Contexto espec√≠fico para habilidades
            contexto_habilidades = ""
            if 'habilidade' in nome_grafico.lower() or 'compet√™ncia' in nome_grafico.lower():
                # Adicionar compara√ß√£o espec√≠fica com compet√™ncias do BNCC/DCRC
                comparacao_competencias = comparar_habilidades_competencias(dados_rag, nome_grafico)
                
                # Adicionar an√°lise de percursos de aprendizado
                analise_percursos = analisar_percursos_aprendizado(dados_rag, nome_grafico)
                
                # Adicionar a√ß√µes espec√≠ficas para escola
                acoes_escola = gerar_acoes_escola_baseadas_pdfs(dados_rag, nome_grafico, contexto)
                
                contexto_habilidades = f"""

        ===== AN√ÅLISE HIER√ÅRQUICA DE HABILIDADES: RELA√á√ïES, DEPEND√äNCIAS E PERCURSOS POR N√çVEL EDUCACIONAL =====
        
        **AN√ÅLISE HIER√ÅRQUICA OBRIGAT√ìRIA - PERSPECTIVA POR N√çVEL EDUCACIONAL:**
        
        1. MAPEAMENTO HIER√ÅRQUICO DE RELA√á√ïES E DEPEND√äNCIAS:
           - IDENTIFIQUE EXATAMENTE quais habilidades aparecem pr√≥ximas nos dados ESPEC√çFICOS do DataFrame
           - ANALISE se habilidades com desempenho similar est√£o relacionadas de forma CONCRETA conforme BNCC/DCRC
           - MAPEIE depend√™ncias ESPEC√çFICAS: quais habilidades s√£o pr√©-requisito para outras conforme os documentos
           - IDENTIFIQUE habilidades "gargalo" ESPEC√çFICAS que bloqueiam o desenvolvimento de outras
           - EXPLIQUE por que certas habilidades t√™m padr√µes similares de forma ESPEC√çFICA baseado nas rela√ß√µes dos documentos
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        2. PERCURSOS HIER√ÅRQUICOS DE APRENDIZADO ESTRUTURADOS:
           - DESENHE percursos de aprendizado ESPEC√çFICOS: quais habilidades devem ser desenvolvidas primeiro
           - MAPEIE a hierarquia ESPEC√çFICA: habilidades b√°sicas ‚Üí intermedi√°rias ‚Üí avan√ßadas conforme BNCC/DCRC
           - IDENTIFIQUE pontos de converg√™ncia CONCRETOS onde m√∫ltiplas habilidades se encontram
           - ANALISE transfer√™ncias de conhecimento ESPEC√çFICAS entre componentes usando as rela√ß√µes dos documentos
           - SUGIRA sequ√™ncias de ensino ESPEC√çFICAS baseadas nas rela√ß√µes internas identificadas nos documentos
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        3. RELA√á√ÉO HIER√ÅRQUICA ENTRE COMPONENTES E COMPET√äNCIAS:
           - MAPEIE como habilidades de diferentes componentes se conectam de forma CONCRETA conforme BNCC/DCRC
           - IDENTIFIQUE compet√™ncias ESPEC√çFICAS que dependem de m√∫ltiplos componentes baseado nas compet√™ncias espec√≠ficas
           - RELACIONE cada habilidade com compet√™ncias espec√≠ficas do BNCC/DCRC de forma CONCRETA
           - ANALISE lacunas ESPEC√çFICAS entre habilidades e compet√™ncias esperadas conforme os documentos
           - SUGIRA abordagens interdisciplinares ESPEC√çFICAS baseadas nas rela√ß√µes identificadas nos documentos
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        4. DESCRI√á√ïES E METODOLOGIAS HIER√ÅRQUICAS:
           - USE as descri√ß√µes ESPEC√çFICAS do BNCC/DCRC para entender o que cada habilidade envolve
           - COMPARE descri√ß√µes com desempenho real nos dados ESPEC√çFICOS do DataFrame
           - IDENTIFIQUE habilidades mal compreendidas pelos estudantes de forma CONCRETA baseado nas descri√ß√µes
           - MAPEIE metodologias ESPEC√çFICAS sugeridas nos documentos para cada habilidade
           - SUGIRA reformula√ß√µes pedag√≥gicas ESPEC√çFICAS baseadas nas descri√ß√µes dos documentos
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        5. INTERVEN√á√ïES HIER√ÅRQUICAS SIST√äMICAS E MONITORAMENTO:
           - DESENHE planos de a√ß√£o ESPEC√çFICOS baseados nos percursos de aprendizado identificados
           - IDENTIFIQUE pontos de interven√ß√£o mais eficazes de forma CONCRETA baseado nas depend√™ncias
           - MAPEIE como melhorar uma habilidade impacta outras habilidades de forma ESPEC√çFICA
           - SUGIRA interven√ß√µes sist√™micas ESPEC√çFICAS baseadas nas rela√ß√µes identificadas nos documentos
           - MONITORE progresso considerando as interconex√µes de forma CONCRETA conforme BNCC/DCRC
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        6. REFERENCIAMENTO HIER√ÅRQUICO OBRIGAT√ìRIO:
           - REFERENCIE SEMPRE: "Conforme a BNCC", "Segundo o DCRC", "Baseado nas rela√ß√µes identificadas"
           - CITE compet√™ncias espec√≠ficas e objetivos de aprendizagem mencionados nos documentos de forma CONCRETA
           - REFERENCIE metodologias e recursos sugeridos nos documentos de forma ESPEC√çFICA
           - IDENTIFIQUE campos de experi√™ncia e pr√°ticas de linguagem dos documentos de forma CONCRETA
           - DIFERENCIE entre informa√ß√µes dos documentos vs. an√°lises gen√©ricas de forma CLARA
           - SEJA ESPEC√çFICO: evite generaliza√ß√µes, foque nos dados espec√≠ficos da entidade
           - **CITE OBRIGATORIAMENTE BNCC E DCRC**: Sempre que poss√≠vel, referencie tanto a BNCC quanto o DCRC como fontes principais das metodologias, compet√™ncias e diretrizes curriculares
           - **PERSPECTIVA HIER√ÅRQUICA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        {comparacao_competencias}
        
        {analise_percursos}
        
        {acoes_escola}
        """
            
            # Contexto espec√≠fico para profici√™ncia
            contexto_proficiencia = ""
            if 'profici√™ncia' in nome_grafico.lower() or 'desempenho' in nome_grafico.lower():
                # Adicionar a√ß√µes espec√≠ficas para escola
                acoes_escola_prof = gerar_acoes_escola_baseadas_pdfs(dados_rag, nome_grafico, contexto)
                
                contexto_proficiencia = f"""

        ===== CONTEXTO ESPEC√çFICO PARA AN√ÅLISE DE PROFICI√äNCIA (DCRC + BNCC) =====
        
        FOQUE ESPECIALMENTE EM:
        1. RELA√á√ÉO COM COMPET√äNCIAS GERAIS DA BNCC
        2. ALINHAMENTO COM OBJETIVOS DE APRENDIZAGEM
        3. PROGRESS√ÉO CURRICULAR POR ETAPAS
        4. CAMPOS DE EXPERI√äNCIA E √ÅREAS DE CONHECIMENTO
        5. EXPECTATIVAS DE APRENDIZAGEM POR ANO/S√âRIE
        
        USE AS INFORMA√á√ïES DO DCRC E BNCC PARA:
        - Contextualizar n√≠veis de profici√™ncia com expectativas curriculares
        - Identificar lacunas entre desempenho e objetivos da BNCC
        - Sugerir interven√ß√µes alinhadas com compet√™ncias espec√≠ficas
        - Relacionar profici√™ncia com campos de experi√™ncia
        - Considerar princ√≠pios e fundamentos da BNCC
        
        {acoes_escola_prof}
        """
            
            # Adicionar an√°lise personalizada baseada nos dados espec√≠ficos
            analise_personalizada = gerar_analise_personalizada(dados_rag, df_info, nome_grafico, contexto)
            
            # Adicionar a√ß√µes espec√≠ficas para escola baseadas no tipo de gr√°fico
            acoes_escola_geral = gerar_acoes_escola_baseadas_pdfs(dados_rag, nome_grafico, contexto)
            
            if informacoes_relevantes:
                contexto_rag = "\n\n".join([info['texto'] for info in informacoes_relevantes])
                contexto_documentos = f"""

        ===== CONTEXTO DOS DOCUMENTOS DCRC + BNCC (INFORMA√á√ïES RELEVANTES) =====
        
        INFORMA√á√ïES ESPEC√çFICAS ENCONTRADAS:
        {contexto_rag[:2000]}
        
        {tabelas_contexto}
        
        {secoes_contexto}
        
        {contexto_habilidades}
        
        {contexto_proficiencia}
        
        {analise_personalizada}
        
        {acoes_escola_geral}
        
        INSTRU√á√ÉO CR√çTICA - AN√ÅLISE CIR√öRGICA FUNDAMENTADA NOS DOCUMENTOS BNCC E DCRC:
        
        **AN√ÅLISE HIER√ÅRQUICA OBRIGAT√ìRIA - PERSPECTIVA POR N√çVEL EDUCACIONAL:**
        
        **OBRIGAT√ìRIO**: Sua an√°lise deve ser fundamentada EXCLUSIVAMENTE nas informa√ß√µes dos documentos BNCC e DCRC apresentados acima. Evite an√°lises gen√©ricas ou baseadas em conhecimento geral. **ANALISE PELA HIERARQUIA EDUCACIONAL**: cada entidade deve se ver no contexto dos n√≠veis superiores (escola dentro do munic√≠pio, munic√≠pio dentro da regional, etc.).
        
        **REFERENCIAMENTO HIER√ÅRQUICO OBRIGAT√ìRIO**:
        1. **CITE EXPLICITAMENTE** quando usar informa√ß√µes do BNCC ("conforme a BNCC", "segundo a Base Nacional Comum Curricular")
        2. **REFERENCIE DIRETAMENTE** quando usar informa√ß√µes do DCRC ("conforme o DCRC", "segundo o Documento Curricular Referencial do Cear√°")
        3. **IDENTIFIQUE A FONTE** de cada recomenda√ß√£o (BNCC ou DCRC) de forma CONCRETA
        4. **SEJA ESPEC√çFICO**: evite generaliza√ß√µes, foque nos dados espec√≠ficos da entidade
        5. **CITE OBRIGATORIAMENTE BNCC E DCRC**: Sempre que poss√≠vel, referencie tanto a BNCC quanto o DCRC como fontes principais das metodologias, compet√™ncias e diretrizes curriculares
        6. **ANALISE PELA HIERARQUIA**: Considere como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        
        **FUNDAMENTA√á√ÉO CURRICULAR HIER√ÅRQUICA**:
        7. **COMPET√äNCIAS GERAIS**: Relacione com as 10 compet√™ncias gerais da BNCC de forma CONCRETA
        8. **COMPET√äNCIAS ESPEC√çFICAS**: Cite compet√™ncias espec√≠ficas das √°reas de conhecimento de forma ESPEC√çFICA
        9. **HABILIDADES**: Referencie habilidades espec√≠ficas mencionadas nos documentos de forma CONCRETA
        10. **OBJETIVOS DE APRENDIZAGEM**: Use expectativas de aprendizagem dos documentos de forma ESPEC√çFICA
        11. **CAMPOS DE EXPERI√äNCIA**: Relacione com campos de experi√™ncia da BNCC de forma CONCRETA
        12. **√ÅREAS DE CONHECIMENTO**: Contextualize com √°reas de conhecimento espec√≠ficas de forma ESPEC√çFICA
        13. **PR√ÅTICAS DE LINGUAGEM**: Aplique pr√°ticas de linguagem quando relevante de forma CONCRETA
        
        **AN√ÅLISE PEDAG√ìGICA HIER√ÅRQUICA**:
        14. **METODOLOGIAS**: Use metodologias ESPEC√çFICAS sugeridas no DCRC para interven√ß√µes
        15. **RECURSOS**: Sugira recursos ESPEC√çFICOS baseados nas orienta√ß√µes dos documentos
        16. **AVALIA√á√ÉO**: Aplique princ√≠pios de avalia√ß√£o ESPEC√çFICOS mencionados nos documentos
        17. **PROGRESS√ÉO**: Considere progress√£o curricular ESPEC√çFICA definida nos documentos
        18. **INTERVEN√á√ïES**: Baseie interven√ß√µes nas diretrizes curriculares de forma CONCRETA
        
        **ESTRUTURA DE RESPOSTA HIER√ÅRQUICA OBRIGAT√ìRIA**:
        - **Fundamenta√ß√£o Documental**: Cite trechos ESPEC√çFICOS dos documentos
        - **An√°lise Curricular**: Relacione dados ESPEC√çFICOS com compet√™ncias e habilidades
        - **Recomenda√ß√µes Baseadas em Evid√™ncias**: Use metodologias ESPEC√çFICAS dos documentos
        - **A√ß√µes Pedag√≥gicas**: Espec√≠ficas baseadas nas diretrizes curriculares de forma CONCRETA
        - **Indicadores de Progress√£o**: Alinhados com expectativas de aprendizagem ESPEC√çFICAS
        - **PERSPECTIVA HIER√ÅRQUICA**: Analise como a entidade se posiciona em rela√ß√£o aos n√≠veis superiores e inferiores
        """
            else:
                # Fallback para contexto geral se RAG n√£o encontrar informa√ß√µes espec√≠ficas
                contexto_documentos = f"""

        ===== CONTEXTO DOS DOCUMENTOS DCRC + BNCC (GERAL) =====
        
        {st.session_state['documentos_referencia'][:3000]}
        
        {tabelas_contexto}
        
        {secoes_contexto}
        
        {contexto_habilidades}
        
        {contexto_proficiencia}
        
        {analise_personalizada}
        
        {acoes_escola_geral}
        
        INSTRU√á√ÉO CR√çTICA: Use OBRIGATORIAMENTE estas informa√ß√µes do DCRC e BNCC para contextualizar suas an√°lises e descrever a√ß√µes espec√≠ficas para a escola. PERSONALIZE baseando-se nos dados espec√≠ficos da entidade. REFERENCIE explicitamente os PDFs nas an√°lises.
        """

        prompt = f"""
        **AN√ÅLISE HIER√ÅRQUICA** dos dados educacionais do SPAECE (Sistema Permanente de Avalia√ß√£o da Educa√ß√£o B√°sica do Cear√°) considerando a HIERARQUIA EDUCACIONAL.

        **CONTEXTO HIER√ÅRQUICO ESPEC√çFICO:**
        - Entidade Consultada: {entidade_consultada}
        - Tipo de Entidade: {tipo_entidade}
        - N√≠vel Hier√°rquico: {nivel_hierarquico}
        - Entidades Superiores: {', '.join(entidades_superiores) if entidades_superiores else 'Nenhuma'}

        **INFORMA√á√ïES ESPEC√çFICAS DO GR√ÅFICO:**
        - Nome: {nome_grafico}
        - Contexto: {contexto}
        - Dimens√µes Originais: {df_info['shape_original'][0]} linhas x {df_info['shape_original'][1]} colunas
        - Dimens√µes Ap√≥s Limpeza: {df_info['shape_limpo'][0]} linhas x {df_info['shape_limpo'][1]} colunas
        - Colunas: {', '.join(df_info['colunas'])}

        **INSTRU√á√ÉO HIER√ÅRQUICA OBRIGAT√ìRIA:**
        ANALISE PELA HIERARQUIA EDUCACIONAL: cada entidade deve se ver no contexto dos n√≠veis superiores (escola dentro do munic√≠pio, munic√≠pio dentro da regional, etc.). Use informa√ß√µes dos documentos BNCC/DCRC de forma CONCRETA e ESPEC√çFICA. **CITE OBRIGATORIAMENTE BNCC E DCRC** como fontes principais das metodologias, compet√™ncias e diretrizes curriculares.
        
        **IMPORTANTE - FORMATA√á√ÉO DE N√öMEROS:**
        - **N√∫meros de alunos:** SEMPRE arredonde para n√∫meros inteiros (ex: 150 alunos, n√£o 150,5 alunos)
        - **Percentuais:** Use 1 casa decimal (ex: 85,3%)
        - **Profici√™ncia:** Use n√∫meros inteiros (ex: 250 pontos, n√£o 250,7 pontos)
        - **Evite:** "meio aluno", "0,5 alunos" ou qualquer n√∫mero decimal para quantidade de pessoas
        
        **FOCO EXCLUSIVO NO GR√ÅFICO ATUAL:**
        - **ANALISE APENAS** o gr√°fico "{nome_grafico}" apresentado acima
        - **N√ÉO MENCIONE** outros gr√°ficos ou an√°lises (participa√ß√£o, profici√™ncia, habilidades, etc.)
        - **FOQUE EXCLUSIVAMENTE** nos dados espec√≠ficos deste gr√°fico
        - **N√ÉO FA√áA** compara√ß√µes com outros tipos de gr√°ficos
        - **MANTENHA** o foco apenas nos dados e contexto deste gr√°fico espec√≠fico
        
        **COMPARA√á√ÉO HIER√ÅRQUICA ESPEC√çFICA:**
        - **COMPARE APENAS** entre os n√≠veis: Estado, Regional (CREDE), Municipal e Escolar
        - **N√ÉO MENCIONE** compara√ß√µes nacionais ou benchmarks nacionais
        - **FOQUE** na compara√ß√£o entre os n√≠veis hier√°rquicos do Cear√°
        - **EVITE** palavras como "benchmarks" ou "padr√µes nacionais"
        - **CONCENTRE-SE** na an√°lise comparativa entre os n√≠veis do estado do Cear√°

        {obter_contexto_banner(nome_grafico)}

        {obter_contexto_seduc_spaece()}

        **OBSERVA√á√ÉO IMPORTANTE:** Valores faltantes (NaN) foram tratados inteligentemente na an√°lise. Quando poss√≠vel, foram removidos completamente. Quando isso resultaria em dados insuficientes, foram mantidas linhas com pelo menos 50% ou 25% das colunas v√°lidas, pois valores faltantes indicam que aquela coluna n√£o possui registro para aquela linha espec√≠fica na estrutura do DataFrame.

        DADOS DE AMOSTRA (ap√≥s limpeza):
        {json.dumps(df_info['amostra_dados'], indent=2, default=str)}

        ESTAT√çSTICAS DESCRITIVAS (ap√≥s limpeza):
        {json.dumps(df_info['estatisticas'], indent=2, default=str)}

        INFORMA√á√ïES DE DEBUG:
        {json.dumps(df_info['debug_info'], indent=2, default=str)}
        {contexto_documentos}

        INSTRU√á√ïES ESPEC√çFICAS PARA AN√ÅLISE PROFUNDA E DETALHADA:
        
        **AN√ÅLISE ESTAT√çSTICA AVAN√áADA:**
        1. CALCULE m√©tricas estat√≠sticas completas (m√©dia, mediana, moda, desvio padr√£o, vari√¢ncia, coeficiente de varia√ß√£o, assimetria, curtose)
        2. REALIZE an√°lise de distribui√ß√£o (normalidade, outliers, percentis 25, 50, 75, 90, 95)
        3. CALCULE intervalos de confian√ßa e margens de erro quando aplic√°vel
        4. IDENTIFIQUE correla√ß√µes significativas entre vari√°veis e calcule coeficientes de correla√ß√£o
        5. ANALISE variabilidade intra e inter-grupos com medidas de dispers√£o
        6. CALCULE √≠ndices de desigualdade (Gini, Theil, etc.) quando relevante
        
        **AN√ÅLISE COMPARATIVA DETALHADA:**
        7. COMPARE entre os n√≠veis hier√°rquicos: Estado, Regional (CREDE), Municipal e Escolar
        8. ANALISE evolu√ß√£o temporal (se dispon√≠vel) com tend√™ncias e sazonalidades
        9. IDENTIFIQUE posicionamento relativo entre entidades com rankings e percentis
        10. CALCULE gaps de desempenho espec√≠ficos e oportunidades de melhoria quantificadas
        11. COMPARE contra metas educacionais estabelecidas e padr√µes de refer√™ncia do Cear√°
        
        **AN√ÅLISE DE SEGMENTA√á√ÉO E DISPERS√ÉO:**
        12. IDENTIFIQUE subgrupos com desempenho diferenciado e analise suas caracter√≠sticas
        13. ANALISE variabilidade intra e inter-grupos com medidas estat√≠sticas precisas
        14. CALCULE √≠ndices de desigualdade e concentra√ß√£o quando aplic√°vel
        15. IDENTIFIQUE fatores explicativos para as diferen√ßas observadas
        16. MAPEIE distribui√ß√£o espacial e temporal dos resultados
        
        **AN√ÅLISE DE CORRELA√á√ïES E RELA√á√ïES CAUSAIS:**
        17. IDENTIFIQUE correla√ß√µes significativas entre vari√°veis com coeficientes precisos
        18. ANALISE rela√ß√µes de causa e efeito com evid√™ncias estat√≠sticas
        19. IDENTIFIQUE fatores de influ√™ncia, mediadores e moderadores
        20. SUGIRA hip√≥teses explicativas para os padr√µes observados com fundamenta√ß√£o
        21. ANALISE cadeias causais e efeitos indiretos
        
        **AN√ÅLISE DE EQUIDADE E JUSTI√áA EDUCACIONAL:**
        22. AVALIE distribui√ß√£o justa de oportunidades e resultados com m√©tricas espec√≠ficas
        23. IDENTIFIQUE grupos em desvantagem educacional com evid√™ncias quantitativas
        24. ANALISE fatores de exclus√£o e discrimina√ß√£o com dados concretos
        25. SUGIRA pol√≠ticas de equidade e inclus√£o baseadas em evid√™ncias
        26. CALCULE √≠ndices de equidade e justi√ßa educacional
        
        **AN√ÅLISE SOCIOL√ìGICA CR√çTICA (para ETNIA, NSE, SEXO):**
        27. PERSPECTIVA SOCIOL√ìGICA: Analise atrav√©s de lente cr√≠tica da sociologia da educa√ß√£o
        28. FOCO EM EQUIDADE: Identifique e analise desigualdades educacionais entre grupos
        29. CONTEXTO HIST√ìRICO: Considere heran√ßas de exclus√£o e discrimina√ß√£o no Brasil
        30. FATORES ESTRUTURAIS: Analise como sistemas sociais perpetuam desigualdades
        31. INTERSECCIONALIDADE: Como ra√ßa, classe e g√™nero se cruzam nas desigualdades
        32. POL√çTICAS P√öBLICAS: Sugira a√ß√µes afirmativas e pol√≠ticas de equidade
        33. MOBILIDADE SOCIAL: Como a educa√ß√£o pode transformar realidades sociais
        34. CAPITAL CULTURAL: Como recursos familiares influenciam o desempenho
        35. ESTERE√ìTIPOS: Como expectativas sociais afetam diferentes grupos
        36. REPRESENTA√á√ÉO: Papel da representatividade e modelos de refer√™ncia
        
        **AN√ÅLISE DE HABILIDADES E COMPET√äNCIAS:**
        37. MAPEIE hierarquia de habilidades e pr√©-requisitos com base no DCRC
        38. IDENTIFIQUE gaps de aprendizagem espec√≠ficos e quantificados
        39. ANALISE sequ√™ncia pedag√≥gica ideal baseada em compet√™ncias
        40. SUGIRA interven√ß√µes diferenciadas por habilidade com estrat√©gias espec√≠ficas
        41. RELACIONE habilidades com compet√™ncias espec√≠ficas do DCRC
        42. ANALISE interdepend√™ncias entre habilidades e compet√™ncias
        
        **AN√ÅLISE DE PROFICI√äNCIA E DESEMPENHO:**
        43. USE escalas de refer√™ncia adequadas (500/1000) com interpreta√ß√£o precisa
        44. ANALISE distribui√ß√£o por n√≠veis de desempenho com percentuais espec√≠ficos
        45. IDENTIFIQUE fatores que explicam a profici√™ncia com evid√™ncias
        46. SUGIRA estrat√©gias de melhoria por n√≠vel com a√ß√µes espec√≠ficas
        47. RELACIONE com compet√™ncias gerais da BNCC
        48. ANALISE alinhamento com objetivos de aprendizagem
        
        **AN√ÅLISE CONTEXTUAL E SIST√äMICA:**
        49. CONSIDERE fatores socioecon√¥micos, geogr√°ficos e institucionais
        50. ANALISE impacto de pol√≠ticas p√∫blicas e programas espec√≠ficos
        51. IDENTIFIQUE recursos e condi√ß√µes necess√°rias para melhoria
        52. SUGIRA mudan√ßas sist√™micas necess√°rias com fundamenta√ß√£o
        
        **RECOMENDA√á√ïES ESTRAT√âGICAS PRIORIT√ÅRIAS:**
        53. PRIORIZE a√ß√µes por impacto e viabilidade com matriz de prioriza√ß√£o
        54. DEFINA metas espec√≠ficas e mensur√°veis com indicadores claros
        55. SUGIRA cronograma de implementa√ß√£o com marcos temporais
        56. IDENTIFIQUE recursos necess√°rios com estimativas quantificadas
        57. FOQUE na entidade espec√≠fica consultada ({nome_entidade_consultada})
        58. ADAPTE conselhos ao tipo de gestor (Secret√°rio Estadual, Coordenador Regional, Secret√°rio Municipal, Diretor Escolar)
        
        **INDICADORES DE MONITORAMENTO E AVALIA√á√ÉO:**
        59. DEFINA m√©tricas de processo e resultado espec√≠ficas
        60. ESTABELE√áA metas intermedi√°rias e finais quantificadas
        61. SUGIRA frequ√™ncia de monitoramento com cronograma
        62. IDENTIFIQUE sinais de alerta e sucesso com thresholds espec√≠ficos
        
        **ESTRUTURA DA RESPOSTA DETALHADA:**
        63. RESUMO EXECUTIVO (4-5 par√°grafos com insights principais e n√∫meros espec√≠ficos)
        64. AN√ÅLISE ESTAT√çSTICA AVAN√áADA (m√©tricas detalhadas com c√°lculos)
        65. AN√ÅLISE COMPARATIVA E BENCHMARKING (posicionamento relativo quantificado)
        66. AN√ÅLISE DE SEGMENTA√á√ÉO E DISPERS√ÉO (subgrupos e variabilidade espec√≠fica)
        67. AN√ÅLISE DE CORRELA√á√ïES E RELA√á√ïES CAUSAIS (fatores explicativos com evid√™ncias)
        68. AN√ÅLISE DE EQUIDADE E JUSTI√áA EDUCACIONAL (desigualdades e inclus√£o quantificadas)
        69. AN√ÅLISE DE HABILIDADES/COMPET√äNCIAS (se aplic√°vel, com mapeamento detalhado)
        70. AN√ÅLISE DE PROFICI√äNCIA E DESEMPENHO (se aplic√°vel, com escalas precisas)
        71. AN√ÅLISE CONTEXTUAL E SIST√äMICA (fatores externos com impacto quantificado)
        72. RECOMENDA√á√ïES ESTRAT√âGICAS PRIORIT√ÅRIAS (a√ß√µes espec√≠ficas com cronograma)
        73. INDICADORES DE MONITORAMENTO E AVALIA√á√ÉO (m√©tricas de sucesso espec√≠ficas)
        74. CONCLUS√ïES E PR√ìXIMOS PASSOS (s√≠ntese e direcionamento claro)
        
        **FUNDAMENTA√á√ÉO SEDUC-CE E SPAECE:**
        75. USE OBRIGATORIAMENTE o contexto da SEDUC-CE e SPAECE fornecido acima
        76. COMPARE resultados com indicadores de refer√™ncia do Cear√° (IDEB, profici√™ncia m√©dia, taxas)
        77. CONTEXTUALIZE an√°lises com pol√≠ticas educacionais do estado (PAIC, Mais Paic, Aprender Pra Valer)
        78. REFERENCIE padr√µes de desempenho espec√≠ficos do SPAECE (escalas 500/1000, n√≠veis)
        79. RELACIONE com fatores de sucesso educacional do Cear√° identificados
        80. CONSIDERE caracter√≠sticas socioecon√¥micas espec√≠ficas do estado
        81. IDENTIFIQUE alinhamento com metas e padr√µes de refer√™ncia estaduais
        82. SUGIRA a√ß√µes baseadas em programas e iniciativas j√° implementadas no Cear√°
        83. CONTEXTUALIZE desafios atuais do sistema educacional cearense
        84. REFERENCIE fontes oficiais (sites SEDUC-CE e SPAECE) quando apropriado
        
        **REQUISITOS DE QUALIDADE:**
        85. SEJA EXTREMAMENTE espec√≠fico e detalhado com n√∫meros concretos
        86. USE dados concretos e c√°lculos precisos com f√≥rmulas quando aplic√°vel
        87. FORNE√áA insights acion√°veis e estrat√©gicos com fundamenta√ß√£o
        88. MANTENHA foco na melhoria educacional e equidade com evid√™ncias
        89. EVITE an√°lises superficiais - seja profundo e anal√≠tico
        90. USE linguagem t√©cnica apropriada mas acess√≠vel
        91. FORNE√áA evid√™ncias para todas as afirma√ß√µes com dados espec√≠ficos
        92. REFERENCIE explicitamente os PDFs quando aplic√°vel
        93. FOQUE na entidade espec√≠fica consultada, n√£o em todas as entidades
        94. ADAPTE conselhos ao tipo de gestor e sua esfera de influ√™ncia
        95. FUNDAMENTE an√°lises com contexto espec√≠fico do Cear√° e SPAECE

        Responda em portugu√™s brasileiro.
        """
        
        # Fazer chamada para a API
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": f"Voc√™ √© um consultor educacional especializado em an√°lise de dados do SPAECE com mais de 15 anos de experi√™ncia. Seu papel √© aconselhar especificamente o gestor da entidade consultada ({nome_entidade_consultada}) sobre a√ß√µes pr√°ticas e vi√°veis dentro de sua esfera de influ√™ncia. Considere que este gestor tem poder apenas sobre seu n√≠vel hier√°rquico ({nivel_hierarquico}) e n√£o pode influenciar outros n√≠veis da hierarquia educacional. Forne√ßa an√°lises PROFUNDAS, DETALHADAS e ESTRAT√âGICAS com evid√™ncias quantitativas e qualitativas."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,
            temperature=0.2
        )
        
        return response.choices[0].message.content
        
    except ImportError:
        return "‚ö†Ô∏è Biblioteca groq n√£o instalada. Execute: pip install groq"
    except Exception as e:
        return f"‚ùå Erro na an√°lise: {str(e)}"

# Sistema de Autentica√ß√£o - Carregar do secrets.toml
try:
    # Combinar todas as credenciais em um √∫nico dicion√°rio
    PASSWORDS = {}
    ENTITY_NAMES = {}
    
    # Carregar senha mestra
    MASTER_PASSWORD = st.secrets.get("master", {}).get("password", "SPAECE2024")
    
    # Carregar usu√°rios regionais
    if "xregionais" in st.secrets:
        PASSWORDS.update(st.secrets["xregionais"])
        for codigo in st.secrets["xregionais"].keys():
            ENTITY_NAMES[codigo] = f"Regional {codigo}"
    
    # Carregar usu√°rios municipais
    if "xmunicipios" in st.secrets:
        PASSWORDS.update(st.secrets["xmunicipios"])
        # Mapear c√≥digos municipais para nomes
        municipios_map = {
            "2301000": "AQUIRAZ",
            "2303709": "CAUCAIA", 
            "2304285": "EUSEBIO",
            "2304954": "GUAIUBA",
            "2306256": "ITAITINGA",
            "2307650": "MARACANAU",
            "2307700": "MARANGUAPE",
            "2309706": "PACATUBA"
        }
        for codigo in st.secrets["xmunicipios"].keys():
            ENTITY_NAMES[codigo] = municipios_map.get(codigo, f"Munic√≠pio {codigo}")
    
    # Carregar usu√°rios de escolas
    if "xescolas" in st.secrets:
        PASSWORDS.update(st.secrets["xescolas"])
        # Mapear c√≥digos de escolas para nomes (usando coment√°rios do secrets.toml)
        escolas_map = {
            # AQUIRAZ
            "23061197": "ALOISIO BERNARDO DE CASTRO EMEF",
            "23061723": "ANTONIO DE BRITO LIMA EMEF",
            "23060956": "BATOQUE EMEF",
            "23564385": "CENTRO DE EDUCACAO E CIDADANIA MANUEL ASSUNCAO PIRES",
            "23061251": "CENTRO DE EDUCACAO E CIDADANIA MARIA DE CASTRO BERNARDO",
            "23061634": "CLARENCIO CRISOSTOMO DE FREITAS EMEF",
            "23061014": "CORREGO DA MINHOCA EMEF",
            "23061758": "DIONISIA GUERRA EMEF",
            "23061022": "ERNESTO GURGEL VALENTE EMEF",
            "23061618": "ESCOLA MUNICIPAL DE ENSINO FUNDAMENTAL TIA ALZIRA",
            "23262672": "FERDINANDO TANSI CENTRO EDUCACIONAL MUNICIPAL",
            "23061049": "FRANCISCA MONTEIRO DA SILVA EMEF",
            "23061057": "FRANCISCO DA SILVA SAMPAIO EMEF",
            "23061650": "FRANCISCO GOMES FARIAS EMEF CEL",
            "23061073": "GUILHERME JANJA EMEF",
            "23061081": "HENRIQUE GONCALVES DA JUSTA FILHO EMEF",
            "23061774": "ISIDORO DE SOUSA ASSUNCAO EMEF",
            "23061090": "JARBAS PASSARINHO MIN EMEF",
            "23061790": "JOAO JAIME GADELHA EMEF",
            "23061804": "JOAO PIRES CARDOSO EMEF",
            "23061111": "JOAQUIM DE SOUSA TAVARES EMEF",
            "23204150": "JOSE ALMIR DA SILVA EMEF",
            "23061413": "JOSE CAMARA DE ALMEIDA EMEF",
            "23061146": "JOSE FERREIRA DA COSTA EMEF",
            "23204141": "JOSE ISAAC SARAIVA DA CUNHA EMEF",
            "23061820": "JOSE RAIMUNDO DA COSTA EMEF",
            "23060999": "JOSE RODRIGUES MONTEIRO EMEF",
            "23061162": "JUSCELINO KUBITSCHEK EMEF",
            "23061847": "JUVENAL PEREIRA FACANHA EMEF",
            "23061189": "LAGOA DE CIMA EMEF",
            "23061855": "LAGOA DO MATO DE SERPA EMEF",
            "23248750": "LAIS SIDRIM TARGINO EMEF",
            "23176423": "LEOLINA BATISTA RAMOS EMEF",
            "23204125": "LUIZ EDUARDO STUDART GOMES EMEF",
            "23061278": "MARIA FACANHA DE SA EMEF",
            "23061294": "MARIA MARGARIDA RAMOS COELHO EMEF",
            "23061685": "MARIA SOARES DE FREITAS EMEF",
            "23061430": "PLACIDO CASTELO EMEF",
            "23060905": "RAIMUNDA DE FREITAS FACANHA CEI",
            "23061626": "RAIMUNDA FERREIRA DA SILVA EMEF",
            "23061480": "RAIMUNDO RAMOS DA COSTA EMEF",
            "23061448": "RITA PAULA DE BRITO EMEF",
            "23061596": "VILA PAGA EMEF",
            "23061910": "VINDINA ASSUNCAO DE AQUINO EMEF",
            # PACATUBA - Exemplo de algumas escolas
            "23264292": "JOAO PAULO SAMPAIO DE MENEZES EEIEF",
            "23083417": "ANA ALBUQUERQUE CAMPOS EEIEF",
            "23083433": "ANGELA COSTA CAMPOS EEF",
            "23083735": "CLOVIS DE CASTRO PEREIRA EEF",
            "23083492": "CRISPIANA DE ALBUQUERQUE EEF",
            "23083450": "DR CARLOS ALBERTO DE ALMEIDA PONTE EEF",
            "23083751": "FIRMINO DE ABREU LIMA EEIEF",
            "23182342": "GELIA DA SILVA CORREIA EEIEF",
            "23083778": "JARDIM BOM RETIRO EREIEF",
            "23326662": "JOANA VASCONCELOS DE OLIVEIRA EMTI",
            "23264020": "JOSE BATISTA DE OLIVEIRA EEIEF",
            "23083697": "MAJOR MANOEL ASSIS NEPOMUCENO EEIEF",
            "23267259": "MANOEL ROSENDO FREIRE EEF",
            "23083611": "MANUEL PONTES DE MEDEIROS EEIEF",
            "23083700": "MARIA DE SA RORIZ EEIEF",
            "23083808": "MARIA GUIOMAR BASTOS CAVALCANTE PROFESSORA EEIEF",
            "23083638": "MARIA MIRTES HOLANDA DO VALE PROF EEF",
            "23083719": "MARIA MOCINHA ROCHA SA EEIEF",
            "23083824": "NELLY DE LIMA E MELO EEIEF",
            "23083760": "OS HEROIS DO TIMBO EEIEF",
            "23083832": "PEDRO DE SA RORIZ EEIEF",
            "23083506": "RAIMUNDA DA CRUZ ALEXANDRE EREIEF",
            "23083689": "VICENTE FERRER DE LIMA EEIEF",
            "23190906": "WALNEY DO CARMO LOPES EEIEF"
        }
        for codigo in st.secrets["xescolas"].keys():
            ENTITY_NAMES[codigo] = escolas_map.get(codigo, f"Escola {codigo}")
    
    if not PASSWORDS:
        st.error("‚ùå Nenhuma credencial encontrada no secrets.toml!")
        st.stop()
        
except Exception as e:
    st.error(f"‚ùå Erro ao carregar secrets.toml: {str(e)}")
    st.stop()

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Painel CECOM 1 - Resultados do SPAECE 2024", 
    layout="wide",
    page_icon="üìä",
    initial_sidebar_state="expanded"
)

# CSS Global para Relat√≥rio Formal
st.markdown("""
    <style>
    /* Reset e configura√ß√µes globais */
    .stContainer {
        padding: 0 !important;
    }
    
    /* Tema de relat√≥rio formal */
    .main .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
        max-width: 1200px;
        background: #fafafa;
        font-family: 'Arial', sans-serif;
    }
    
    /* Cards de m√©tricas estilo relat√≥rio formal */
    div[data-testid="stMetric"] {
        background: #ffffff;
        padding: 20px;
        border-radius: 8px;
        border: 2px solid #e5e7eb;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        transition: all 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    div[data-testid="stMetric"]:hover {
        border-color: #26a737;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
    }
    
    div[data-testid="stMetric"]::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 4px;
        background: #26a737;
    }
    
    div[data-testid="stMetricValue"] {
        font-size: 28px;
        font-weight: 700;
        color: #26a737;
        margin-bottom: 8px;
    }
    
    div[data-testid="stMetricLabel"] {
        font-size: 12px;
        color: #6b7280;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    /* Espa√ßamento entre colunas */
    [data-testid="column"] {
        padding: 0 8px;
    }
    
    /* Bot√µes estilo relat√≥rio formal */
    .stButton > button {
        background: #26a737;
        color: white;
        border: none;
        border-radius: 6px;
        padding: 10px 20px;
        font-weight: 600;
        font-size: 14px;
        transition: all 0.2s ease;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    .stButton > button:hover {
        background: #26a737;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
    }
    
    /* Selectbox estilo relat√≥rio formal */
    .stSelectbox > div > div {
        background: white;
        border: 2px solid #d1d5db;
        border-radius: 6px;
        transition: all 0.2s ease;
    }
    
    .stSelectbox > div > div:hover {
        border-color: #2ca02c;
        box-shadow: 0 0 0 2px rgba(31, 119, 180, 0.1);
    }
    
    /* Expanders estilo relat√≥rio formal */
    .streamlit-expander {
        border: 2px solid #e5e7eb;
        border-radius: 8px;
        background: white;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }
    
    .streamlit-expanderHeader {
        background: #f9fafb;
        border-radius: 6px 6px 0 0;
        font-weight: 600;
        color: #1f2937;
        border-bottom: 1px solid #e5e7eb;
    }
    
    /* DataFrames estilo relat√≥rio formal */
    .stDataFrame {
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        border: 1px solid #e5e7eb;
    }
    
    /* Dividers estilo relat√≥rio formal */
    .stDivider {
        background: #d1d5db;
        height: 1px;
        border: none;
        margin: 1.5rem 0;
    }
    
    /* Headers de se√ß√£o estilo relat√≥rio formal */
    .report-header {
        background: #26a737;
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 6px;
        margin: 1.5rem 0 1rem 0;
        font-weight: 700;
        font-size: 1.2rem;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    /* Cards de informa√ß√£o estilo relat√≥rio formal */
    .report-card {
        background: white;
        border: 2px solid #e5e7eb;
        border-radius: 8px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }
    
    .report-card-header {
        background: #f9fafb;
        border-bottom: 2px solid #2ca02c;
        padding: 0.75rem 1rem;
        margin: -1.5rem -1.5rem 1rem -1.5rem;
        border-radius: 6px 6px 0 0;
        font-weight: 700;
        color: #1f2937;
    }
    
    /* Cores da paleta do gr√°fico de habilidades */
    .color-primary { color: #2ca02c; }
    .color-secondary { color: #f59c00; }
    .color-success { color: #2ca02c; }
    .color-danger { color: #d62728; }
    
    /* Scrollbar personalizada */
    ::-webkit-scrollbar {
        width: 6px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f5f9;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #26a737;
        border-radius: 3px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #26a737;
    }
    
    /* Estilos para impress√£o */
    @media print {
        /* Configura√ß√µes gerais da p√°gina */
        * {
            -webkit-print-color-adjust: exact !important;
            color-adjust: exact !important;
            print-color-adjust: exact !important;
        }
        
        /* Container principal - sem compress√£o */
        .main .block-container {
            padding: 0.5in !important;
            max-width: none !important;
            width: 100% !important;
            margin: 0 !important;
        }
        
        /* Ocultar sidebar */
        .stSidebar {
            display: none !important;
        }
        
        /* Ocultar elementos interativos */
        .stButton > button,
        .stDownloadButton,
        .stSelectbox,
        .stTextInput,
        .stButton,
        .stDownloadButton {
            display: none !important;
        }
        
        /* Expanders */
        .stExpander {
            border: 1px solid #ccc !important;
        }
        
        /* Quebras de p√°gina estrat√©gicas */
        .page-break {
            page-break-before: always;
            break-before: page;
        }
        
        .page-break-before {
            page-break-before: always;
            break-before: page;
        }
        
        .page-break-after {
            page-break-after: always;
            break-after: page;
        }
        
        /* Evitar quebras de p√°gina desnecess√°rias */
        .stMarkdown {
            page-break-inside: avoid;
            break-inside: avoid;
        }
        
        /* Evitar quebras em elementos pequenos */
        .stDivider {
            page-break-after: avoid;
            break-after: avoid;
        }
        
        .avoid-break {
            break-inside: avoid;
            page-break-inside: avoid;
        }
        
        /* Headers sempre no topo da p√°gina */
        .report-header {
            break-inside: avoid;
            page-break-inside: avoid;
            break-after: avoid;
            page-break-after: avoid;
            margin: 0.5rem 0 !important;
            padding: 0.75rem 1rem !important;
        }
        
        /* Cards evitam quebra no meio */
        .report-card {
            break-inside: avoid;
            page-break-inside: avoid;
            margin-bottom: 1rem;
            padding: 1rem !important;
        }
        
        /* M√©tricas evitam quebra */
        div[data-testid="stMetric"] {
            break-inside: avoid;
            page-break-inside: avoid;
            margin: 0.25rem !important;
            padding: 0.75rem !important;
        }
        
        /* DataFrames podem quebrar se necess√°rio */
        .stDataFrame {
            break-inside: auto;
            page-break-inside: auto;
            width: 100% !important;
            overflow: visible !important;
        }
        
        /* Gr√°ficos evitam quebra */
        .stPlotlyChart {
            break-inside: avoid;
            page-break-inside: avoid;
            width: 100% !important;
        }
        
        /* Dividers evitam quebra */
        .stDivider {
            break-inside: avoid;
            page-break-inside: avoid;
            margin: 0.5rem 0 !important;
        }
        
        /* Se√ß√µes que devem ficar na mesma p√°gina */
        .same-page-section {
            break-inside: avoid;
            page-break-inside: avoid;
            margin-bottom: 0.5rem !important;
        }
        
        /* Colunas responsivas */
        [data-testid="column"] {
            width: 100% !important;
            padding: 0.25rem !important;
        }
        
        /* Ajustar cores para impress√£o */
        .report-header {
            background: #2ca02c !important;
            color: white !important;
        }
        
        div[data-testid="stMetric"] {
            border: 2px solid #2ca02c !important;
        }
        
        div[data-testid="stMetricValue"] {
            color: #2ca02c !important;
        }
        
        /* Margens da p√°gina - reduzidas para melhor aproveitamento */
        @page {
            margin: 0.5in;
            size: A4 landscape;
        }
        
        /* Garantir que o conte√∫do n√£o seja comprimido */
        body {
            width: 100% !important;
            margin: 0 !important;
            padding: 0 !important;
        }
        
        /* Ajustar tabelas para impress√£o */
        table {
            width: 100% !important;
            border-collapse: collapse !important;
        }
        
        /* Ajustar imagens e gr√°ficos */
        img, svg {
            max-width: 100% !important;
            height: auto !important;
        }
        
        /* Corrigir compress√£o de colunas */
        .element-container {
            width: 100% !important;
            max-width: none !important;
        }
        
        /* Ajustar espa√ßamento geral */
        .stMarkdown {
            margin: 0.25rem 0 !important;
        }
        
        /* Corrigir largura de elementos */
        .stDataFrame > div {
            width: 100% !important;
            overflow: visible !important;
        }
        
        /* Ajustar bot√µes ocultos */
        .stButton {
            display: none !important;
        }
        
        /* Corrigir layout de m√©tricas */
        .metric-container {
            width: 100% !important;
            display: block !important;
        }
        
        /* Ajustar headers personalizados */
        .report-header {
            width: 100% !important;
            box-sizing: border-box !important;
        }
        
        /* Ajustar cards personalizados */
        .report-card {
            width: 100% !important;
            box-sizing: border-box !important;
        }
    }
    
    /* Estilo do bot√£o Consultar com hover laranja */
    .stButton > button {
        background-color: #2ca02c !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
    }
    
    .stButton > button:hover {
        background-color: #f59c00 !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(255, 127, 14, 0.3) !important;
    }
    
    /* Estilo customizado para bot√µes de IA */
    .stButton > button[kind="primary"] {
        background-color: #dc3545 !important; /* Vermelho quando desativado */
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.75rem 1.5rem !important;
        font-weight: 600 !important;
        font-size: 1rem !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 2px 8px rgba(220, 53, 69, 0.3) !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        background-color: #c82333 !important; /* Vermelho mais escuro no hover */
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(220, 53, 69, 0.4) !important;
    }
    
    .stButton > button[kind="secondary"] {
        background-color: #28a745 !important; /* Verde quando ativado */
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.75rem 1.5rem !important;
        font-weight: 600 !important;
        font-size: 1rem !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 2px 8px rgba(40, 167, 69, 0.3) !important;
    }
    
    .stButton > button[kind="secondary"]:hover {
        background-color: #218838 !important; /* Verde mais escuro no hover */
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(40, 167, 69, 0.4) !important;
    }
    
    .stButton > button:active {
        transform: translateY(0) !important;
        box-shadow: 0 2px 6px rgba(255, 127, 14, 0.2) !important;
    }
    </style>
""", unsafe_allow_html=True)

# Header estilo relat√≥rio formal com logos
st.markdown("""
    <div style="
        background: linear-gradient(135deg, #26a737, #1e7e34, #155724);
        padding: 2rem;
        border-radius: 8px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        border: 3px solid #2ca02c;
        position: relative;
    ">
        <div style="
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 1rem;
        ">
            <div style="flex: 0 0 auto; width: 180px;">
                <img src="data:image/png;base64,{}" style="max-width: 100%; height: auto; max-height: 120px;" />
            </div>
            <div style="flex: 1; text-align: center;">
                <h1 style="
                    color: white;
                    font-size: 2.5rem;
                    font-weight: 700;
                    margin: 0;
                    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
                ">Resultados SPAECE 2024</h1>
                <p style="
                    color: rgba(255,255,255,0.9);
                    font-size: 1.1rem;
                    margin: 0.5rem 0 0 0;
                    font-weight: 500;
                ">Sistema Permanente de Avalia√ß√£o da Educa√ß√£o B√°sica do Cear√°</p>
            </div>
            <div style="flex: 0 0 auto; width: 180px;">
                <img src="data:image/png;base64,{}" style="max-width: 100%; height: auto; max-height: 120px;" />
            </div>
        </div>
        <div style="
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 2px solid rgba(255,255,255,0.3);
        ">
            <p style="
                color: rgba(255,255,255,0.8);
                font-size: 0.9rem;
                margin: 0;
                font-style: italic;
            ">An√°lise de Dados Educacionais - Relat√≥rio Executivo</p>
        </div>
    </div>
""".format(
    # Logo CECOM (lado esquerdo)
    base64.b64encode(open('logo_CECOM_branco2.png', 'rb').read()).decode(),
    # Logo CREDE (lado direito)
    base64.b64encode(open('logo_CREDE_branco2.png', 'rb').read()).decode()
), unsafe_allow_html=True)

# ==================== CONSTANTES ====================

# C√≥digos de tipos de entidade no sistema SPAECE
CODIGOS_ENTIDADE = {
    'ESTADO': '01',      # Estado do Cear√°
    'CREDE': '02',       # Coordenadoria Regional de Desenvolvimento da Educa√ß√£o
    'MUNICIPIO': '11',   # Munic√≠pio
    'ESCOLA': '03'       # Escola individual
}

# ==================== FUN√á√ïES DE API ====================

def consultar_api(agregado):
    """Consulta a API SPAECE com tratamento de erros aprimorado"""
    try:
        # Validar entrada
        if not agregado or not str(agregado).strip():
            st.error("‚ùå C√≥digo da Entidade n√£o pode estar vazio")
            return None
            
        payload = criar_payload(
            indicadores=INDICADORES,
            agregado=str(agregado).strip(),
            filtros=[],
            nivel_abaixo="0"
        )
        
        response = requests.post(
            API_URL, 
            json=payload, 
            headers=HEADERS, 
            timeout=30
        )
        response.raise_for_status()
        
        # Verificar se a resposta cont√©m dados v√°lidos
        data = response.json()
        if not data:
            st.warning(f"‚ö†Ô∏è Nenhum dado retornado para o agregado {agregado}")
            return None
            
        return data
        
    except requests.exceptions.Timeout:
        st.error(f"‚è±Ô∏è Timeout ao consultar agregado {agregado}. Tente novamente.")
        return None
    except requests.exceptions.ConnectionError:
        st.error(f"üåê Erro de conex√£o. Verifique sua internet.")
        return None
    except requests.exceptions.HTTPError as e:
        st.error(f"‚ùå Erro HTTP {e.response.status_code}: {e.response.reason}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Erro na requisi√ß√£o: {str(e)}")
        return None
    except json.JSONDecodeError:
        st.error("‚ùå Erro ao decodificar resposta da API")
        return None
    except Exception as e:
        st.error(f"‚ùå Erro inesperado: {str(e)}")
        return None

# ==================== FUN√á√ïES DE PROCESSAMENTO ====================

def processar_dados(data):
    """Processa dados da API e retorna DataFrame"""
    if not data:
        st.warning("‚ö†Ô∏è Nenhum dado fornecido para processamento")
        return None
        
    try:
        if isinstance(data, dict):
            if 'result' in data and data['result']:
                df = pd.DataFrame(data['result'])
            elif 'data' in data and data['data']:
                df = pd.DataFrame(data['data'])
            elif 'results' in data and data['results']:
                df = pd.DataFrame(data['results'])
            else:
                # Tentar normalizar dados aninhados
                df = pd.json_normalize(data)
        elif isinstance(data, list) and data:
            df = pd.DataFrame(data)
        else:
            st.warning("‚ö†Ô∏è Formato de dados n√£o suportado")
            return None
            
        if df.empty:
            st.warning("‚ö†Ô∏è DataFrame vazio ap√≥s processamento")
            return None
            
        return df
        
    except pd.errors.EmptyDataError:
        st.warning("‚ö†Ô∏è Dados vazios recebidos da API")
        return None
    except pd.errors.ParserError as e:
        st.error(f"‚ùå Erro ao processar dados: {str(e)}")
        return None
    except Exception as e:
        st.error(f"‚ùå Erro inesperado ao processar dados: {str(e)}")
        return None

def converter_para_numerico(df, colunas):
    """Converte colunas para formato num√©rico com tratamento robusto"""
    if df is None or df.empty:
        return df
        
    for col in colunas:
        if col in df.columns:
            try:
                # Substituir valores inv√°lidos por NaN
                df[col] = df[col].replace(['-', 'N/A', 'n/a', '', 'NULL', 'null', 'None'], pd.NA).infer_objects(copy=False)
                
                # Limpar strings se for coluna de texto
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.strip()
                    # Substituir strings vazias por NaN
                    df[col] = df[col].replace('', pd.NA).infer_objects(copy=False)
                
                # Converter para num√©rico
                df[col] = pd.to_numeric(df[col], errors='coerce')
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao converter coluna '{col}': {str(e)}")
                continue
                
    return df

def extrair_agregados_hierarquia(df):
    """Extrai c√≥digos de agregados da coluna DC_HIERARQUIA"""
    if 'DC_HIERARQUIA' not in df.columns:
        return []
    
    agregados = set()
    for valor in df['DC_HIERARQUIA'].dropna():
        if isinstance(valor, str):
            codigos = valor.split('/')
            agregados.update([cod.strip() for cod in codigos if cod.strip()])
    
    return sorted(list(agregados))

def obter_nome_entidade(df):
    """Obt√©m o nome da entidade da coluna NM_ENTIDADE"""
    if 'NM_ENTIDADE' in df.columns and not df['NM_ENTIDADE'].empty:
        nome = df['NM_ENTIDADE'].iloc[0]
        if pd.notna(nome):
            return str(nome)
    return None

def obter_tipo_entidade(df):
    """Obt√©m o tipo da entidade da coluna DC_TIPO_ENTIDADE"""
    if 'DC_TIPO_ENTIDADE' in df.columns and not df['DC_TIPO_ENTIDADE'].empty:
        tipo = df['DC_TIPO_ENTIDADE'].iloc[0]
        if pd.notna(tipo):
            return str(tipo).upper()
    return None

# ==================== FUN√á√ïES DE VISUALIZA√á√ÉO ====================

def criar_card_entidade(titulo):
    """Cria um card HTML para exibir t√≠tulo de entidade"""
    return f"""
        <div style="
            border: 3px solid {COR_PRIMARIA};
            border-radius: 15px;
            padding: 20px 20px 5px 20px;
            background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
            height: 120px;
            display: flex;
            flex-direction: column;
        ">
            <h3 style="
                text-align: center;
                color: #26a737;
                font-size: 1.4em;
                font-weight: bold;
                margin: 0 0 10px 0;
                padding-bottom: 10px;
                border-bottom: 3px solid {COR_PRIMARIA};
            ">{titulo}</h3>
        </div>
    """

def obter_proficiencia_media(df, codigo_tipo, coluna='Profici√™ncia M√©dia'):
    """Obt√©m a profici√™ncia m√©dia para um tipo de entidade"""
    if df is None or df.empty:
        return None
    try:
        return df[df['Tipo de Entidade'].str.contains(codigo_tipo, case=False, na=False)][coluna].mean()
    except:
        return None

def aplicar_substituicoes(df):
    """Aplica substitui√ß√µes padronizadas nas colunas do DataFrame"""
    if df is None or df.empty:
        return df
        
    # Substitui√ß√µes para disciplina
    if 'VL_FILTRO_DISCIPLINA' in df.columns:
        df['VL_FILTRO_DISCIPLINA'] = df['VL_FILTRO_DISCIPLINA'].replace({
            'LP': 'L√≠ngua Portuguesa',
            'MT': 'Matem√°tica'
        })
    
    # Substitui√ß√µes para rede
    if 'VL_FILTRO_REDE' in df.columns:
        df['VL_FILTRO_REDE'] = df['VL_FILTRO_REDE'].replace({
            'ESTADUAL': 'Estadual',
            'MUNICIPAL': 'Municipal',
            'PUBLICA': 'P√∫blica',
            'P√öBLICA': 'P√∫blica'
        })
    
    # Substitui√ß√µes para etapa
    if 'VL_FILTRO_ETAPA' in df.columns:
        df['VL_FILTRO_ETAPA'] = df['VL_FILTRO_ETAPA'].replace({
            'ENSINO FUNDAMENTAL DE 9 ANOS - 2¬∫ ANO': '2¬∫ Ano - Fundamental',
            'ENSINO FUNDAMENTAL DE 9 ANOS - 5¬∫ ANO': '5¬∫ Ano - Fundamental',
            'ENSINO FUNDAMENTAL DE 9 ANOS - 9¬∫ ANO': '9¬∫ Ano - Fundamental',
            'ENSINO MEDIO - 3¬™ SERIE': '3¬™ S√©rie - M√©dio',
            'EJA DO ENSINO MEDIO - 3¬™ S√âRIE': '3¬™ S√©rie - M√©dio EJA',
            'ENSINO MEDIO - 2¬™ SERIE': '2¬™ S√©rie - M√©dio'
        })
    
    # Substitui√ß√µes para tipo de entidade
    if 'DC_TIPO_ENTIDADE' in df.columns:
        df['DC_TIPO_ENTIDADE'] = df['DC_TIPO_ENTIDADE'].replace({
            'ESTADO': 'Cear√°',
            'REGIONAL': 'CREDE',
            'MUNICIPIO': 'Munic√≠pio',
            'ESCOLA': 'Escola'
        })
    
    return df

def criar_grafico_proficiencia(df, titulo, codigo_tipo, key_suffix):
    """
    Cria gr√°fico de profici√™ncia m√©dia com cards e banners coloridos
    """
    if df.empty:
        st.warning("‚ùå Nenhum dado dispon√≠vel para profici√™ncia")
        return
    
    # Obter profici√™ncia m√©dia
    prof_500 = obter_proficiencia_media(df, codigo_tipo, 'Profici√™ncia M√©dia 500')
    prof_1000 = obter_proficiencia_media(df, codigo_tipo, 'Profici√™ncia M√©dia 1000')
    
    # Criar cards de profici√™ncia
    col1, col2 = st.columns(2)
    
    with col1:
        if not pd.isna(prof_500):
            st.metric("Profici√™ncia 500", f"{prof_500:.0f}" if not pd.isna(prof_500) else "N/A", label_visibility="collapsed")
        
        with col2:
            if not pd.isna(prof_1000):
                st.metric("Profici√™ncia 1000", f"{prof_1000:.0f}", label_visibility="collapsed")
            else:
                st.markdown("""
                <div style="
                    background: linear-gradient(135deg, #ff6b35, #f7931e);
                    color: white;
                    padding: 10px;
                    border-radius: 8px;
                    text-align: center;
                    font-weight: bold;
                    margin-bottom: 4px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
                ">
                    üìä Escala 0-1000<br>
                    <span style="font-size: 12px;">Dados n√£o dispon√≠veis<br>para esta etapa</span>
                </div>
                """, unsafe_allow_html=True)

def criar_grafico_padrao_desempenho(df, titulo, codigo_tipo, key_suffix):
    """
    Cria gr√°fico de padr√£o de desempenho
    """
    if df.empty:
        st.warning("‚ùå Nenhum dado dispon√≠vel para padr√£o de desempenho")
        return
    
    # Colunas de padr√£o de desempenho
    colunas_desempenho = [col for col in df.columns if 'Padr√£o' in col or 'Desempenho' in col]
    
    if not colunas_desempenho:
        st.warning("‚ùå Nenhuma coluna de padr√£o de desempenho encontrada")
        return
    
    # Criar gr√°fico de barras
    dados_grafico = []
    for col in colunas_desempenho:
        if col in df.columns:
            valor = df[col].iloc[0] if not df.empty else 0
            dados_grafico.append({
                'Categoria': col.replace('Padr√£o ', '').replace('Desempenho ', ''),
                'Valor': valor
            })
    
    if dados_grafico:
        df_grafico = pd.DataFrame(dados_grafico)
        fig = px.bar(df_grafico, x='Categoria', y='Valor', 
                    title=f"Distribui√ß√£o por Padr√£o de Desempenho - {titulo}",
                    color='Valor',
                    color_continuous_scale=['#e06a0c', '#f59c00', '#26a737'])
        
        fig.update_layout(
            showlegend=False,
            height=400,
            margin=dict(l=10, r=10, t=40, b=10),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)'
        )
        
        st.plotly_chart(fig, use_container_width=True, key=f"desempenho_{key_suffix}")

def criar_grafico_habilidades(df, titulo, codigo_tipo, key_suffix):
    """
    Cria gr√°fico de habilidades
    """
    if df.empty:
        st.warning("‚ùå Nenhum dado dispon√≠vel para habilidades")
        return
    
    # Colunas de habilidades
    colunas_habilidade = [col for col in df.columns if 'Habilidade' in col or 'Taxa' in col]
    
    if not colunas_habilidade:
        st.warning("‚ùå Nenhuma coluna de habilidade encontrada")
        return
    
    # Criar gr√°fico de barras
    dados_grafico = []
    for col in colunas_habilidade:
        if col in df.columns:
            valor = df[col].iloc[0] if not df.empty else 0
            dados_grafico.append({
                'Habilidade': col.replace('Taxa ', '').replace('Habilidade ', ''),
                'Taxa_Acerto': valor
            })
    
    if dados_grafico:
        df_grafico = pd.DataFrame(dados_grafico)
        fig = px.bar(df_grafico, x='Habilidade', y='Taxa_Acerto', 
                    title=f"Taxa de Acerto por Habilidade - {titulo}",
                    color='Taxa_Acerto',
                    color_continuous_scale=['#e06a0c', '#f59c00', '#26a737'])
        
        fig.update_layout(
            showlegend=False,
            height=400,
            margin=dict(l=10, r=10, t=40, b=10),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)'
        )
        
        st.plotly_chart(fig, use_container_width=True, key=f"habilidades_{key_suffix}")

def criar_gauge_participacao(df, titulo, codigo_tipo, key_suffix):
    """
    Cria um gauge de participa√ß√£o para um tipo espec√≠fico de entidade dentro de um card
    
    Args:
        df: DataFrame com dados de participa√ß√£o
        titulo: T√≠tulo do gauge
        codigo_tipo: C√≥digo para filtrar o tipo de entidade
        key_suffix: Sufixo para chave √∫nica do plotly
    """
    if df.empty:
        st.info("Sem dados de participa√ß√£o dispon√≠veis")
        return
    
    # Filtrar dados do tipo espec√≠fico
    dados_filtrados = df[df['Tipo de Entidade'].str.contains(codigo_tipo, case=False, na=False)]
    
    if dados_filtrados.empty:
        st.info(f"Sem dados de {titulo} para exibir")
        return
    
    # Encontrar a linha com o maior valor de participa√ß√£o
    idx_max_participacao = dados_filtrados['Participa√ß√£o'].idxmax()
    linha_max_participacao = dados_filtrados.loc[idx_max_participacao]
    
    # Pegar valores da linha com maior participa√ß√£o
    participacao_maxima = linha_max_participacao['Participa√ß√£o']
    total_previstos = linha_max_participacao['Alunos Previstos']
    total_efetivos = linha_max_participacao['Alunos Efetivos']
    
    # Card com altura fixa
    st.markdown(f"""
        <div style="
            border: 3px solid {COR_PRIMARIA};
            border-radius: 15px;
            padding: 20px 20px 5px 20px;
            background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
            height: 120px;
            display: flex;
            flex-direction: column;
        ">
            <h3 style="
                text-align: center;
                color: #26a737;
                font-size: 1.4em;
                font-weight: bold;
                margin: 0 0 10px 0;
                padding-bottom: 10px;
                border-bottom: 3px solid {COR_PRIMARIA};
            ">{titulo}</h3>
        </div>
    """, unsafe_allow_html=True)
    
    # Criar gauge
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=participacao_maxima,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': "", 'font': {'size': 14, 'color': COR_PRIMARIA}},
        number={'suffix': "%", 'font': {'size': 24}},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': COR_PRIMARIA},
            'steps': [
                {'range': [0, 80], 'color': "#ffcccc"},
                {'range': [80, 90], 'color': "#ffff99"},
                {'range': [90, 100], 'color': "#ccffcc"}
            ],
            'threshold': {
                'line': {'color': "black", 'width': 4},
                'thickness': 0.75,
                'value': participacao_maxima,
            }
        }
    ))
    
    fig.update_layout(
        height=150,
        margin=dict(l=10, r=10, t=30, b=5),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
                        font=dict(size=14)
    )
    st.plotly_chart(fig, use_container_width=True, key=f"gauge_{key_suffix}")
    
    # M√©tricas de alunos
    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            label="üë• Previstos", 
            value=f"{int(total_previstos):,}".replace(',', 'X').replace('.', ',').replace('X', '.')
        )
    with col2:
        st.metric(
            label="‚úÖ Efetivos", 
            value=f"{int(total_efetivos):,}".replace(',', 'X').replace('.', ',').replace('X', '.')
        )

# ==================== INICIALIZA√á√ÉO DO SESSION STATE ====================

if 'df_concatenado' not in st.session_state:
    st.session_state.df_concatenado = None
if 'agregado_consultado' not in st.session_state:
    st.session_state.agregado_consultado = None

# ==================== SISTEMA DE AUTENTICA√á√ÉO ====================

# Inicializar session state para autentica√ß√£o
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
if 'user_code' not in st.session_state:
    st.session_state.user_code = None

# Interface de Login
if not st.session_state.authenticated:
    st.markdown("### üîê Sistema de Autentica√ß√£o SPAECE")
    
    # CSS customizado para bot√µes laranja #ff7100 (aplicado globalmente)
    st.markdown("""
    <style>
    .stButton > button[kind="secondary"] {
        background: linear-gradient(135deg, #e94f0e, #f59c00) !important;
        color: white !important;
        border: 3px solid #e94f0e !important;
        border-radius: 8px !important;
        font-weight: 700 !important;
        transition: all 0.3s ease !important;
        font-size: 1.1rem !important;
        text-shadow: 0 1px 2px rgba(0,0,0,0.3) !important;
        box-shadow: 0 3px 6px rgba(255, 113, 0, 0.4) !important;
    }
    .stButton > button[kind="secondary"]:hover {
        background: linear-gradient(135deg, #e06a0c, #e94f0e) !important;
        border-color: #e06a0c !important;
        transform: translateY(-3px) !important;
        box-shadow: 0 6px 12px rgba(255, 113, 0, 0.6) !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    with st.form("login_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            codigo = st.text_input("üè¢ C√≥digo da Entidade", placeholder="Ex: 23, 230010, 230020...", help="Digite o c√≥digo da entidade que deseja consultar, ou use a senha mestra para acessar todos os dados")
        
        with col2:
            senha = st.text_input("üîë Senha", type="password", placeholder="Digite a senha da entidade")
        
        # Sele√ß√£o de rede
        rede_selecionada = st.selectbox(
            "üè´ Rede de Ensino", 
            ["Selecione uma rede...", "Estadual", "Municipal"],
            index=0,
            help="Selecione a rede de ensino para filtrar os dados"
        )
        
        submitted = st.form_submit_button("üöÄ Fazer Login e Consultar", type="secondary")
        
        if submitted:
            if not codigo or not senha:
                st.error("‚ùå Por favor, preencha todos os campos")
            elif rede_selecionada == "Selecione uma rede...":
                st.error("‚ùå Por favor, selecione uma rede de ensino")
            elif not codigo.isdigit():
                st.error("‚ùå O c√≥digo da entidade deve conter apenas n√∫meros")
            elif len(codigo) < 2:
                st.error("‚ùå O c√≥digo da entidade deve ter pelo menos 2 d√≠gitos")
            elif codigo not in PASSWORDS and senha != MASTER_PASSWORD:
                st.error("‚ùå C√≥digo da entidade n√£o encontrado")
            elif PASSWORDS.get(codigo) != senha and senha != MASTER_PASSWORD:
                st.error("‚ùå Senha incorreta")
            else:
                # Login bem-sucedido
                st.session_state.authenticated = True
                st.session_state.user_code = codigo
                st.session_state.rede_selecionada_login = rede_selecionada
                
                # Verificar se √© senha mestra e armazenar no session_state
                if senha == MASTER_PASSWORD:
                    st.session_state.master_access = True
                    st.success(f"‚úÖ Login realizado com sucesso usando **SENHA MESTRA** para: **{ENTITY_NAMES.get(codigo, f'Entidade {codigo}')}** - Rede: **{rede_selecionada}**")
                else:
                    st.session_state.master_access = False
                    st.success(f"‚úÖ Login realizado com sucesso para: **{ENTITY_NAMES.get(codigo, f'Entidade {codigo}')}** - Rede: **{rede_selecionada}**")
                st.rerun()
    
   
else:
    # Usu√°rio autenticado - mostrar interface principal
    codigo = st.session_state.user_code
    nome_entidade = ENTITY_NAMES.get(codigo, f"Entidade {codigo}")
    
    # Bot√£o de logout
    col1, col2 = st.columns([4, 1])
    with col1:
        rede_atual = st.session_state.get('rede_selecionada_login', 'N√£o definida')
        st.success(f"‚úÖ Logado como: **{nome_entidade}** (C√≥digo: {codigo}) - Rede: **{rede_atual}**")
    with col2:
        # CSS para bot√£o Sair laranja
        st.markdown("""
        <style>
        div[data-testid="stButton"] button[kind="secondary"] {
            background-color: #ff6b35 !important;
            color: white !important;
            border: none !important;
        }
        div[data-testid="stButton"] button[kind="secondary"]:hover {
            background-color: #e55a2b !important;
            color: white !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        if st.button("üö™ Sair", type="secondary"):
            st.session_state.authenticated = False
            st.session_state.user_code = None
            st.session_state.agregado_consultado = None
            st.session_state.df_concatenado = None
            st.rerun()
    
    # Consulta autom√°tica usando o c√≥digo do login
    agregado = codigo
    
    # Fazer consulta automaticamente
    if st.session_state.agregado_consultado != agregado:
        with st.spinner(f"üîÑ Consultando dados da entidade {agregado}..."):
            # Lista para armazenar todos os dataframes
            lista_dfs = []
            
            # Consulta inicial
            data = consultar_api(agregado)
            if data:
                df = processar_dados(data)
                if df is not None:
                    # Adicionar coluna identificadora do agregado
                    df['AGREGADO_ORIGEM'] = agregado
                    lista_dfs.append(df)
                    
                    # L√ìGICA ESPECIAL PARA SENHA MESTRA: Consultar dados mais amplos
                    if st.session_state.get('master_access', False):
                        st.info("üîë **Acesso Administrativo:** Consultando dados ampliados...")
                        
                        # Para senha mestra, consultar tamb√©m o estado completo (23)
                        if agregado != "23":
                            st.write("üìä Consultando dados do Estado do Cear√° (23)...")
                            data_estado = consultar_api("23")
                            if data_estado:
                                df_estado = processar_dados(data_estado)
                                if df_estado is not None:
                                    df_estado['AGREGADO_ORIGEM'] = "23"
                                    lista_dfs.append(df_estado)
                        
                        # Consultar todas as CREDEs se for uma consulta estadual ou regional
                        if len(agregado) <= 2 or agregado == "23":
                            credes_para_consultar = ["230010", "230020", "230030", "230040", "230050", 
                                                    "230060", "230070", "230080", "230090", "230100", 
                                                    "230110", "230120", "230130", "230140", "230150", 
                                                    "230160", "230170", "230180", "230190", "230200"]
                            
                            for crede in credes_para_consultar:
                                st.write(f"üìä Consultando CREDE {crede}...")
                                data_crede = consultar_api(crede)
                                if data_crede:
                                    df_crede = processar_dados(data_crede)
                                    if df_crede is not None:
                                        df_crede['AGREGADO_ORIGEM'] = crede
                                        lista_dfs.append(df_crede)
                        
                        # Consultar munic√≠pios principais se for uma consulta estadual
                        if agregado == "23" or len(agregado) <= 2:
                            municipios_principais = ["2301000", "2303709", "2304285", "2304954", 
                                                   "2306256", "2307650", "2307700", "2309706"]
                            
                            for municipio in municipios_principais:
                                st.write(f"üìä Consultando Munic√≠pio {municipio}...")
                                data_municipio = consultar_api(municipio)
                                if data_municipio:
                                    df_municipio = processar_dados(data_municipio)
                                    if df_municipio is not None:
                                        df_municipio['AGREGADO_ORIGEM'] = municipio
                                        lista_dfs.append(df_municipio)
                        
                        # EXTRAIR AGREGADOS DA HIERARQUIA PARA SENHA MESTRA TAMB√âM
                        st.write("üìä Extraindo c√≥digos da hierarquia...")
                        agregados_hierarquia = []
                        if len(agregado) > 2:
                            agregados_hierarquia = extrair_agregados_hierarquia(df)
                            agregados_hierarquia = [ag for ag in agregados_hierarquia if ag != agregado]
                        
                        # Consultar agregados da hierarquia para senha mestra
                        if agregados_hierarquia:
                            st.write(f"üìä Encontrados {len(agregados_hierarquia)} c√≥digos na hierarquia")
                            for ag_hierarquia in agregados_hierarquia:
                                st.write(f"üìä Consultando hierarquia {ag_hierarquia}...")
                                data_hierarquia = consultar_api(ag_hierarquia)
                                if data_hierarquia:
                                    df_hierarquia = processar_dados(data_hierarquia)
                                    if df_hierarquia is not None:
                                        df_hierarquia['AGREGADO_ORIGEM'] = ag_hierarquia
                                        lista_dfs.append(df_hierarquia)
                    
                    # Extrair agregados da hierarquia (sem exibir) - apenas para usu√°rios normais
                    else:
                        agregados_hierarquia = []
                        if len(agregado) > 2:
                            agregados_hierarquia = extrair_agregados_hierarquia(df)
                            agregados_hierarquia = [ag for ag in agregados_hierarquia if ag != agregado]
                        
                        # Consultar agregados da hierarquia silenciosamente
                        if agregados_hierarquia:
                            for ag_hierarquia in agregados_hierarquia:
                                data_hierarquia = consultar_api(ag_hierarquia)
                                if data_hierarquia:
                                    df_hierarquia = processar_dados(data_hierarquia)
                                    if df_hierarquia is not None:
                                        df_hierarquia['AGREGADO_ORIGEM'] = ag_hierarquia
                                        lista_dfs.append(df_hierarquia)
                    
                    # Criar dataframe concatenado (sem exibir)
                    if len(lista_dfs) == 1:
                        df_unico = lista_dfs[0].copy()
                        df_unico = aplicar_substituicoes(df_unico)
                        st.session_state.df_concatenado = df_unico
                        st.session_state.agregado_consultado = agregado
                    elif len(lista_dfs) > 1:
                        df_concatenado = pd.concat(lista_dfs, ignore_index=True)
                        df_concatenado = aplicar_substituicoes(df_concatenado)
                        st.session_state.df_concatenado = df_concatenado
                        st.session_state.agregado_consultado = agregado
                    
                    # Calcular total de registros
                    total_registros = sum(len(df) for df in lista_dfs)
                    st.success(f"‚úÖ Dados carregados: {total_registros} registros (incluindo hierarquia)")
                    
                    # Op√ß√£o de download do df_concatenado para usu√°rios com senha mestra
                    if st.session_state.get('master_access', False):
                        st.info("üîë **Acesso Administrativo:** Voc√™ pode baixar o dataset completo")
                        csv_data = st.session_state.df_concatenado.to_csv(index=False)
                        st.download_button(
                            label="üì• Baixar Dataset Completo (df_concatenado)",
                            data=csv_data,
                            file_name=f"spaece_dataset_completo_{codigo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            key="download_dataset_completo"
                        )
                else:
                    st.error("‚ùå Erro ao processar dados")
            else:
                st.warning("‚ö†Ô∏è Nenhum dado retornado pela API")
    
    # Verificar se h√° dados para exibir
    if st.session_state.df_concatenado is not None:
        # ==================== SE√á√ÉO DE AN√ÅLISE ====================
        df_concat = st.session_state.df_concatenado.copy()
        
        # Aplicar substitui√ß√µes para padronizar os nomes
        df_concat = aplicar_substituicoes(df_concat)
        
        
        # Header estilo relat√≥rio formal para an√°lise dos dados
        st.markdown("""
        <div class="report-header" style="font-size: 2rem; text-align: left; background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
            üìä AN√ÅLISE DOS DADOS
        </div>


        """, unsafe_allow_html=True)
        
        # ==================== INFORMA√á√ïES DA ENTIDADE ====================
        st.markdown("---")
        
        # Exibir informa√ß√µes da entidade consultada
        entidade_info = []
        
        # Verificar e adicionar nome da entidade principal
        if 'NM_ENTIDADE' in df_concat.columns and not df_concat.empty:
            entidade_nome = df_concat['NM_ENTIDADE'].iloc[0]
            if pd.notna(entidade_nome) and str(entidade_nome).strip():
                entidade_info.append(f"Entidade: {entidade_nome}")
        
        # Verificar e adicionar informa√ß√µes do munic√≠pio
        if 'NM_MUNICIPIO' in df_concat.columns and not df_concat.empty:
            municipio = df_concat['NM_MUNICIPIO'].iloc[0]
            if pd.notna(municipio) and str(municipio).strip():
                entidade_info.append(f"Munic√≠pio: {municipio}")
        
        # Verificar e adicionar informa√ß√µes da CREDE
        if 'NM_REGIONAL' in df_concat.columns and not df_concat.empty:
            crede = df_concat['NM_REGIONAL'].iloc[0]
            if pd.notna(crede) and str(crede).strip():
                entidade_info.append(f"CREDE: {crede}")
        
        # Verificar e adicionar informa√ß√µes do estado
        if 'NM_ESTADO' in df_concat.columns and not df_concat.empty:
            estado = df_concat['NM_ESTADO'].iloc[0]
            if pd.notna(estado) and str(estado).strip():
                entidade_info.append(f"Estado: {estado}")
        
        # Exibir as informa√ß√µes se existirem, sen√£o mostrar C√≥digo da Entidade
        if entidade_info:
            # Card estilo relat√≥rio formal para informa√ß√µes da entidade
            # Criar o HTML com as informa√ß√µes da entidade
            entidade_html = "<br>".join(entidade_info)
            st.markdown(f"""
            <div class="report-card">
                <div class="report-card-header">
                    üèõÔ∏è INFORMA√á√ïES DA ENTIDADE
                </div>
                <div style="
                    font-size: 1rem;
                    line-height: 1.8;
                    color: #374151;
                    font-weight: 500;
                ">
                    {entidade_html}
                </div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="report-card">
                <div class="report-card-header" style="border-bottom-color: #46ac33;">
                    üèõÔ∏è ENTIDADE CONSULTADA
                </div>
                <div style="
                    font-size: 1rem;
                    line-height: 1.8;
                    color: #4b5563;
                    font-weight: 500;
                ">
                    <strong>C√≥digo:</strong> {st.session_state.agregado_consultado}
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # # ==================== ESTAT√çSTICAS GERAIS ====================
    # with st.expander("üìà Estat√≠sticas Gerais", expanded=False):
    #     col1, col2, col3, col4 = st.columns(4)
    #     with col1:
    #         st.metric("Total de Registros", f"{len(df_concat):,}".replace(',', '.'))
    #     with col2:
    #         if 'VL_FILTRO_DISCIPLINA' in df_concat.columns:
    #             st.metric("Componentes", df_concat['VL_FILTRO_DISCIPLINA'].nunique())
    #     with col3:
    #         if 'VL_FILTRO_ETAPA' in df_concat.columns:
    #             st.metric("Etapas", df_concat['VL_FILTRO_ETAPA'].nunique())
    #     with col4:
    #         if 'NM_ENTIDADE' in df_concat.columns:
    #             st.metric("Entidades", df_concat['NM_ENTIDADE'].nunique())
    
    # Filtrar por entidade se for consulta de n√≠vel estadual
    agregado_original = st.session_state.agregado_consultado
    if agregado_original and len(agregado_original) == 2:
        if 'CD_ENTIDADE' in df_concat.columns:
            df_concat = df_concat[df_concat['CD_ENTIDADE'] == agregado_original].copy()
            nome_estado = df_concat['NM_ENTIDADE'].iloc[0] if 'NM_ENTIDADE' in df_concat.columns and len(df_concat) > 0 else agregado_original
            st.info(f"üéØ Exibindo apenas dados da entidade: **{nome_estado}**")
    
    # Sidebar estilo relat√≥rio formal
    with st.sidebar:
        # Imagem do painel CECOM no topo do sidebar
        st.image("painel_cecom.png", width=300)
        
        # Card estilo relat√≥rio formal para informa√ß√µes da entidade no sidebar
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #26a737, #1e7e34, #155724);
            padding: 1rem;
            border-radius: 6px;
            margin-bottom: 1rem;
            color: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            border: 2px solid #2ca02c;
        ">
            <h3 style="
                margin: 0;
                font-size: 1rem;
                font-weight: 700;
                text-align: center;
            ">üèõÔ∏è INFORMA√á√ïES DA ENTIDADE</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Verificar e exibir informa√ß√µes da entidade
        sidebar_info = []
        
        # Verificar e adicionar nome da entidade principal
        if 'NM_ENTIDADE' in df_concat.columns and not df_concat.empty:
            entidade_nome = df_concat['NM_ENTIDADE'].iloc[0]
            if pd.notna(entidade_nome) and str(entidade_nome).strip():
                sidebar_info.append(f"Entidade: {entidade_nome}")
        
        # Verificar e adicionar informa√ß√µes do munic√≠pio
        if 'NM_MUNICIPIO' in df_concat.columns and not df_concat.empty:
            municipio = df_concat['NM_MUNICIPIO'].iloc[0]
            if pd.notna(municipio) and str(municipio).strip():
                sidebar_info.append(f"Munic√≠pio: {municipio}")
        
        # Verificar e adicionar informa√ß√µes da CREDE
        if 'NM_REGIONAL' in df_concat.columns and not df_concat.empty:
            crede = df_concat['NM_REGIONAL'].iloc[0]
            if pd.notna(crede) and str(crede).strip():
                sidebar_info.append(f"CREDE: {crede}")
        
        # Verificar e adicionar informa√ß√µes do estado
        if 'NM_ESTADO' in df_concat.columns and not df_concat.empty:
            estado = df_concat['NM_ESTADO'].iloc[0]
            if pd.notna(estado) and str(estado).strip():
                sidebar_info.append(f"Estado: {estado}")
        
        # Exibir as informa√ß√µes no sidebar com estilo relat√≥rio formal
        if sidebar_info:
            for info in sidebar_info:
                st.markdown(f"""
                <div style="
                    background: white;
                    padding: 0.6rem;
                    margin: 0.3rem 0;
                    border-radius: 4px;
                    border-left: 3px solid #2ca02c;
                    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
                    font-size: 0.8rem;
                    border: 1px solid #e5e7eb;
                ">{info}</div>
                """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div style="
                background: white;
                padding: 0.6rem;
                margin: 0.3rem 0;
                border-radius: 4px;
                border-left: 3px solid #6b7280;
                box-shadow: 0 1px 2px rgba(0,0,0,0.1);
                font-size: 0.8rem;
                border: 1px solid #e5e7eb;
            ">**C√≥digo:** {st.session_state.agregado_consultado}</div>
            """, unsafe_allow_html=True)
        
        # Header estilo relat√≥rio formal para filtros
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #26a737, #1e7e34, #155724);
            padding: 0.8rem;
            border-radius: 4px;
            margin: 1rem 0;
            text-align: center;
            border: 2px solid #2ca02c;
        ">
            <h3 style="
                margin: 0;
                color: white;
                font-size: 0.9rem;
                font-weight: 700;
            ">üîç FILTROS</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Filtro de Etapa - Din√¢mico baseado na coluna VL_FILTRO_ETAPA
        if 'VL_FILTRO_ETAPA' in df_concat.columns:
            # Filtrar etapas apenas da entidade consultada
            df_etapas_entidade = df_concat.copy()
            
            # Se h√° uma entidade espec√≠fica consultada, filtrar por ela
            agregado_original = st.session_state.agregado_consultado
            if agregado_original and 'CD_ENTIDADE' in df_concat.columns:
                df_etapas_entidade = df_etapas_entidade[df_etapas_entidade['CD_ENTIDADE'] == agregado_original]
            
            # Obter etapas √∫nicas apenas da entidade consultada
            etapas_unicas = df_etapas_entidade['VL_FILTRO_ETAPA'].unique()
            etapas_unicas = [e for e in etapas_unicas if pd.notna(e)]  # Remove NaN
            etapas_unicas = [str(e).strip() for e in etapas_unicas if str(e).strip()]  # Remove espa√ßos e valores vazios
            
            # Ordenar etapas de forma l√≥gica (Educa√ß√£o Infantil -> Fundamental -> M√©dio)
            ordem_etapas = {
                'EDUCA√á√ÉO INFANTIL': 1,
                'EDUCA√á√ÉO INFANTIL - PR√â-ESCOLA': 2,
                'ENSINO FUNDAMENTAL': 3,
                'ENSINO FUNDAMENTAL - ANOS INICIAIS': 4,
                'ENSINO FUNDAMENTAL - 1¬∫ ANO': 5,
                'ENSINO FUNDAMENTAL - 2¬∫ ANO': 6,
                'ENSINO FUNDAMENTAL - 3¬∫ ANO': 7,
                'ENSINO FUNDAMENTAL - 4¬∫ ANO': 8,
                'ENSINO FUNDAMENTAL - 5¬∫ ANO': 9,
                'ENSINO FUNDAMENTAL - ANOS FINAIS': 10,
                'ENSINO FUNDAMENTAL - 6¬∫ ANO': 11,
                'ENSINO FUNDAMENTAL - 7¬∫ ANO': 12,
                'ENSINO FUNDAMENTAL - 8¬∫ ANO': 13,
                'ENSINO FUNDAMENTAL - 9¬∫ ANO': 14,
                'ENSINO M√âDIO': 15,
                'ENSINO M√âDIO - 1¬™ S√âRIE': 16,
                'ENSINO M√âDIO - 2¬™ S√âRIE': 17,
                'ENSINO M√âDIO - 3¬™ S√âRIE': 18,
                'EJA': 19,
                'EJA DO ENSINO FUNDAMENTAL': 20,
                'EJA DO ENSINO M√âDIO': 21,
                'EJA DO ENSINO M√âDIO - 1¬™ S√âRIE': 22,
                'EJA DO ENSINO M√âDIO - 2¬™ S√âRIE': 23,
                'EJA DO ENSINO M√âDIO - 3¬™ S√âRIE': 24
            }
            
            # Ordenar etapas usando a ordem definida
            etapas_ordenadas = sorted(etapas_unicas, key=lambda x: ordem_etapas.get(x.upper(), 999))
            
            # Remover etapas espec√≠ficas do seletor (se necess√°rio)
            etapas_remover = [
                'ENSINO M√âDIO - 2¬™ S√âRIE',
                'ENSINO M√âDIO - 3¬™ S√âRIE', 
                'EJA DO ENSINO M√âDIO - 3¬™ S√âRIE'
            ]
            etapas_finais = [e for e in etapas_ordenadas if e.upper() not in [r.upper() for r in etapas_remover]]
            
            if len(etapas_finais) > 0:
                # Definir √≠ndice padr√£o (primeira etapa)
                default_index = 0
                
                etapa_selecionada = st.selectbox(
                    "üìö Selecione a Etapa de Ensino", 
                    etapas_finais, 
                    index=default_index,
                    key="etapa_selecionada",
                    help="Selecione uma etapa espec√≠fica de ensino"
                )
                
                # Aplicar filtro
                if etapa_selecionada:
                    df_concat = df_concat[df_concat['VL_FILTRO_ETAPA'] == etapa_selecionada]
                    st.session_state.etapa_filtro_aplicado = etapa_selecionada
                    st.info(f"üîç **Filtro aplicado:** {etapa_selecionada}")
            else:
                st.warning("‚ö†Ô∏è Nenhuma etapa encontrada na coluna VL_FILTRO_ETAPA")
        else:
            st.warning("‚ö†Ô∏è Coluna VL_FILTRO_ETAPA n√£o encontrada nos dados")
        
        # Filtro de Disciplina - Din√¢mico baseado na coluna VL_FILTRO_DISCIPLINA
        if 'VL_FILTRO_DISCIPLINA' in df_concat.columns:
            # Obter disciplinas √∫nicas da coluna VL_FILTRO_DISCIPLINA
            disciplinas_unicas = df_concat['VL_FILTRO_DISCIPLINA'].unique()
            disciplinas_unicas = [d for d in disciplinas_unicas if pd.notna(d)]  # Remove NaN
            disciplinas_unicas = [str(d).strip() for d in disciplinas_unicas if str(d).strip()]  # Remove espa√ßos e valores vazios
            
            # Ordenar disciplinas de forma l√≥gica
            ordem_disciplinas = {
                'L√çNGUA PORTUGUESA': 1,
                'L√çNGUA PORTUGUESA - ESCRITA E LEITURA': 2,
                'MATEM√ÅTICA': 3,
                'CI√äNCIAS': 4,
                'HIST√ìRIA': 5,
                'GEOGRAFIA': 6,
                'ARTES': 7,
                'EDUCA√á√ÉO F√çSICA': 8,
                'INGL√äS': 9,
                'ESPANHOL': 10,
                'FILOSOFIA': 11,
                'SOCIOLOGIA': 12,
                'F√çSICA': 13,
                'QU√çMICA': 14,
                'BIOLOGIA': 15
            }
            
            # Ordenar disciplinas usando a ordem definida
            disciplinas_ordenadas = sorted(disciplinas_unicas, key=lambda x: ordem_disciplinas.get(x.upper(), 999))
            
            if len(disciplinas_ordenadas) > 0:
                # Definir √≠ndice padr√£o (L√≠ngua Portuguesa se dispon√≠vel, sen√£o primeira disciplina)
                default_index = 0
                if "L√≠ngua Portuguesa" in disciplinas_ordenadas:
                    try:
                        default_index = disciplinas_ordenadas.index("L√≠ngua Portuguesa")
                    except ValueError:
                        default_index = 0
                elif "L√≠ngua Portuguesa - Escrita e Leitura" in disciplinas_ordenadas:
                    try:
                        default_index = disciplinas_ordenadas.index("L√≠ngua Portuguesa - Escrita e Leitura")
                    except ValueError:
                        default_index = 0
                
                disciplina_selecionada = st.selectbox(
                    "üìñ Selecione a Disciplina", 
                    disciplinas_ordenadas, 
                    index=default_index,
                    key="disciplina_selecionada",
                    help="Selecione uma disciplina espec√≠fica"
                )
                
                # Aplicar filtro
                if disciplina_selecionada:
                    df_concat = df_concat[df_concat['VL_FILTRO_DISCIPLINA'] == disciplina_selecionada]
                    st.session_state.disciplina_filtro_aplicado = disciplina_selecionada
                    st.info(f"üîç **Filtro aplicado:** {disciplina_selecionada}")
            else:
                st.warning("‚ö†Ô∏è Nenhuma disciplina encontrada na coluna VL_FILTRO_DISCIPLINA")
        else:
            st.warning("‚ö†Ô∏è Coluna VL_FILTRO_DISCIPLINA n√£o encontrada nos dados")
        
        # Aplicar filtro de rede selecionado no login
        rede_login = st.session_state.get('rede_selecionada_login', 'Estadual')
        if 'VL_FILTRO_REDE' in df_concat.columns:
            df_concat = df_concat[df_concat['VL_FILTRO_REDE'] == rede_login]
            st.info(f"üîç **Rede selecionada no login:** {rede_login}")
        else:
            st.warning("‚ö†Ô∏è Coluna VL_FILTRO_REDE n√£o encontrada nos dados")
        
        # Se√ß√£o de controle da IA
        st.markdown("---")
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #f8f9fa, #e9ecef, #dee2e6);
            padding: 1.5rem;
            border-radius: 8px;
            border-left: 4px solid #007bff;
            margin: 1rem 0;
        ">
            <h4 style="color: #007bff; margin: 0 0 1rem 0;">ü§ñ An√°lise Inteligente com IA</h4>
            <p style="margin: 0 0 1rem 0; color: #6c757d;">
                Ative as an√°lises inteligentes com IA para obter insights avan√ßados dos dados. 
                <strong>Este processo carregar√° as bases de dados (DCRC e BNCC) e pode demorar alguns minutos</strong>.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Inicializar estado da IA se n√£o existir (come√ßar desligada)
        if 'ia_ativa' not in st.session_state:
            st.session_state.ia_ativa = False
        
        col1, col2, col3 = st.columns([0.5, 3, 0.5])
        with col2:
            if st.session_state.ia_ativa:
                if st.button("ü§ñ Desativar An√°lise IA", type="secondary", use_container_width=True, 
                            help="Clique para desativar as an√°lises inteligentes com IA"):
                    st.session_state.ia_ativa = False
                    st.rerun()
            else:
                if st.button("ü§ñ Ativar An√°lise IA", type="primary", use_container_width=True,
                            help="Clique para ativar as an√°lises inteligentes com IA"):
                    # Carregar arquivos Markdown quando ativar a IA
                    try:
                        with st.spinner("üîÑ Carregando bases de dados..."):
                            # Carregar DCRC
                            with st.spinner("üîÑ Carregando DCRC..."):
                                texto_dcrc = extrair_texto_md("dcrc.md")
                            
                            # Carregar BNCC
                            with st.spinner("üîÑ Carregando BNCC..."):
                                texto_bncc = extrair_texto_md("bncc.md")
                            
                            if texto_dcrc and texto_bncc:
                                with st.spinner("ü§ñ Processando documentos com RAG..."):
                                    # Combinar textos dos dois arquivos Markdown
                                    texto_combinado = f"DCRC:\n{texto_dcrc}\n\nBNCC:\n{texto_bncc}"
                                    dados_rag = processar_md_com_rag(texto_combinado)
                                
                                if dados_rag:
                                    st.session_state.documentos_referencia = texto_combinado
                                    st.session_state.dados_rag = dados_rag
                                    st.session_state.documentos_carregados = True
                                    st.session_state.ia_ativa = True
                                    st.success("‚úÖ IA ativada com sucesso! Bases carregadas e an√°lises inteligentes habilitadas.")
                                    st.rerun()
                                else:
                                    st.error("‚ùå Erro ao processar os documentos. Tente novamente.")
                            else:
                                st.error("‚ùå Erro ao extrair texto dos PDFs. Verifique se os arquivos est√£o corretos.")
                                
                    except FileNotFoundError as e:
                        st.error(f"‚ùå Arquivo n√£o encontrado: {e}")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao carregar PDFs: {e}")
        
        # Mostrar status atual da IA
        if st.session_state.ia_ativa:
            st.markdown("""
            <div style="
                background: #e8f5e8;
                padding: 0.8rem;
                border-radius: 6px;
                border-left: 4px solid #28a745;
                margin: 1rem 0;
            ">
                <strong>‚úÖ IA Ativa:</strong> Bases carregadas e an√°lises inteligentes habilitadas
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div style="
                background: #f8f9fa;
                padding: 0.8rem;
                border-radius: 6px;
                border-left: 4px solid #6c757d;
                margin: 1rem 0;
            ">
                <strong>‚è∏Ô∏è IA Inativa:</strong> An√°lises inteligentes desabilitadas
            </div>
            """, unsafe_allow_html=True)
    
    # ==================== TAXA DE PARTICIPA√á√ÉO ====================
    colunas_participacao = ['TP_ENTIDADE','NM_ENTIDADE','QT_ALUNO_PREVISTO','QT_ALUNO_EFETIVO', 
                           'TX_PARTICIPACAO', 'VL_FILTRO_DISCIPLINA','VL_FILTRO_ETAPA']
    
    if not df_concat.empty and all(col in df_concat.columns for col in colunas_participacao):
        df_participacao = df_concat[colunas_participacao].dropna().copy()
        df_participacao = df_participacao[df_participacao['VL_FILTRO_DISCIPLINA'] != 'L√≠ngua Portuguesa - Escrita e Leitura']
        df_participacao.columns = ['Tipo de Entidade', 'Entidade', 'Alunos Previstos', 'Alunos Efetivos', 
                                   'Participa√ß√£o', 'Componente Curricular', 'Etapa']
        
        # S√≥ aplicar quebra de p√°gina se houver dados v√°lidos ap√≥s processamento
        if not df_participacao.empty:
            st.markdown("""
            <div class="report-header same-page-section" style="background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
                üìä TAXA DE PARTICIPA√á√ÉO
            </div>
            """, unsafe_allow_html=True)
            
            # Help para an√°lise do gr√°fico
            with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
                st.markdown("""
                **üìä Taxa de Participa√ß√£o - Informa√ß√µes T√©cnicas**
                
                **Constru√ß√£o do gr√°fico:**
                - **Tipo:** Gauge (medidor circular) com escala de 0% a 100%
                - **Cores:** Verde (90-100%), Amarelo (80-89%), Vermelho (<80%)
                - **Dados:** Taxa de participa√ß√£o = (Alunos Efetivos √∑ Alunos Previstos) √ó 100
                
                **O que representa:**
                - **Taxa de Participa√ß√£o:** Percentual de alunos que efetivamente participaram da avalia√ß√£o
                - **Alunos Previstos:** Total de alunos matriculados que deveriam participar
                - **Alunos Efetivos:** Alunos que realmente fizeram a prova
                
                **Como ler:**
                - **Ponteiro:** Indica a taxa de participa√ß√£o atual
                - **Zonas coloridas:** Mostram faixas de classifica√ß√£o
                - **Valor num√©rico:** Taxa exata de participa√ß√£o
                """)
            
            # Converter para num√©rico
            df_participacao = converter_para_numerico(
                df_participacao, 
                ['Alunos Previstos', 'Alunos Efetivos', 'Participa√ß√£o']
            )
            
            # Gauges de participa√ß√£o
            col1, col2, col3, col4 = st.columns([1.2, 1, 1, 1])
            
            with col1:
                criar_gauge_participacao(df_participacao, "Cear√°", CODIGOS_ENTIDADE['ESTADO'], "ceara")
            
            with col2:
                criar_gauge_participacao(df_participacao, "CREDE", CODIGOS_ENTIDADE['CREDE'], "crede")
            
            with col3:
                criar_gauge_participacao(df_participacao, "Munic√≠pio", CODIGOS_ENTIDADE['MUNICIPIO'], "municipio")
            
            with col4:
                criar_gauge_participacao(df_participacao, "Escola", CODIGOS_ENTIDADE['ESCOLA'], "escola")
            
            # Download
            csv_part = df_participacao.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• Baixar Dados de Participa√ß√£o",
                data=csv_part,
                file_name="participacao.csv",
                mime="text/csv",
                key="download_participacao"
            )
            
            # An√°lise com Groq
            with st.expander("ü§ñ An√°lise Inteligente - Taxa de Participa√ß√£o", expanded=False):
                if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                    st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                    
                    # Criar chave √∫nica baseada nos filtros atuais
                    etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                    disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                    key_analise = f"analise_participacao_{etapa_filtro}_{disciplina_filtro}"
                    
                    if st.button("üîç Analisar Dados com IA", key=key_analise):
                        with st.spinner("ü§ñ Analisando dados com IA..."):
                            analise = analisar_dataframe_com_groq(
                                df_participacao, 
                                "Taxa de Participa√ß√£o", 
                                "An√°lise da participa√ß√£o dos estudantes nas avalia√ß√µes SPAECE. IMPORTANTE: O ideal √© manter 100% de participa√ß√£o. Destaque como altas taxas de participa√ß√£o podem trazer recursos para o munic√≠pio, melhorar a estrutura da escola e servir de subs√≠dio para implementar planos de cargos e carreiras e aumento de sal√°rio dos profissionais da educa√ß√£o, especialmente professores. Considere que participa√ß√£o alta √© indicador de qualidade educacional e pode resultar em mais investimentos e melhorias estruturais.",
                                st.session_state.agregado_consultado,
                                st.session_state.df_concatenado
                            )
                            st.markdown(analise)
                elif not st.session_state.get('documentos_carregados', False):
                    st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
                else:
                    st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
        else:
            st.info("Sem dados v√°lidos de participa√ß√£o ap√≥s processamento")
    else:
        st.info("Colunas necess√°rias n√£o encontradas para exibir participa√ß√£o")
    
    # Espa√ßamento menor para manter na mesma p√°gina
    st.markdown("<br>", unsafe_allow_html=True)
    
    # ==================== PROFICI√äNCIA M√âDIA ====================
    st.markdown("""
    <div class="report-header same-page-section" style="background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
        üìà PROFICI√äNCIA M√âDIA
    </div>
    """, unsafe_allow_html=True)
    
    # Help para an√°lise do gr√°fico
    with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
        st.markdown("""
        **üìà Profici√™ncia M√©dia - Informa√ß√µes T√©cnicas**
        
        **Constru√ß√£o do gr√°fico:**
        - **Tipo:** Cards com m√©tricas e banners coloridos
        - **Escalas:** Duas escalas diferentes (0-500 e 0-1000)
        - **Layout:** 4 colunas lado a lado (Estado, CREDE, Munic√≠pio, Escola)
        
        **O que representa:**
        - **Profici√™ncia M√©dia 500:** Pontua√ß√£o m√©dia na escala de 0 a 500 pontos (2¬∫ e 5¬∫ anos)
        - **Profici√™ncia M√©dia 1000:** Pontua√ß√£o m√©dia na escala de 0 a 1000 pontos (9¬∫ ano e EM)
        - **Banners:** Verde (escala 500) e Laranja (escala 1000)
        
        **Como ler:**
        - **Valores num√©ricos:** Pontua√ß√£o m√©dia exata de cada entidade
        - **Banners coloridos:** Identificam qual escala est√° sendo mostrada
        - **Compara√ß√£o:** Valores podem ser comparados entre as entidades
        """)
    
    colunas_proficiencia = ['TP_ENTIDADE','NM_ENTIDADE','AVG_PROFICIENCIA_E1','AVG_PROFICIENCIA_E2','VL_FILTRO_DISCIPLINA','VL_FILTRO_ETAPA']
    
    # Verificar se colunas de profici√™ncia existem
    colunas_proficiencia_existentes = [col for col in colunas_proficiencia if col in df_concat.columns]
    
    # Tentar usar dados de profici√™ncia espec√≠ficos primeiro
    if not df_concat.empty and all(col in df_concat.columns for col in colunas_proficiencia):
        # Usar dropna apenas nas colunas essenciais, n√£o nas de profici√™ncia
        df_proficiencia = df_concat[colunas_proficiencia].dropna(
            subset=['TP_ENTIDADE', 'NM_ENTIDADE', 'VL_FILTRO_DISCIPLINA', 'VL_FILTRO_ETAPA']
        ).copy()
        
        df_proficiencia = df_proficiencia[df_proficiencia['VL_FILTRO_DISCIPLINA'] != 'L√≠ngua Portuguesa - Escrita e Leitura']
        
        df_proficiencia.columns = ['Tipo de Entidade', 'Entidade', 'Profici√™ncia M√©dia 500', 'Profici√™ncia M√©dia 1000', 'Componente Curricular', 'Etapa']
        
        # Converter para num√©rico
        df_proficiencia['Profici√™ncia M√©dia 500'] = pd.to_numeric(df_proficiencia['Profici√™ncia M√©dia 500'], errors='coerce')
        df_proficiencia['Profici√™ncia M√©dia 1000'] = pd.to_numeric(df_proficiencia['Profici√™ncia M√©dia 1000'], errors='coerce')
        
        # Debug: Verificar dados ap√≥s processamento
        if len(df_proficiencia) > 0:
            pass  # Dados v√°lidos encontrados
        else:
            st.warning("‚ö†Ô∏è DataFrame de profici√™ncia est√° vazio ap√≥s processamento")
    else:
        # Fallback: Criar dados de profici√™ncia a partir dos dados dispon√≠veis
        
        # Criar DataFrame b√°sico com tipos de entidade
        if 'TP_ENTIDADE' in df_concat.columns and 'NM_ENTIDADE' in df_concat.columns:
            df_proficiencia = df_concat[['TP_ENTIDADE', 'NM_ENTIDADE']].copy()
            df_proficiencia.columns = ['Tipo de Entidade', 'Entidade']
            
            # Adicionar colunas de profici√™ncia com valores padr√£o ou calculados
            df_proficiencia['Profici√™ncia M√©dia 500'] = 0.0
            df_proficiencia['Profici√™ncia M√©dia 1000'] = 0.0
            df_proficiencia['Componente Curricular'] = 'N/A'
            df_proficiencia['Etapa'] = 'N/A'
            
            # Tentar calcular profici√™ncia m√©dia a partir de outras colunas se existirem
            colunas_proficiencia_alternativas = [col for col in df_concat.columns if 'PROFICIENCIA' in col.upper() or 'VL_' in col]
            
            if colunas_proficiencia_alternativas:
                # Para cada tipo de entidade, tentar calcular profici√™ncia m√©dia
                for tipo_codigo in ['01', '02', '11', '03']:
                    dados_tipo = df_concat[df_concat['TP_ENTIDADE'] == tipo_codigo]
                    if len(dados_tipo) > 0:
                        # Tentar encontrar colunas de profici√™ncia v√°lidas
                        for col in colunas_proficiencia_alternativas:
                            if dados_tipo[col].notna().any():
                                try:
                                    prof_media = pd.to_numeric(dados_tipo[col], errors='coerce').mean()
                                    if not pd.isna(prof_media):
                                        # Atualizar dados de profici√™ncia
                                        mask = df_proficiencia['Tipo de Entidade'] == tipo_codigo
                                        if 'E1' in col or '500' in col:
                                            df_proficiencia.loc[mask, 'Profici√™ncia M√©dia 500'] = prof_media
                                        elif 'E2' in col or '1000' in col:
                                            df_proficiencia.loc[mask, 'Profici√™ncia M√©dia 1000'] = prof_media
                                        break
                                except:
                                    continue
        else:
            st.error("‚ùå N√£o foi poss√≠vel criar dados de profici√™ncia")
            df_proficiencia = pd.DataFrame()
        
        # Debug m√≠nimo: apenas mostrar se conseguiu criar dados
        if len(df_proficiencia) > 0:
            pass  # Dados criados com sucesso
        else:
            st.warning("‚ö†Ô∏è N√£o foi poss√≠vel criar dados de profici√™ncia")
    
    # Exibir gr√°ficos de profici√™ncia (para ambos os casos)
    if not df_proficiencia.empty:
        # DataFrame para exibi√ß√£o (sem a coluna Tipo de Entidade)
        df_proficiencia_display = df_proficiencia[['Entidade', 'Profici√™ncia M√©dia 500', 'Profici√™ncia M√©dia 1000', 'Componente Curricular', 'Etapa']].copy()
        
        col1, col2, col3, col4 = st.columns([1.2, 1, 1, 1])
        
        # Cards de profici√™ncia
        entidades = [
            ("Cear√°", CODIGOS_ENTIDADE['ESTADO']),
            ("CREDE", CODIGOS_ENTIDADE['CREDE']),
            ("Munic√≠pio", CODIGOS_ENTIDADE['MUNICIPIO']),
            ("Escola", CODIGOS_ENTIDADE['ESCOLA'])
        ]
        
        for i, (nome, codigo) in enumerate(entidades):
            with [col1, col2, col3, col4][i]:
                st.markdown(criar_card_entidade(nome), unsafe_allow_html=True)
                proficiencia_500 = obter_proficiencia_media(df_proficiencia, codigo, 'Profici√™ncia M√©dia 500')
                proficiencia_1000 = obter_proficiencia_media(df_proficiencia, codigo, 'Profici√™ncia M√©dia 1000')
                
                # Espa√ßo em cima dos banners
                st.markdown("<br>", unsafe_allow_html=True)
                
                # Layout lado a lado para as duas escalas
                escala_col1, escala_col2 = st.columns(2)
                
                with escala_col1:
                    # Banner destacado para Escala 500
                    st.markdown(f"""
                    <div style="background: linear-gradient(135deg, {COR_PRIMARIA}, {COR_SUCESSO}); 
                               color: white; padding: 8px 10px; border-radius: 6px; 
                               text-align: center; font-weight: bold; font-size: 14px;
                               margin-bottom: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.2);">
                        üìä Escala<br>0-500
                    </div>
                    """, unsafe_allow_html=True)
                    st.metric("Profici√™ncia 500", f"{proficiencia_500:.0f}" if not pd.isna(proficiencia_500) else "N/A", label_visibility="collapsed")
                
                with escala_col2:
                    # Banner destacado para Escala 1000
                    if not pd.isna(proficiencia_1000):
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, {COR_SECUNDARIA}, {COR_ACENTO}); 
                                   color: white; padding: 8px 10px; border-radius: 6px; 
                                   text-align: center; font-weight: bold; font-size: 14px;
                                   margin-bottom: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.2);">
                            üìä Escala<br>0-1000
                        </div>
                        """, unsafe_allow_html=True)
                        st.metric("Profici√™ncia 1000", f"{proficiencia_1000:.0f}", label_visibility="collapsed")
                    else:
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, {COR_SECUNDARIA}, {COR_ACENTO}); 
                                   color: white; padding: 8px 10px; border-radius: 6px; 
                                   text-align: center; font-weight: bold; font-size: 14px;
                                   margin-bottom: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.2);">
                            üìä Escala<br>0-1000<br>
                            <span style="font-size: 11px;">Dados n√£o dispon√≠veis<br>para esta etapa</span>
                        </div>
                        """, unsafe_allow_html=True)
        
        #Download
        csv_prof = df_proficiencia_display.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• Baixar Dados de Profici√™ncia",
            data=csv_prof,
            file_name="proficiencia.csv",
            mime="text/csv",
            key="download_proficiencia"
        )
        
        # An√°lise com Groq
        with st.expander("ü§ñ An√°lise Inteligente - Profici√™ncia M√©dia", expanded=False):
            if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                
                # Criar chave √∫nica baseada nos filtros atuais
                etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                key_analise = f"analise_proficiencia_{etapa_filtro}_{disciplina_filtro}"
                
                if st.button("üîç Analisar Dados com IA", key=key_analise):
                    with st.spinner("ü§ñ Analisando dados com IA..."):
                        analise = analisar_dataframe_com_groq(
                            df_proficiencia_display, 
                            "Profici√™ncia M√©dia", 
                            "An√°lise dos n√≠veis de profici√™ncia dos estudantes nas avalia√ß√µes SPAECE (escalas 500 e 1000)",
                            st.session_state.agregado_consultado,
                            st.session_state.df_concatenado
                        )
                        st.markdown(analise)
            elif not st.session_state.get('documentos_carregados', False):
                st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
            else:
                st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
    
    else:
        st.info("Sem dados v√°lidos de profici√™ncia ap√≥s processamento")
    # ==================== DISTRIBUI√á√ÉO POR DESEMPENHO ====================
    colunas_desempenho = ['TP_ENTIDADE','DC_TIPO_ENTIDADE','NM_ENTIDADE','NU_N01_TRI_E1','NU_N02_TRI_E1','NU_N03_TRI_E1',
                         'NU_N04_TRI_E1','NU_N05_TRI_E1','TX_N01_TRI_E1', 'TX_N02_TRI_E1', 
                         'TX_N03_TRI_E1', 'TX_N04_TRI_E1', 'TX_N05_TRI_E1', 'VL_FILTRO_DISCIPLINA', 
                         'VL_FILTRO_ETAPA']
    
    if not df_concat.empty and all(col in df_concat.columns for col in colunas_desempenho):
        # Quebra de p√°gina antes da se√ß√£o de desempenho (s√≥ se houver dados)
        st.markdown("""
        <div style="page-break-before: always; break-before: page;">
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="report-header" style="background: linear-gradient(135deg, {COR_SECUNDARIA}, #e67e22, #d35400);">
            üìä DISTRIBUI√á√ÉO POR PADR√ÉO DE DESEMPENHO
        </div>
        """, unsafe_allow_html=True)
        
        # Help para an√°lise do gr√°fico
        with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
            st.markdown("""
            **üìä Distribui√ß√£o por Padr√£o de Desempenho - Informa√ß√µes T√©cnicas**
            
            **Constru√ß√£o do gr√°fico:**
            - **Tipo:** Gr√°fico de barras empilhadas (stacked bar chart)
            - **Eixo X:** Entidades (Estado, CREDE, Munic√≠pio, Escola)
            - **Eixo Y:** Percentual de alunos (0% a 100%)
            - **Barras:** Divididas em 5 segmentos (N√≠veis 1-5)
            
            **O que representa:**
            - **N√≠vel 1-5:** Classifica√ß√£o dos estudantes por padr√µes de desempenho
            - **Percentual:** Propor√ß√£o de alunos em cada n√≠vel
            - **Hover:** Mostra quantidade de alunos e percentual por n√≠vel
            
            **Padr√µes por etapa:**
            - **2¬∫ Ano:** N√£o Alfabetizado ‚Üí Alfabetiza√ß√£o Incompleta ‚Üí Intermedi√°rio ‚Üí Suficiente ‚Üí Desej√°vel
            - **5¬∫/9¬∫ Ano:** Muito Cr√≠tico ‚Üí Cr√≠tico ‚Üí Intermedi√°rio ‚Üí Adequado
            
            **Como ler:**
            - **Altura total:** 100% dos alunos avaliados
            - **Segmentos coloridos:** Propor√ß√£o em cada n√≠vel de desempenho
            - **Hover:** Detalhes espec√≠ficos de cada segmento
            """)
        
        # Usar dropna apenas nas colunas essenciais, n√£o nas de desempenho
        df_desempenho = df_concat[colunas_desempenho].dropna(
            subset=['TP_ENTIDADE', 'DC_TIPO_ENTIDADE', 'NM_ENTIDADE', 'VL_FILTRO_DISCIPLINA', 'VL_FILTRO_ETAPA']
        ).copy()
        
        df_desempenho.columns = ['Tipo de Entidade', 'Tipo de Entidade Descri√ß√£o', 'Entidade', 'N√≠vel 1', 'N√≠vel 2', 'N√≠vel 3', 
                                'N√≠vel 4', 'N√≠vel 5', 'Taxa N√≠vel 1', 'Taxa N√≠vel 2', 
                                'Taxa N√≠vel 3', 'Taxa N√≠vel 4', 'Taxa N√≠vel 5', 
                                'Componente Curricular', 'Etapa']
        
        # Definir ordem dos tipos de entidade e criar coluna de ordena√ß√£o
        ordem_tipos = {'01': 1, '02': 2, '11': 3, '03': 4}
        df_desempenho['Ordem_Tipo'] = df_desempenho['Tipo de Entidade'].map(ordem_tipos)
        df_desempenho['Tipo de Entidade'] = pd.Categorical(
            df_desempenho['Tipo de Entidade'], 
            categories=['01', '02', '11', '03'], 
            ordered=True
        )
        
        # Ordenar o DataFrame principal pela ordem correta
        df_desempenho = df_desempenho.sort_values(['Ordem_Tipo', 'Entidade'])
        
        # Converter colunas de n√≠veis para num√©rico
        df_desempenho = converter_para_numerico(
            df_desempenho, 
            ['N√≠vel 1', 'N√≠vel 2', 'N√≠vel 3', 'N√≠vel 4', 'N√≠vel 5', 
             'Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4', 'Taxa N√≠vel 5']
        )
        
        
        # Criar gr√°fico de barras para apresentar os n√≠veis de desempenho
        st.subheader("Gr√°fico de Distribui√ß√£o por Padr√£o de Desempenho")
        
        # Preparar dados para o gr√°fico
        df_grafico = df_desempenho.copy()
        
        # Ordenar por ordem num√©rica do tipo e depois por Entidade
        df_grafico = df_grafico.sort_values(['Ordem_Tipo', 'Entidade'])
        
        # Agrupar por tipo de entidade para manter as escolas individuais
        colunas_agregacao = {}
        for col in ['Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4', 'Taxa N√≠vel 5']:
            if col in df_grafico.columns:
                colunas_agregacao[col] = 'mean'
        
        # Adicionar tamb√©m as colunas de quantidade (N√≠vel 1-5) para o hover
        for col in ['N√≠vel 1', 'N√≠vel 2', 'N√≠vel 3', 'N√≠vel 4', 'N√≠vel 5']:
            if col in df_grafico.columns:
                colunas_agregacao[col] = 'sum'  # Somar as quantidades
        
        # Para escolas, manter individualmente; para outros tipos, agrupar por tipo
        df_escolas = df_grafico[df_grafico['Tipo de Entidade'] == '03'].copy()
        df_outros = df_grafico[df_grafico['Tipo de Entidade'] != '03'].copy()
        
        # Agregar outros tipos (Estado, CREDE, Munic√≠pio)
        if not df_outros.empty:
            df_outros_agregado = df_outros.groupby(['Tipo de Entidade', 'Tipo de Entidade Descri√ß√£o', 'Ordem_Tipo'], observed=True).agg(colunas_agregacao).reset_index()
        else:
            df_outros_agregado = pd.DataFrame()
        
        # Manter escolas individuais (sem agrega√ß√£o)
        if not df_escolas.empty:
            df_escolas_agregado = df_escolas.groupby(['Tipo de Entidade', 'Tipo de Entidade Descri√ß√£o', 'Ordem_Tipo', 'Entidade'], observed=True).agg(colunas_agregacao).reset_index()
        else:
            df_escolas_agregado = pd.DataFrame()
        
        # Combinar os DataFrames
        if not df_outros_agregado.empty and not df_escolas_agregado.empty:
            df_agregado = pd.concat([df_outros_agregado, df_escolas_agregado], ignore_index=True)
        elif not df_outros_agregado.empty:
            df_agregado = df_outros_agregado
        elif not df_escolas_agregado.empty:
            df_agregado = df_escolas_agregado
        else:
            df_agregado = pd.DataFrame()
        
        if len(df_agregado) > 0:
            # Ordenar o DataFrame agregado para manter a ordem no gr√°fico
            # Para escolas, ordenar por nome da escola; para outros, por tipo
            if 'Entidade' in df_agregado.columns:
                df_agregado = df_agregado.sort_values(['Ordem_Tipo', 'Tipo de Entidade Descri√ß√£o', 'Entidade'])
            else:
                df_agregado = df_agregado.sort_values(['Ordem_Tipo', 'Tipo de Entidade Descri√ß√£o'])
            
            # Detectar colunas de n√≠veis dispon√≠veis
            colunas_niveis_disponiveis = [col for col in df_agregado.columns if col.startswith('Taxa N√≠vel')]
            
            # Transformar os dados para formato adequado para plotagem
            df_plot = pd.melt(
                df_agregado, 
                id_vars=['Tipo de Entidade', 'Tipo de Entidade Descri√ß√£o', 'Ordem_Tipo'],
                value_vars=colunas_niveis_disponiveis,
                var_name='Padr√£o de Desempenho',
                value_name='Percentual'
            )
            
            # Ordenar o DataFrame plot para manter a ordem das entidades
            df_plot = df_plot.sort_values(['Ordem_Tipo', 'Tipo de Entidade Descri√ß√£o'])
            
            # As colunas TX_* j√° s√£o percentuais (0-100), n√£o precisamos multiplicar por 100
            
            # Criar o gr√°fico de barras empilhadas usando go.Figure
            fig = go.Figure()
            
            # Detectar quantos n√≠veis existem baseado na etapa
            # Usar df_desempenho que tem a coluna Etapa, n√£o df_grafico que pode n√£o ter
            etapa_atual = df_desempenho['Etapa'].iloc[0] if 'Etapa' in df_desempenho.columns and len(df_desempenho) > 0 else None
            
            if etapa_atual and ('2¬∫ Ano' in etapa_atual or '2¬∫' in etapa_atual):
                # 2¬∫ ano tem APENAS 5 n√≠veis
                niveis = ['Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4', 'Taxa N√≠vel 5']
                cores = ['#e30513', '#fdc300', '#ffed00', '#cce4ce', '#1ca041']
                # Nomes para a legenda do 2¬∫ ano
                nomes_legenda = ['N√£o Alfabetizado', 'Alfabetiza√ß√£o Incompleta', 'Intermedi√°rio', 'Suficiente', 'Desej√°vel']
            elif etapa_atual and '5¬∫ Ano' in etapa_atual:
                # 5¬∫ ano tem 4 n√≠veis
                niveis = ['Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4']
                cores = ['#e30513', '#fdc300', '#cce4ce', '#1ca041']
                # Nomes para a legenda do 5¬∫ ano
                nomes_legenda = ['Muito Cr√≠tico', 'Cr√≠tico', 'Intermedi√°rio', 'Adequado']
            elif etapa_atual and '9¬∫ Ano' in etapa_atual:
                # 9¬∫ ano tem 4 n√≠veis
                niveis = ['Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4']
                cores = ['#e30513', '#fdc300', '#cce4ce', '#1ca041']
                # Nomes para a legenda do 9¬∫ ano
                nomes_legenda = ['Muito Cr√≠tico', 'Cr√≠tico', 'Intermedi√°rio', 'Adequado']
            else:
                # Fallback para outras etapas
                niveis = ['Taxa N√≠vel 1', 'Taxa N√≠vel 2', 'Taxa N√≠vel 3', 'Taxa N√≠vel 4']
                cores = ['#e30513', '#fdc300', '#cce4ce', '#1ca041']
                nomes_legenda = ['Muito Cr√≠tico', 'Cr√≠tico', 'Intermedi√°rio', 'Adequado']
            
            # Filtrar apenas os n√≠veis que existem nos dados
            niveis_existentes = [nivel for nivel in niveis if nivel in df_agregado.columns]
            cores = cores[:len(niveis_existentes)]
            nomes_legenda_filtrados = nomes_legenda[:len(niveis_existentes)]
            
            # Adicionar uma barra para cada n√≠vel
            for i, nivel in enumerate(niveis_existentes):
                dados_nivel = df_plot[df_plot['Padr√£o de Desempenho'] == nivel]
                # Criar nome simplificado para o hover
                nome_nivel = nivel.replace('Taxa ', '')
                
                # Buscar os valores num√©ricos correspondentes (N√≠vel 1, N√≠vel 2, etc.)
                coluna_numerica = nome_nivel  # N√≠vel 1, N√≠vel 2, etc.
                
                # Criar dados para hover com quantidade de alunos
                hover_data = []
                for idx, row in dados_nivel.iterrows():
                    entidade_desc = row['Tipo de Entidade Descri√ß√£o']
                    percentual = row['Percentual']
                    
                    # Para escolas, incluir nome da escola no hover
                    if row['Tipo de Entidade'] == '03' and 'Entidade' in row:
                        nome_display = f"{entidade_desc} - {row['Entidade']}"
                    else:
                        nome_display = entidade_desc
                    
                    # Buscar quantidade de alunos correspondente (coluna N√≠vel 1, N√≠vel 2, etc.)
                    # O percentual j√° vem da coluna Taxa N√≠vel X, agora buscamos a quantidade da coluna N√≠vel X
                    if 'Entidade' in df_agregado.columns:
                        # Para escolas, buscar por tipo + entidade
                        mask = (df_agregado['Tipo de Entidade Descri√ß√£o'] == entidade_desc) & (df_agregado['Entidade'] == row.get('Entidade', ''))
                    else:
                        # Para outros tipos, buscar apenas por tipo
                        mask = df_agregado['Tipo de Entidade Descri√ß√£o'] == entidade_desc
                    
                    quantidade_alunos = df_agregado[mask][coluna_numerica].iloc[0] if coluna_numerica in df_agregado.columns and mask.any() else 0
                    hover_data.append(f'<b>{nome_display}</b><br>N√≠vel: {nomes_legenda_filtrados[i]}<br>Percentual: {percentual:.1f}%<br>Quantidade de Alunos: {quantidade_alunos:,.0f}')
                
                fig.add_trace(go.Bar(
                    name=nomes_legenda_filtrados[i],
                    x=dados_nivel['Percentual'],
                    y=dados_nivel.apply(lambda row: f"{row['Tipo de Entidade Descri√ß√£o']} - {row['Entidade']}" if row['Tipo de Entidade'] == '03' and 'Entidade' in row else row['Tipo de Entidade Descri√ß√£o'], axis=1),
                    orientation='h',
                    marker_color=cores[i],
                    customdata=hover_data,
                    hovertemplate='%{customdata}<extra></extra>',
                    text=dados_nivel['Percentual'].apply(lambda x: f'{x:.1f}%'),
                    textposition='inside',
                    textfont=dict(size=16, color='black')
                ))
            
            # Criar ordem espec√≠fica das entidades baseada no tipo (01, 02, 11, 03)
            # Para escolas, usar nome da escola; para outros, usar tipo
            if 'Entidade' in df_plot.columns:
                df_ordenado = df_plot.sort_values(['Ordem_Tipo', 'Tipo de Entidade Descri√ß√£o', 'Entidade'])
                # Para escolas, usar nome da escola; para outros, usar tipo
                ordem_manual = []
                for _, row in df_ordenado.iterrows():
                    if row['Tipo de Entidade'] == '03':  # Escola
                        nome_entidade = f"{row['Tipo de Entidade Descri√ß√£o']} - {row['Entidade']}"
                    else:
                        nome_entidade = row['Tipo de Entidade Descri√ß√£o']
                    if nome_entidade not in ordem_manual:
                        ordem_manual.append(nome_entidade)
            else:
                df_ordenado = df_plot.sort_values(['Ordem_Tipo', 'Tipo de Entidade Descri√ß√£o'])
                ordem_manual = df_ordenado['Tipo de Entidade Descri√ß√£o'].unique().tolist()
            
            # Configurar o layout para barras empilhadas
            fig.update_layout(
                barmode='stack',
                title=dict(
                    text='Distribui√ß√£o por Padr√£o de Desempenho',
                    font=dict(size=24, family='Arial Black')
                ),
                xaxis_title=dict(
                    text='Percentual (%)',
                    font=dict(size=18)
                ),
                yaxis_title=dict(
                    text='Entidade',
                    font=dict(size=18)
                ),
                legend=dict(
                    title=dict(
                        text='Padr√£o de Desempenho',
                        font=dict(size=16)
                    ),
                    font=dict(size=16)
                ),
                height=500,
                yaxis=dict(
                    categoryorder='array', 
                    categoryarray=ordem_manual,
                    tickfont=dict(size=18)
                ),
                xaxis=dict(
                    tickfont=dict(size=18),
                    range=[0, 100]  # For√ßar escala de 0 a 100%
                ),
                hoverlabel=dict(
                    font_size=16,
                    font_family="Arial"
                )
            )
            
            # Exibir o gr√°fico
            st.plotly_chart(fig, use_container_width=True)
            
            csv_desemp = df_desempenho.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• Baixar Dados de Desempenho",
                data=csv_desemp,
                file_name="desempenho.csv",
                mime="text/csv",
                key="download_desempenho"
            )
            
            # An√°lise com Groq
            with st.expander("ü§ñ An√°lise Inteligente - Distribui√ß√£o por Desempenho", expanded=False):
                if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                    st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                    
                    # Criar chave √∫nica baseada nos filtros atuais
                    etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                    disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                    key_analise = f"analise_desempenho_{etapa_filtro}_{disciplina_filtro}"
                    
                    if st.button("üîç Analisar Dados com IA", key=key_analise):
                        with st.spinner("ü§ñ Analisando dados com IA..."):
                            # Determinar os termos da legenda baseado na etapa
                            etapa_atual = df_desempenho['Etapa'].iloc[0] if 'Etapa' in df_desempenho.columns and len(df_desempenho) > 0 else None
                            if etapa_atual and '2¬∫ Ano' in etapa_atual:
                                termos_legenda = "N√£o Alfabetizado, Alfabetiza√ß√£o Incompleta, Intermedi√°rio, Suficiente, Desej√°vel"
                            elif etapa_atual and '5¬∫ Ano' in etapa_atual:
                                termos_legenda = "Muito Cr√≠tico, Cr√≠tico, Intermedi√°rio, Adequado"
                            elif etapa_atual and '9¬∫ Ano' in etapa_atual:
                                termos_legenda = "Muito Cr√≠tico, Cr√≠tico, Intermedi√°rio, Adequado"
                            else:
                                termos_legenda = "Muito Cr√≠tico, Cr√≠tico, Intermedi√°rio, Adequado"
                            
                            analise = analisar_dataframe_com_groq(
                                df_desempenho, 
                                "Distribui√ß√£o por Desempenho", 
                                f"An√°lise da distribui√ß√£o dos estudantes por padr√µes de desempenho ({termos_legenda})",
                                st.session_state.agregado_consultado,
                                st.session_state.df_concatenado
                            )
                            st.markdown(analise)
                elif not st.session_state.get('documentos_carregados', False):
                    st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
                else:
                    st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
    else:
        st.info("Colunas necess√°rias n√£o encontradas para exibir distribui√ß√£o de desempenho")
    
    # ==================== TAXA DE ACERTO POR HABILIDADE ====================
    colunas_habilidade = ['TP_ENTIDADE','DC_TIPO_ENTIDADE','NM_ENTIDADE','VL_FILTRO_DISCIPLINA','VL_FILTRO_ETAPA',
                         'TX_ACERTO','DC_HABILIDADE','CD_HABILIDADE_MODELO_02']
    
    if not df_concat.empty and all(col in df_concat.columns for col in colunas_habilidade):
        # Quebra de p√°gina antes da se√ß√£o de habilidades (s√≥ se houver dados)
        st.markdown("""
        <div style="page-break-before: always; break-before: page;">
        </div>
        """, unsafe_allow_html=True)
        
        # S√≥ exibir o header se houver dados
        st.markdown("""
        <div class="report-header" style="background: linear-gradient(135deg, #d62728, #c82333, #a71e2a);">
            üìö TAXA DE ACERTO POR HABILIDADE
        </div>
        """, unsafe_allow_html=True)
        
        # Help para an√°lise do gr√°fico
        with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
            st.markdown("""
            **üìö Taxa de Acerto por Habilidade - Informa√ß√µes T√©cnicas**
            
            **Constru√ß√£o do gr√°fico:**
            - **Tipo:** Gr√°fico de barras agrupadas (grouped bar chart)
            - **Eixo X:** C√≥digo da Habilidade (identificador √∫nico)
            - **Eixo Y:** Taxa de acerto (0% a 100%)
            - **Barras:** Agrupadas por tipo de entidade (Cear√°, CREDE, Munic√≠pio, Escola)
            
            **O que representa:**
            - **Taxa de Acerto:** Percentual de quest√µes corretas por habilidade espec√≠fica
            - **C√≥digo da Habilidade:** Identificador √∫nico de cada compet√™ncia
            - **Habilidade:** Descri√ß√£o da compet√™ncia avaliada
            - **Compara√ß√£o:** Entre tipos de entidade para cada habilidade
            
            **Como ler:**
            - **Altura da barra:** Taxa de acerto da habilidade para cada entidade
            - **Cores das barras:** Cada cor representa um tipo de entidade
            - **Agrupamento:** Barras lado a lado para comparar entidades
            - **Hover:** Mostra c√≥digo, taxa de acerto e descri√ß√£o da habilidade
            
            **Dados dispon√≠veis:**
            - **Taxa de Acerto:** Percentual de quest√µes corretas
            - **C√≥digo da Habilidade:** Identificador t√©cnico
            - **Habilidade:** Descri√ß√£o da compet√™ncia
            - **Tipo de Entidade:** Cear√°, CREDE, Munic√≠pio ou Escola
            """)
        
        df_habilidade = df_concat[colunas_habilidade].copy()
        
        df_habilidade.columns = ['Tipo de Entidade C√≥digo', 'Tipo de Entidade', 'Entidade', 'Componente Curricular', 'Etapa', 
                                'Taxa de Acerto', 'Habilidade', 'C√≥digo Habilidade']
        
        # Converter Taxa de Acerto para num√©rico
        df_habilidade['Taxa de Acerto'] = pd.to_numeric(df_habilidade['Taxa de Acerto'], errors='coerce')
        
        # Criar gr√°fico de barras para taxa de acerto por habilidade
        if not df_habilidade.empty:
            st.subheader("Gr√°fico de Taxa de Acerto por Habilidade")
            
            # Remover valores NaN e ordenar por taxa de acerto
            df_habilidade_grafico = df_habilidade.dropna(subset=['Taxa de Acerto']).copy()
            
            if not df_habilidade_grafico.empty:
                # Criar gr√°fico de barras agrupadas
                fig_habilidade = go.Figure()
                
                # Mapear tipos de entidade para nomes amig√°veis
                mapa_tipos = {
                    '01': 'Cear√°',
                    '02': 'CREDE',
                    '11': 'Munic√≠pio',
                    '03': 'Escola',
                    'Estado': 'Cear√°',
                    'Regional': 'CREDE',
                    'Munic√≠pio': 'Munic√≠pio',
                    'Escola': 'Escola'
                }
                
                # Criar coluna com tipo de entidade amig√°vel
                df_habilidade_grafico['Tipo Simplificado'] = df_habilidade_grafico['Tipo de Entidade C√≥digo'].map(mapa_tipos)
                if df_habilidade_grafico['Tipo Simplificado'].isna().any():
                    df_habilidade_grafico['Tipo Simplificado'] = df_habilidade_grafico['Tipo Simplificado'].fillna(
                        df_habilidade_grafico['Tipo de Entidade'].map(mapa_tipos)
                    )
                
                # Agrupar por tipo de entidade e c√≥digo de habilidade, calculando a m√©dia
                df_agrupado = df_habilidade_grafico.groupby(['Tipo Simplificado', 'C√≥digo Habilidade', 'Habilidade']).agg({
                    'Taxa de Acerto': 'mean'
                }).reset_index()
                
                # Obter tipos de entidade √∫nicos na ordem correta
                ordem_tipos = ['Cear√°', 'CREDE', 'Munic√≠pio', 'Escola']
                tipos_disponiveis = [t for t in ordem_tipos if t in df_agrupado['Tipo Simplificado'].unique()]
                
                # Cores fixas para cada tipo de entidade
                cores_tipos = {
                    'Cear√°': '#e94f0e',
                    'CREDE': '#f59c00',
                    'Munic√≠pio': '#26a737',
                    'Escola': '#2db39e'
                }
                
                # Adicionar uma barra para cada tipo de entidade
                for tipo in tipos_disponiveis:
                    df_tipo = df_agrupado[df_agrupado['Tipo Simplificado'] == tipo]
                    
                    if not df_tipo.empty:
                        # Ordenar por c√≥digo da habilidade para manter consist√™ncia
                        df_tipo = df_tipo.sort_values('C√≥digo Habilidade')
                        
                        fig_habilidade.add_trace(go.Bar(
                            name=tipo,
                            x=df_tipo['C√≥digo Habilidade'],
                            y=df_tipo['Taxa de Acerto'],
                            text=df_tipo['Taxa de Acerto'].apply(lambda x: f'{x:.1f}'.replace('.', ',')) + '%',
                            textposition='auto',
                            textfont=dict(size=12, family='Arial', color='black'),
                            marker_color=cores_tipos.get(tipo, '#999999'),
                            hovertemplate=f'<b style="font-size:18px">{tipo}</b><br><span style="font-size:16px">C√≥digo: %{{x}}<br>Taxa de Acerto: %{{y:.1f}}%<br>Habilidade: %{{customdata}}</span><extra></extra>'.replace('.', ','),
                            customdata=df_tipo['Habilidade']
                        ))
                
                # Configurar o layout do gr√°fico
                fig_habilidade.update_layout(
                    title=dict(
                        text='Taxa de Acerto por Habilidade - Compara√ß√£o entre Tipos de Entidade',
                        font=dict(size=18, family='Arial Black')
                    ),
                    xaxis_title=dict(
                        text='C√≥digo da Habilidade',
                        font=dict(size=14)
                    ),
                    yaxis_title=dict(
                        text='Taxa de Acerto (%)',
                        font=dict(size=14)
                    ),
                    legend=dict(
                        title=dict(
                            text='Tipo de Entidade',
                            font=dict(size=14)
                        ),
                        font=dict(size=14)
                    ),
                        font=dict(size=14),
                    height=400,
                    yaxis=dict(
                        range=[0, 100],
                        tickfont=dict(size=15)
                    ),
                    xaxis=dict(
                        tickfont=dict(size=15)
                    ),
                    barmode='group',
                    hoverlabel=dict(
                        font_size=18,
                        font_family="Arial"
                    )
                )
                
                # Exibir o gr√°fico
                st.plotly_chart(fig_habilidade, use_container_width=True)
            else:
                st.info("Sem dados v√°lidos de taxa de acerto para criar o gr√°fico")
        else:
            st.info("Sem dados suficientes para criar o gr√°fico de habilidades")
        
        csv_hab = df_habilidade.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• Baixar Dados de Habilidade",
            data=csv_hab,
            file_name="habilidade.csv",
            mime="text/csv",
            key="download_habilidade"
        )
        
        # An√°lise com Groq
        with st.expander("ü§ñ An√°lise Inteligente - Taxa de Acerto por Habilidade", expanded=False):
            if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                
                # Criar chave √∫nica baseada nos filtros atuais
                etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                key_analise = f"analise_habilidade_{etapa_filtro}_{disciplina_filtro}"
                
                if st.button("üîç Analisar Dados com IA", key=key_analise):
                    with st.spinner("ü§ñ Analisando dados com IA..."):
                        analise = analisar_dataframe_com_groq(
                            df_habilidade, 
                            "Taxa de Acerto por Habilidade", 
                            "An√°lise das habilidades espec√≠ficas dos estudantes nas avalia√ß√µes SPAECE. IMPORTANTE: Considere que as habilidades t√™m hierarquia de pr√©-requisitos - algumas s√£o mais b√°sicas e fundamentais que outras. Foque sempre em fortalecer as habilidades mais basilares primeiro, pois elas s√£o pr√©-requisito para o desenvolvimento das demais. Identifique quais habilidades b√°sicas precisam de mais aten√ß√£o e como elas impactam o desenvolvimento das habilidades mais avan√ßadas.",
                            st.session_state.agregado_consultado,
                            st.session_state.df_concatenado
                        )
                        st.markdown(analise)
            elif not st.session_state.get('documentos_carregados', False):
                st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
            else:
                st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
    else:
        st.info("Colunas necess√°rias n√£o encontradas para exibir taxa de acerto por habilidade")
    
    # Quebra de p√°gina antes da se√ß√£o de etnia (removida para evitar p√°ginas vazias)
    # st.markdown("""
    # <div style="page-break-before: always; break-before: page;">
    # </div>
    # """, unsafe_allow_html=True)
    
    # ==================== DADOS CONTEXTUAIS - ETNIA ====================
    colunas_etnia = ['TP_ENTIDADE','DC_TIPO_ENTIDADE','NM_ENTIDADE', 'VL_FILTRO_DISCIPLINA', 'VL_FILTRO_ETAPA', 'VL_PRETA',
                    'VL_BRANCA', 'VL_PARDA', 'VL_AMARELA', 'VL_INDIGENA','TX_PRETA','TX_BRANCA',
                    'TX_PARDA','TX_AMARELA','TX_INDIGENA','NU_PRETA','NU_BRANCA','NU_PARDA',
                    'NU_AMARELA','NU_INDIGENA']
    colunas_etnia_disponiveis = [col for col in colunas_etnia if col in df_concat.columns]
    
    if len(colunas_etnia_disponiveis) >= 4:
        # Quebra de p√°gina antes da se√ß√£o de etnia (s√≥ se houver dados)
        st.markdown("""
        <div style="page-break-before: always; break-before: page;">
        </div>
        """, unsafe_allow_html=True)
        
        # S√≥ exibir o header se houver dados
        st.markdown("""
        <div class="report-header" style="background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
            üë• PROFICI√äNCIA POR ETNIA
        </div>
        """, unsafe_allow_html=True)
        
        # Help para an√°lise do gr√°fico
        with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
            st.markdown("""
            **üë• Profici√™ncia por Etnia - Informa√ß√µes T√©cnicas**
            
            **Constru√ß√£o do gr√°fico:**
            - **Tipo:** Gr√°fico de barras agrupadas (grouped bar chart)
            - **Eixo X:** Entidades (Estado, CREDE, Munic√≠pio, Escola)
            - **Eixo Y:** Taxa de participa√ß√£o (0% a 100%)
            - **Cores:** Baseadas na profici√™ncia m√©dia de cada grupo √©tnico
            
            **O que representa:**
            - **Altura da barra:** Taxa de participa√ß√£o por grupo √©tnico
            - **Cor da barra:** Profici√™ncia m√©dia do grupo (escala din√¢mica)
            - **Grupos √©tnicos:** Preta, Branca, Parda, Amarela, Ind√≠gena
            
            **Como ler:**
            - **Altura:** Percentual de participa√ß√£o na avalia√ß√£o
            - **Cor:** N√≠vel de profici√™ncia (üü† Baixa, üü° M√©dia, üü¢ Alta)
            - **Legenda:** Escala de profici√™ncia din√¢mica
            - **Hover:** Valores espec√≠ficos de participa√ß√£o e profici√™ncia
            
            **Dados dispon√≠veis:**
            - **Taxa de Participa√ß√£o:** Percentual de alunos que participaram
            - **Profici√™ncia M√©dia:** Pontua√ß√£o m√©dia do grupo
            - **N√∫mero de Alunos:** Quantidade de estudantes por grupo
            """)
        
        df_etnia = df_concat[colunas_etnia_disponiveis].copy()
        
        colunas_valores_etnia = ['VL_PRETA', 'VL_BRANCA', 'VL_PARDA', 'VL_AMARELA', 'VL_INDIGENA',
                                     'TX_PRETA','TX_BRANCA','TX_PARDA','TX_AMARELA','TX_INDIGENA',
                                     'NU_PRETA','NU_BRANCA','NU_PARDA','NU_AMARELA','NU_INDIGENA']
        df_etnia = converter_para_numerico(df_etnia, colunas_valores_etnia)
        
        colunas_etnia_valores = [col for col in colunas_valores_etnia if col in df_etnia.columns]
        if colunas_etnia_valores:
            df_etnia = df_etnia.dropna(subset=colunas_etnia_valores, how='all')
        
        if not df_etnia.empty:
            renomear = {
                'TP_ENTIDADE': 'Tipo de Entidade C√≥digo',
                'DC_TIPO_ENTIDADE': 'Tipo de Entidade',
                'NM_ENTIDADE': 'Entidade',
                'VL_FILTRO_DISCIPLINA': 'Componente Curricular',
                'VL_FILTRO_ETAPA': 'Etapa',
                'VL_PRETA': 'Profici√™ncia Preta',
                'VL_BRANCA': 'Profici√™ncia Branca',
                'VL_PARDA': 'Profici√™ncia Parda',
                'VL_AMARELA': 'Profici√™ncia Amarela',
                'VL_INDIGENA': 'Profici√™ncia Ind√≠gena',
                'TX_PRETA': 'Taxa Preta',
                'TX_BRANCA': 'Taxa Branca',
                'TX_PARDA': 'Taxa Parda',
                'TX_AMARELA': 'Taxa Amarela',
                'TX_INDIGENA': 'Taxa Ind√≠gena',
                'NU_PRETA': 'N√∫mero Preta',
                'NU_BRANCA': 'N√∫mero Branca',
                'NU_PARDA': 'N√∫mero Parda',
                'NU_AMARELA': 'N√∫mero Amarela',
                'NU_INDIGENA': 'N√∫mero Ind√≠gena'
            }
            df_etnia = df_etnia.rename(columns={k: v for k, v in renomear.items() if k in df_etnia.columns})
            
            st.info(f"üìä {len(df_etnia)} registros com dados de profici√™ncia por etnia")
            
            csv_etnia = df_etnia.to_csv(index=False).encode('utf-8')
            
            # Criar gr√°fico de barras para taxa e profici√™ncia por Etnia
            st.subheader("Gr√°fico de Taxa e Profici√™ncia por Etnia - Por Tipo de Entidade")
            
            # Verificar quais colunas est√£o dispon√≠veis
            colunas_taxa_etnia = [col for col in ['Taxa Preta', 'Taxa Branca', 
                                                'Taxa Parda', 'Taxa Amarela', 
                                                'Taxa Ind√≠gena'] if col in df_etnia.columns]
            
            colunas_prof_etnia = [col for col in ['Profici√™ncia Preta', 'Profici√™ncia Branca', 
                                                'Profici√™ncia Parda', 'Profici√™ncia Amarela', 
                                                'Profici√™ncia Ind√≠gena'] if col in df_etnia.columns]
            
            if colunas_taxa_etnia and colunas_prof_etnia and ('Tipo de Entidade C√≥digo' in df_etnia.columns or 'Tipo de Entidade' in df_etnia.columns):
                # Preparar dados para o gr√°fico
                df_plot = df_etnia.copy()
                
                # Mapear tipos de entidade para nomes amig√°veis
                mapa_tipos = {
                    '01': 'Cear√°',
                    '02': 'CREDE',
                    '11': 'Munic√≠pio',
                    '03': 'Escola',
                    'Estado': 'Cear√°',
                    'Regional': 'CREDE',
                    'Munic√≠pio': 'Munic√≠pio',
                    'Escola': 'Escola'
                }
                
                # Criar coluna com tipo de entidade amig√°vel
                if 'Tipo de Entidade C√≥digo' in df_plot.columns:
                    df_plot['Tipo Simplificado'] = df_plot['Tipo de Entidade C√≥digo'].map(mapa_tipos)
                    if df_plot['Tipo Simplificado'].isna().any() and 'Tipo de Entidade' in df_plot.columns:
                        df_plot['Tipo Simplificado'] = df_plot['Tipo Simplificado'].fillna(
                            df_plot['Tipo de Entidade'].map(mapa_tipos)
                        )
                elif 'Tipo de Entidade' in df_plot.columns:
                    df_plot['Tipo Simplificado'] = df_plot['Tipo de Entidade'].map(mapa_tipos)
                
                # Incluir colunas de n√∫mero
                colunas_numero_etnia = [col for col in ['N√∫mero Preta', 'N√∫mero Branca', 
                                                    'N√∫mero Parda', 'N√∫mero Amarela', 
                                                    'N√∫mero Ind√≠gena'] if col in df_etnia.columns]
                
                # Agrupar por tipo de entidade e calcular a m√©dia
                todas_colunas = colunas_taxa_etnia + colunas_prof_etnia + colunas_numero_etnia
                df_plot = df_plot.groupby('Tipo Simplificado')[todas_colunas].mean().reset_index()
                
                # Criar lista de dados para o gr√°fico
                dados_grafico = []
                
                # Categorias de etnia
                categorias = {
                    'Preta': {'taxa': 'Taxa Preta', 'prof': 'Profici√™ncia Preta', 'numero': 'N√∫mero Preta', 'cor_base': COR_PRIMARIA},
                    'Branca': {'taxa': 'Taxa Branca', 'prof': 'Profici√™ncia Branca', 'numero': 'N√∫mero Branca', 'cor_base': COR_SECUNDARIA},
                    'Parda': {'taxa': 'Taxa Parda', 'prof': 'Profici√™ncia Parda', 'numero': 'N√∫mero Parda', 'cor_base': COR_SUCESSO},
                    'Amarela': {'taxa': 'Taxa Amarela', 'prof': 'Profici√™ncia Amarela', 'numero': 'N√∫mero Amarela', 'cor_base': COR_DANGER},
                    'Ind√≠gena': {'taxa': 'Taxa Ind√≠gena', 'prof': 'Profici√™ncia Ind√≠gena', 'numero': 'N√∫mero Ind√≠gena', 'cor_base': COR_LIGHT}
                }
                
                # Fun√ß√£o para calcular cor baseada na profici√™ncia (laranja -> verde)
                def calcular_cor_intensidade(cor_base_hex, proficiencia, prof_min, prof_max):
                    """Calcula a cor variando de laranja (baixa profici√™ncia) a verde (alta profici√™ncia)"""
                    # Cores: Laranja para profici√™ncia baixa, Verde para profici√™ncia alta
                    # Laranja: #FF6B35 (255, 107, 53)
                    # Amarelo intermedi√°rio: #FFB830 (255, 184, 48)
                    # Verde claro: #87C147 (135, 193, 71)
                    # Verde escuro: #2E7D32 (46, 125, 50)
                    
                    # Normalizar profici√™ncia entre 0 e 1
                    if prof_max > prof_min:
                        normalizado = (proficiencia - prof_min) / (prof_max - prof_min)
                    else:
                        normalizado = 0.5
                    
                    # Interpolar cores de acordo com a profici√™ncia
                    if normalizado < 0.33:  # Laranja a Amarelo
                        # Escalar de 0-0.33 para 0-1
                        t = normalizado / 0.33
                        r = int(255)  # Mant√©m vermelho alto
                        g = int(107 + (184 - 107) * t)  # De 107 a 184
                        b = int(53 + (48 - 53) * t)  # De 53 a 48
                    elif normalizado < 0.67:  # Amarelo a Verde claro
                        # Escalar de 0.33-0.67 para 0-1
                        t = (normalizado - 0.33) / 0.34
                        r = int(255 - (255 - 135) * t)  # De 255 a 135
                        g = int(184 + (193 - 184) * t)  # De 184 a 193
                        b = int(48 + (71 - 48) * t)  # De 48 a 71
                    else:  # Verde claro a Verde escuro
                        # Escalar de 0.67-1.0 para 0-1
                        t = (normalizado - 0.67) / 0.33
                        r = int(135 - (135 - 46) * t)  # De 135 a 46
                        g = int(193 - (193 - 125) * t)  # De 193 a 125
                        b = int(71 - (71 - 50) * t)  # De 71 a 50
                    
                    return f'rgb({r},{g},{b})'
                
                # Calcular profici√™ncia m√≠nima e m√°xima para normaliza√ß√£o
                todas_proficiencias = []
                for cat_info in categorias.values():
                    if cat_info['prof'] in df_plot.columns:
                        todas_proficiencias.extend(df_plot[cat_info['prof']].dropna().tolist())
                
                prof_min = min(todas_proficiencias) if todas_proficiencias else 0
                prof_max = max(todas_proficiencias) if todas_proficiencias else 100
                
                # Preparar dados para cada tipo de entidade e categoria
                for tipo_entidade in df_plot['Tipo Simplificado']:
                    for cat_nome, cat_info in categorias.items():
                        if cat_info['taxa'] in df_plot.columns and cat_info['prof'] in df_plot.columns and cat_info['numero'] in df_plot.columns:
                            dados_tipo = df_plot[df_plot['Tipo Simplificado'] == tipo_entidade]
                            if not dados_tipo.empty:
                                taxa = dados_tipo[cat_info['taxa']].values[0]
                                proficiencia = dados_tipo[cat_info['prof']].values[0]
                                numero = dados_tipo[cat_info['numero']].values[0]
                                
                                if pd.notna(taxa) and pd.notna(proficiencia) and pd.notna(numero):
                                    cor = calcular_cor_intensidade(cat_info['cor_base'], proficiencia, prof_min, prof_max)
                                    
                                    dados_grafico.append({
                                        'Tipo de Entidade': tipo_entidade,
                                        'Etnia': cat_nome,
                                        'Taxa': taxa,
                                        'Profici√™ncia': proficiencia,
                                        'Numero': numero,
                                        'Cor': cor,
                                        'Label': f"{cat_nome}<br>{taxa:.1f}%".replace('.', ',')
                                    })
                
                # Criar DataFrame dos dados
                df_grafico = pd.DataFrame(dados_grafico)
                
                if not df_grafico.empty:
                    # Criar gr√°fico
                    fig_etnia = go.Figure()
                    
                    # Definir ordem dos tipos de entidade
                    ordem_tipos = ['Cear√°', 'CREDE', 'Munic√≠pio', 'Escola']
                    
                    # Adicionar barras para cada etnia
                    categorias_etnias = df_grafico['Etnia'].unique()
                    
                    for etnia in categorias_etnias:
                        df_etnia_cat = df_grafico[df_grafico['Etnia'] == etnia].copy()
                        
                        # Ordenar pelo tipo de entidade usando a ordem definida
                        df_etnia_cat['Ordem'] = df_etnia_cat['Tipo de Entidade'].map({t: i for i, t in enumerate(ordem_tipos)})
                        df_etnia_cat = df_etnia_cat.sort_values('Ordem')
                        
                        fig_etnia.add_trace(go.Bar(
                            name=etnia,
                            x=df_etnia_cat['Tipo de Entidade'],
                            y=df_etnia_cat['Taxa'],
                            marker=dict(
                                color=df_etnia_cat['Cor'].tolist(),
                                line=dict(color='rgba(0,0,0,0.3)', width=1)
                            ),
                            text=[f"{e}<br>{t:.1f}%<br>Prof: {p:.0f}<br>N: {n:.0f}".replace('.', ',') for e, t, p, n in zip(df_etnia_cat['Etnia'], df_etnia_cat['Taxa'], df_etnia_cat['Profici√™ncia'], df_etnia_cat['Numero'])],
                            textposition='outside',
                            textfont=dict(size=12, family='Arial', color='black'),
                            textangle=-90,
                            hovertemplate='<b style="font-size:18px">Tipo: %{x}</b><br><span style="font-size:16px">Etnia: ' + etnia + '<br>Percentual de Alunos: %{y:.1f}%<br>Profici√™ncia: %{customdata[0]:.1f}<br>N√∫mero de Alunos: %{customdata[1]:,}</span><extra></extra>'.replace('%{y:.1f}%', '%{y:.1f}%').replace('%{customdata[0]:.1f}', '%{customdata[0]:.1f}').replace('.', ','),
                            customdata=list(zip(df_etnia_cat['Profici√™ncia'], df_etnia_cat['Numero'])),
                            showlegend=False
                        ))
                    
                    # Tipos dispon√≠veis na ordem correta
                    tipos_disponiveis = [t for t in ordem_tipos if t in df_grafico['Tipo de Entidade'].unique()]
                    
                    # Configurar o layout do gr√°fico
                    fig_etnia.update_layout(
                        title=dict(
                            text=f'üë• Taxa (altura) e Profici√™ncia (cor) por Etnia<br><sub style="font-size:14px;">üü† Laranja = Profici√™ncia Baixa | üü° Amarelo = Profici√™ncia M√©dia | üü¢ Verde = Profici√™ncia Alta | Escala: {prof_min:.0f} - {prof_max:.0f}</sub>',
                            font=dict(size=18, family='Arial Black')
                        ),
                        xaxis_title=dict(
                            text='Tipo de Entidade',
                            font=dict(size=18)
                        ),
                        yaxis_title=dict(
                            text='Taxa (%)',
                            font=dict(size=18)
                        ),
                        font=dict(size=14),
                        height=450,
                        barmode='group',
                        bargap=0.2,
                        bargroupgap=0.15,
                        yaxis=dict(
                            range=[0, 110],
                            tickfont=dict(size=14)
                        ),
                        showlegend=False,
                        xaxis=dict(
                            categoryorder='array',
                            categoryarray=tipos_disponiveis,
                            tickfont=dict(size=14)
                        ),
                        hoverlabel=dict(
                            font_size=20,
                            font_family="Arial"
                        )
                    )
                    
                    # Exibir o gr√°fico
                    st.plotly_chart(fig_etnia, use_container_width=True)
                else:
                    st.info("N√£o foi poss√≠vel gerar o gr√°fico com os dados dispon√≠veis")
            else:
                st.info("Dados de taxa e profici√™ncia por etnia insuficientes para gerar o gr√°fico ou coluna de tipo de entidade n√£o dispon√≠vel")
            
            st.download_button(
                "üì• Baixar Dados de Etnia",
                data=csv_etnia,
                file_name="proficiencia_etnia.csv",
                mime="text/csv",
                key="download_etnia"
            )
            
            # An√°lise com Groq
            with st.expander("ü§ñ An√°lise Inteligente - Profici√™ncia por Etnia", expanded=False):
                if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                    st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                    
                    # Criar chave √∫nica baseada nos filtros atuais
                    etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                    disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                    key_analise = f"analise_etnia_{etapa_filtro}_{disciplina_filtro}"
                    
                    if st.button("üîç Analisar Dados com IA", key=key_analise):
                        with st.spinner("ü§ñ Analisando dados com IA..."):
                            analise = analisar_dataframe_com_groq(
                                df_etnia, 
                                "Profici√™ncia por Etnia", 
                            "An√°lise das diferen√ßas de profici√™ncia entre grupos √©tnicos nas avalia√ß√µes SPAECE",
                            st.session_state.agregado_consultado,
                            st.session_state.df_concatenado
                        )
                        st.markdown(analise)
                elif not st.session_state.get('documentos_carregados', False):
                    st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
                else:
                    st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
        else:
            st.info("Sem dados v√°lidos de profici√™ncia por etnia ap√≥s limpeza")
    else:
        st.info("Colunas de etnia n√£o encontradas no conjunto de dados")
    
    
    # Quebra de p√°gina antes da se√ß√£o de NSE (removida para evitar p√°ginas vazias)
    # st.markdown("""
    # <div style="page-break-before: always; break-before: page;">
    # </div>
    # """, unsafe_allow_html=True)
    
    # ==================== DADOS CONTEXTUAIS - NSE ====================
    colunas_nse = ['TP_ENTIDADE', 'DC_TIPO_ENTIDADE', 'NM_ENTIDADE', 'VL_FILTRO_DISCIPLINA', 'VL_FILTRO_ETAPA', 'VL_NSE1', 
                   'VL_NSE2', 'VL_NSE3', 'VL_NSE4', 'TX_NSE1','TX_NSE2','TX_NSE3','TX_NSE4',
                   'NU_NSE1','NU_NSE2','NU_NSE3','NU_NSE4']
    colunas_nse_disponiveis = [col for col in colunas_nse if col in df_concat.columns]
    
    if len(colunas_nse_disponiveis) >= 4:
        # Quebra de p√°gina antes da se√ß√£o de NSE (s√≥ se houver dados)
        st.markdown("""
        <div style="page-break-before: always; break-before: page;">
        </div>
        """, unsafe_allow_html=True)
        
        # S√≥ exibir o header se houver dados
        st.markdown(f"""
        <div class="report-header" style="background: linear-gradient(135deg, {COR_SECUNDARIA}, #e67e22, #d35400);">
            üí∞ PROFICI√äNCIA POR N√çVEL SOCIOECON√îMICO (NSE)
        </div>
        """, unsafe_allow_html=True)
        
        # Help para an√°lise do gr√°fico
        with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
            st.markdown("""
            **üí∞ Profici√™ncia por N√≠vel Socioecon√¥mico (NSE) - Informa√ß√µes T√©cnicas**
            
            **Constru√ß√£o do gr√°fico:**
            - **Tipo:** Gr√°fico de barras agrupadas (grouped bar chart)
            - **Eixo X:** Entidades (Estado, CREDE, Munic√≠pio, Escola)
            - **Eixo Y:** Taxa de participa√ß√£o (0% a 100%)
            - **Cores:** Baseadas na profici√™ncia m√©dia de cada n√≠vel NSE
            
            **O que representa:**
            - **Altura da barra:** Taxa de participa√ß√£o por n√≠vel NSE
            - **Cor da barra:** Profici√™ncia m√©dia do n√≠vel (escala din√¢mica)
            - **N√≠veis NSE:** NSE 1 (mais baixo) a NSE 4 (mais alto)
            
            **Como ler:**
            - **Altura:** Percentual de participa√ß√£o na avalia√ß√£o
            - **Cor:** N√≠vel de profici√™ncia (üü† Baixa, üü° M√©dia, üü¢ Alta)
            - **Legenda:** Escala de profici√™ncia din√¢mica
            - **Hover:** Valores espec√≠ficos de participa√ß√£o e profici√™ncia
            
            **Dados dispon√≠veis:**
            - **Taxa de Participa√ß√£o:** Percentual de alunos que participaram
            - **Profici√™ncia M√©dia:** Pontua√ß√£o m√©dia do n√≠vel NSE
            - **N√∫mero de Alunos:** Quantidade de estudantes por n√≠vel
            """)
        
        df_nse = df_concat[colunas_nse_disponiveis].copy()
        
        colunas_valores_nse = ['VL_NSE1', 'VL_NSE2', 'VL_NSE3', 'VL_NSE4', 
                              'NU_NSE1', 'NU_NSE2', 'NU_NSE3', 'NU_NSE4',
                              'TX_NSE1','TX_NSE2','TX_NSE3','TX_NSE4']
        df_nse = converter_para_numerico(df_nse, colunas_valores_nse)
        
        colunas_nse_valores = [col for col in colunas_valores_nse if col in df_nse.columns]
        if colunas_nse_valores:
            df_nse = df_nse.dropna(subset=colunas_nse_valores, how='all')
        
        if not df_nse.empty:
            renomear = {
                'TP_ENTIDADE': 'Tipo de Entidade C√≥digo',
                'DC_TIPO_ENTIDADE': 'Tipo de Entidade',
                'NM_ENTIDADE': 'Entidade',
                'VL_FILTRO_DISCIPLINA': 'Componente Curricular',
                'VL_FILTRO_ETAPA': 'Etapa',
                'VL_NSE1': 'Profici√™ncia NSE 1 (Mais Baixo)',
                'VL_NSE2': 'Profici√™ncia NSE 2',
                'VL_NSE3': 'Profici√™ncia NSE 3',
                'VL_NSE4': 'Profici√™ncia NSE 4 (Mais Alto)',
                'NU_NSE1': 'N√∫mero NSE 1',
                'NU_NSE2': 'N√∫mero NSE 2',
                'NU_NSE3': 'N√∫mero NSE 3',
                'NU_NSE4': 'N√∫mero NSE 4',
                'TX_NSE1': 'Taxa NSE 1',
                'TX_NSE2': 'Taxa NSE 2',
                'TX_NSE3': 'Taxa NSE 3',
                'TX_NSE4': 'Taxa NSE 4'
            }
            df_nse = df_nse.rename(columns={k: v for k, v in renomear.items() if k in df_nse.columns})
            
            st.info(f"üìä {len(df_nse)} registros com dados de profici√™ncia por NSE")
            # st.dataframe(df_nse, use_container_width=True, height=400)
            
            # Criar gr√°fico para NSE
            st.subheader("Gr√°fico de Taxa e Profici√™ncia por NSE - Por Tipo de Entidade")
            
            # Verificar quais colunas est√£o dispon√≠veis
            colunas_taxa_nse = [col for col in ['Taxa NSE 1', 'Taxa NSE 2', 
                                                'Taxa NSE 3', 'Taxa NSE 4'] if col in df_nse.columns]
            
            colunas_prof_nse = [col for col in ['Profici√™ncia NSE 1 (Mais Baixo)', 'Profici√™ncia NSE 2', 
                                                'Profici√™ncia NSE 3', 'Profici√™ncia NSE 4 (Mais Alto)'] if col in df_nse.columns]
            
            if colunas_taxa_nse and colunas_prof_nse and ('Tipo de Entidade C√≥digo' in df_nse.columns or 'Tipo de Entidade' in df_nse.columns):
                # Preparar dados para o gr√°fico
                df_plot_nse = df_nse.copy()
                
                # Mapear tipos de entidade para nomes amig√°veis
                mapa_tipos = {
                    '01': 'Cear√°',
                    '02': 'CREDE',
                    '11': 'Munic√≠pio',
                    '03': 'Escola',
                    'Estado': 'Cear√°',
                    'Regional': 'CREDE',
                    'Munic√≠pio': 'Munic√≠pio',
                    'Escola': 'Escola'
                }
                
                # Criar coluna com tipo de entidade amig√°vel
                if 'Tipo de Entidade C√≥digo' in df_plot_nse.columns:
                    df_plot_nse['Tipo Simplificado'] = df_plot_nse['Tipo de Entidade C√≥digo'].map(mapa_tipos)
                    if df_plot_nse['Tipo Simplificado'].isna().any() and 'Tipo de Entidade' in df_plot_nse.columns:
                        df_plot_nse['Tipo Simplificado'] = df_plot_nse['Tipo Simplificado'].fillna(
                            df_plot_nse['Tipo de Entidade'].map(mapa_tipos)
                        )
                elif 'Tipo de Entidade' in df_plot_nse.columns:
                    df_plot_nse['Tipo Simplificado'] = df_plot_nse['Tipo de Entidade'].map(mapa_tipos)
                
                # Agrupar por tipo de entidade e calcular a m√©dia
                colunas_numero_nse = [col for col in ['N√∫mero NSE 1', 'N√∫mero NSE 2', 
                                                    'N√∫mero NSE 3', 'N√∫mero NSE 4'] if col in df_plot_nse.columns]
                todas_colunas_nse = colunas_taxa_nse + colunas_prof_nse + colunas_numero_nse
                df_plot_nse = df_plot_nse.groupby('Tipo Simplificado')[todas_colunas_nse].mean().reset_index()
                
                # Criar lista de dados para o gr√°fico
                dados_grafico_nse = []
                
                # Categorias de NSE
                categorias_nse = {
                     'NSE 1 (Mais Baixo)': {'taxa': 'Taxa NSE 1', 'prof': 'Profici√™ncia NSE 1 (Mais Baixo)', 'numero': 'N√∫mero NSE 1', 'cor_base': COR_DANGER},
                     'NSE 2': {'taxa': 'Taxa NSE 2', 'prof': 'Profici√™ncia NSE 2', 'numero': 'N√∫mero NSE 2', 'cor_base': COR_SECUNDARIA},
                     'NSE 3': {'taxa': 'Taxa NSE 3', 'prof': 'Profici√™ncia NSE 3', 'numero': 'N√∫mero NSE 3', 'cor_base': COR_PRIMARIA},
                     'NSE 4 (Mais Alto)': {'taxa': 'Taxa NSE 4', 'prof': 'Profici√™ncia NSE 4 (Mais Alto)', 'numero': 'N√∫mero NSE 4', 'cor_base': COR_SUCESSO}
                }
                
                # Fun√ß√£o para calcular cor baseada na profici√™ncia
                def calcular_cor_intensidade_nse(cor_base_hex, proficiencia, prof_min, prof_max):
                    if prof_max > prof_min:
                        normalizado = (proficiencia - prof_min) / (prof_max - prof_min)
                    else:
                        normalizado = 0.5
                    
                    if normalizado < 0.33:
                        t = normalizado / 0.33
                        r = int(255)
                        g = int(107 + (184 - 107) * t)
                        b = int(53 + (48 - 53) * t)
                    elif normalizado < 0.67:
                        t = (normalizado - 0.33) / 0.34
                        r = int(255 - (255 - 135) * t)
                        g = int(184 + (193 - 184) * t)
                        b = int(48 + (71 - 48) * t)
                    else:
                        t = (normalizado - 0.67) / 0.33
                        r = int(135 - (135 - 46) * t)
                        g = int(193 - (193 - 125) * t)
                        b = int(71 - (71 - 50) * t)
                    
                    return f'rgb({r},{g},{b})'
                
                # Calcular profici√™ncia m√≠nima e m√°xima
                todas_proficiencias_nse = []
                for cat_info in categorias_nse.values():
                    if cat_info['prof'] in df_plot_nse.columns:
                        todas_proficiencias_nse.extend(df_plot_nse[cat_info['prof']].dropna().tolist())
                
                prof_min_nse = min(todas_proficiencias_nse) if todas_proficiencias_nse else 0
                prof_max_nse = max(todas_proficiencias_nse) if todas_proficiencias_nse else 100
                
                # Preparar dados para cada tipo de entidade e categoria
                for tipo_entidade in df_plot_nse['Tipo Simplificado']:
                    for cat_nome, cat_info in categorias_nse.items():
                        if cat_info['taxa'] in df_plot_nse.columns and cat_info['prof'] in df_plot_nse.columns and cat_info['numero'] in df_plot_nse.columns:
                            dados_tipo = df_plot_nse[df_plot_nse['Tipo Simplificado'] == tipo_entidade]
                            if not dados_tipo.empty:
                                taxa = dados_tipo[cat_info['taxa']].values[0]
                                proficiencia = dados_tipo[cat_info['prof']].values[0]
                                numero = dados_tipo[cat_info['numero']].values[0]
                                
                                if pd.notna(taxa) and pd.notna(proficiencia) and pd.notna(numero):
                                    cor = calcular_cor_intensidade_nse(cat_info['cor_base'], proficiencia, prof_min_nse, prof_max_nse)
                                    
                                    dados_grafico_nse.append({
                                        'Tipo de Entidade': tipo_entidade,
                                        'NSE': cat_nome,
                                        'Taxa': taxa,
                                        'Profici√™ncia': proficiencia,
                                        'Numero': numero,
                                        'Cor': cor,
                                        'Label': f"{cat_nome}<br>{taxa:.1f}%".replace('.', ',')
                                    })
                
                # Criar DataFrame dos dados
                df_grafico_nse = pd.DataFrame(dados_grafico_nse)
                
                if not df_grafico_nse.empty:
                    # Criar gr√°fico
                    fig_nse = go.Figure()
                    
                    # Definir ordem dos tipos de entidade
                    ordem_tipos = ['Cear√°', 'CREDE', 'Munic√≠pio', 'Escola']
                    
                    # Adicionar barras para cada NSE
                    categorias_nse_grafico = df_grafico_nse['NSE'].unique()
                    
                    for nse in categorias_nse_grafico:
                        df_nse_cat = df_grafico_nse[df_grafico_nse['NSE'] == nse].copy()
                        
                        # Ordenar pelo tipo de entidade
                        df_nse_cat['Ordem'] = df_nse_cat['Tipo de Entidade'].map({t: i for i, t in enumerate(ordem_tipos)})
                        df_nse_cat = df_nse_cat.sort_values('Ordem')
                        
                        fig_nse.add_trace(go.Bar(
                            name=nse,
                            x=df_nse_cat['Tipo de Entidade'],
                            y=df_nse_cat['Taxa'],
                            marker=dict(
                                color=df_nse_cat['Cor'].tolist(),
                                line=dict(color='rgba(0,0,0,0.3)', width=1)
                            ),
                             text=[f"{n}<br>{t:.1f}%<br>Prof: {p:.0f}<br>N: {num:.0f}".replace('.', ',') for n, t, p, num in zip(df_nse_cat['NSE'], df_nse_cat['Taxa'], df_nse_cat['Profici√™ncia'], df_nse_cat['Numero'])],
                             textposition='outside',
                             textfont=dict(size=12, family='Arial', color='black'),
                             textangle=-90,
                            hovertemplate='<b style="font-size:18px">Tipo: %{x}</b><br><span style="font-size:16px">NSE: ' + nse + '<br>Taxa: %{y:.1f}%<br>Profici√™ncia: %{customdata:.1f}</span><extra></extra>'.replace('%{y:.1f}%', '%{y:.1f}%').replace('%{customdata:.1f}', '%{customdata:.1f}').replace('.', ','),
                            customdata=df_nse_cat['Profici√™ncia'],
                            showlegend=False
                        ))
                    
                    # Tipos dispon√≠veis na ordem correta
                    tipos_disponiveis_nse = [t for t in ordem_tipos if t in df_grafico_nse['Tipo de Entidade'].unique()]
                    
                    # Configurar o layout do gr√°fico
                    fig_nse.update_layout(
                        title=dict(
                            text=f'üìä Taxa (altura) e Profici√™ncia (cor) por NSE<br><sub style="font-size:14px;">üü† Laranja = Profici√™ncia Baixa | üü° Amarelo = Profici√™ncia M√©dia | üü¢ Verde = Profici√™ncia Alta | Escala: {prof_min_nse:.0f} - {prof_max_nse:.0f}</sub>',
                            font=dict(size=18, family='Arial Black')
                        ),
                        xaxis_title=dict(
                            text='Tipo de Entidade',
                            font=dict(size=18)
                        ),
                        yaxis_title=dict(
                            text='Taxa (%)',
                            font=dict(size=18)
                        ),
                        font=dict(size=14),
                        height=450,
                        barmode='group',
                        bargap=0.2,
                        bargroupgap=0.15,
                        yaxis=dict(
                            range=[0, 110],
                            tickfont=dict(size=14)
                        ),
                        showlegend=False,
                        xaxis=dict(
                            categoryorder='array',
                            categoryarray=tipos_disponiveis_nse,
                            tickfont=dict(size=14)
                        ),
                        hoverlabel=dict(
                            font_size=20,
                            font_family="Arial"
                        )
                    )
                    
                    # Exibir o gr√°fico
                    st.plotly_chart(fig_nse, use_container_width=True)
                else:
                    st.info("N√£o foi poss√≠vel gerar o gr√°fico com os dados dispon√≠veis")
            else:
                st.info("Dados de taxa e profici√™ncia por NSE insuficientes para gerar o gr√°fico ou coluna de tipo de entidade n√£o dispon√≠vel")
            
            csv_nse = df_nse.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• Baixar Dados de NSE",
                data=csv_nse,
                file_name="proficiencia_nse.csv",
                mime="text/csv",
                key="download_nse"
            )
            
            # An√°lise com Groq
            with st.expander("ü§ñ An√°lise Inteligente - Profici√™ncia por NSE", expanded=False):
                if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                    st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                    
                    # Criar chave √∫nica baseada nos filtros atuais
                    etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                    disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                    key_analise = f"analise_nse_{etapa_filtro}_{disciplina_filtro}"
                    
                    if st.button("üîç Analisar Dados com IA", key=key_analise):
                        with st.spinner("ü§ñ Analisando dados com IA..."):
                            analise = analisar_dataframe_com_groq(
                                df_nse, 
                                "Profici√™ncia por NSE", 
                            "An√°lise das diferen√ßas de profici√™ncia entre n√≠veis socioecon√¥micos nas avalia√ß√µes SPAECE",
                            st.session_state.agregado_consultado,
                            st.session_state.df_concatenado
                        )
                        st.markdown(analise)
                elif not st.session_state.get('documentos_carregados', False):
                    st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
                else:
                    st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
    
    # ==================== DADOS CONTEXTUAIS - SEXO ====================
    colunas_sexo = ['TP_ENTIDADE', 'DC_TIPO_ENTIDADE', 'NM_ENTIDADE', 'VL_FILTRO_DISCIPLINA', 'VL_FILTRO_ETAPA', 'VL_FEMININO', 
                   'VL_MASCULINO', 'TX_FEMININO','TX_MASCULINO','NU_FEMININO','NU_MASCULINO']
    colunas_sexo_disponiveis = [col for col in colunas_sexo if col in df_concat.columns]
    
    if len(colunas_sexo_disponiveis) >= 4:
        # Quebra de p√°gina antes da se√ß√£o de sexo (s√≥ se houver dados)
        st.markdown("""
        <div style="page-break-before: always; break-before: page;">
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="report-header" style="background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
            üë´ PROFICI√äNCIA POR SEXO
        </div>
        """, unsafe_allow_html=True)
        
        # Help para an√°lise do gr√°fico
        with st.expander("‚ÑπÔ∏è Como analisar este gr√°fico", expanded=False):
            st.markdown("""
            **üë´ Profici√™ncia por Sexo - Informa√ß√µes T√©cnicas**
            
            **Constru√ß√£o do gr√°fico:**
            - **Tipo:** Gr√°fico de barras agrupadas (grouped bar chart)
            - **Eixo X:** Entidades (Estado, CREDE, Munic√≠pio, Escola)
            - **Eixo Y:** Taxa de participa√ß√£o (0% a 100%)
            - **Cores:** Baseadas na profici√™ncia m√©dia de cada sexo
            
            **O que representa:**
            - **Altura da barra:** Taxa de participa√ß√£o por sexo
            - **Cor da barra:** Profici√™ncia m√©dia do sexo (escala din√¢mica)
            - **Grupos:** Feminino e Masculino
            
            **Como ler:**
            - **Altura:** Percentual de participa√ß√£o na avalia√ß√£o
            - **Cor:** N√≠vel de profici√™ncia (üü† Baixa, üü° M√©dia, üü¢ Alta)
            - **Legenda:** Escala de profici√™ncia din√¢mica
            - **Hover:** Valores espec√≠ficos de participa√ß√£o e profici√™ncia
            
            **Dados dispon√≠veis:**
            - **Taxa de Participa√ß√£o:** Percentual de alunos que participaram
            - **Profici√™ncia M√©dia:** Pontua√ß√£o m√©dia por sexo
            - **N√∫mero de Alunos:** Quantidade de estudantes por sexo
            """)
        
        df_sexo = df_concat[colunas_sexo_disponiveis].copy()
        
        colunas_valores_sexo = ['VL_FEMININO', 'VL_MASCULINO', 'NU_FEMININO', 
                               'NU_MASCULINO', 'TX_FEMININO', 'TX_MASCULINO']
        df_sexo = converter_para_numerico(df_sexo, colunas_valores_sexo)
        
        colunas_sexo_valores = [col for col in colunas_valores_sexo if col in df_sexo.columns]
        if colunas_sexo_valores:
            df_sexo = df_sexo.dropna(subset=colunas_sexo_valores, how='all')
        
        if not df_sexo.empty:
            renomear = {
                'TP_ENTIDADE': 'Tipo de Entidade C√≥digo',
                'DC_TIPO_ENTIDADE': 'Tipo de Entidade',
                'NM_ENTIDADE': 'Entidade',
                'VL_FILTRO_DISCIPLINA': 'Componente Curricular',
                'VL_FILTRO_ETAPA': 'Etapa',
                'VL_FEMININO': 'Profici√™ncia Feminino',
                'VL_MASCULINO': 'Profici√™ncia Masculino',
                'NU_FEMININO': 'N√∫mero Feminino',
                'NU_MASCULINO': 'N√∫mero Masculino',
                'TX_FEMININO': 'Taxa Feminino',
                'TX_MASCULINO': 'Taxa Masculino'
            }
            df_sexo = df_sexo.rename(columns={k: v for k, v in renomear.items() if k in df_sexo.columns})
            
            st.info(f"üìä {len(df_sexo)} registros com dados de profici√™ncia por sexo")
            # st.dataframe(df_sexo, use_container_width=True, height=400)
            
            # Criar gr√°fico para Sexo
            st.subheader("Gr√°fico de Taxa e Profici√™ncia por Sexo - Por Tipo de Entidade")
            
            # Verificar quais colunas est√£o dispon√≠veis
            colunas_taxa_sexo = [col for col in ['Taxa Feminino', 'Taxa Masculino'] if col in df_sexo.columns]
            
            colunas_prof_sexo = [col for col in ['Profici√™ncia Feminino', 'Profici√™ncia Masculino'] if col in df_sexo.columns]
            
            if colunas_taxa_sexo and colunas_prof_sexo and ('Tipo de Entidade C√≥digo' in df_sexo.columns or 'Tipo de Entidade' in df_sexo.columns):
                # Preparar dados para o gr√°fico
                df_plot_sexo = df_sexo.copy()
                
                # Mapear tipos de entidade para nomes amig√°veis
                mapa_tipos = {
                    '01': 'Cear√°',
                    '02': 'CREDE',
                    '11': 'Munic√≠pio',
                    '03': 'Escola',
                    'Estado': 'Cear√°',
                    'Regional': 'CREDE',
                    'Munic√≠pio': 'Munic√≠pio',
                    'Escola': 'Escola'
                }
                
                # Criar coluna com tipo de entidade amig√°vel
                if 'Tipo de Entidade C√≥digo' in df_plot_sexo.columns:
                    df_plot_sexo['Tipo Simplificado'] = df_plot_sexo['Tipo de Entidade C√≥digo'].map(mapa_tipos)
                    if df_plot_sexo['Tipo Simplificado'].isna().any() and 'Tipo de Entidade' in df_plot_sexo.columns:
                        df_plot_sexo['Tipo Simplificado'] = df_plot_sexo['Tipo Simplificado'].fillna(
                            df_plot_sexo['Tipo de Entidade'].map(mapa_tipos)
                        )
                elif 'Tipo de Entidade' in df_plot_sexo.columns:
                    df_plot_sexo['Tipo Simplificado'] = df_plot_sexo['Tipo de Entidade'].map(mapa_tipos)
                
                # Agrupar por tipo de entidade e calcular a m√©dia
                colunas_numero_sexo = [col for col in ['N√∫mero Feminino', 'N√∫mero Masculino'] if col in df_plot_sexo.columns]
                todas_colunas_sexo = colunas_taxa_sexo + colunas_prof_sexo + colunas_numero_sexo
                df_plot_sexo = df_plot_sexo.groupby('Tipo Simplificado')[todas_colunas_sexo].mean().reset_index()
                
                # Criar lista de dados para o gr√°fico
                dados_grafico_sexo = []
                
                # Categorias de Sexo
                categorias_sexo = {
                    'Feminino': {'taxa': 'Taxa Feminino', 'prof': 'Profici√™ncia Feminino', 'numero': 'N√∫mero Feminino', 'cor_base': COR_SECUNDARIA},
                    'Masculino': {'taxa': 'Taxa Masculino', 'prof': 'Profici√™ncia Masculino', 'numero': 'N√∫mero Masculino', 'cor_base': COR_PRIMARIA}
                }
                
                # Fun√ß√£o para calcular cor baseada na profici√™ncia
                def calcular_cor_intensidade_sexo(cor_base_hex, proficiencia, prof_min, prof_max):
                    if prof_max > prof_min:
                        normalizado = (proficiencia - prof_min) / (prof_max - prof_min)
                    else:
                        normalizado = 0.5
                    
                    if normalizado < 0.33:
                        t = normalizado / 0.33
                        r = int(255)
                        g = int(107 + (184 - 107) * t)
                        b = int(53 + (48 - 53) * t)
                    elif normalizado < 0.67:
                        t = (normalizado - 0.33) / 0.34
                        r = int(255 - (255 - 135) * t)
                        g = int(184 + (193 - 184) * t)
                        b = int(48 + (71 - 48) * t)
                    else:
                        t = (normalizado - 0.67) / 0.33
                        r = int(135 - (135 - 46) * t)
                        g = int(193 - (193 - 125) * t)
                        b = int(71 - (71 - 50) * t)
                    
                    return f'rgb({r},{g},{b})'
                
                # Calcular profici√™ncia m√≠nima e m√°xima
                todas_proficiencias_sexo = []
                for cat_info in categorias_sexo.values():
                    if cat_info['prof'] in df_plot_sexo.columns:
                        todas_proficiencias_sexo.extend(df_plot_sexo[cat_info['prof']].dropna().tolist())
                
                prof_min_sexo = min(todas_proficiencias_sexo) if todas_proficiencias_sexo else 0
                prof_max_sexo = max(todas_proficiencias_sexo) if todas_proficiencias_sexo else 100
                
                # Preparar dados para cada tipo de entidade e categoria
                for tipo_entidade in df_plot_sexo['Tipo Simplificado']:
                    for cat_nome, cat_info in categorias_sexo.items():
                        if cat_info['taxa'] in df_plot_sexo.columns and cat_info['prof'] in df_plot_sexo.columns and cat_info['numero'] in df_plot_sexo.columns:
                            dados_tipo = df_plot_sexo[df_plot_sexo['Tipo Simplificado'] == tipo_entidade]
                            if not dados_tipo.empty:
                                taxa = dados_tipo[cat_info['taxa']].values[0]
                                proficiencia = dados_tipo[cat_info['prof']].values[0]
                                numero = dados_tipo[cat_info['numero']].values[0]
                                
                                if pd.notna(taxa) and pd.notna(proficiencia) and pd.notna(numero):
                                    cor = calcular_cor_intensidade_sexo(cat_info['cor_base'], proficiencia, prof_min_sexo, prof_max_sexo)
                                    
                                    dados_grafico_sexo.append({
                                        'Tipo de Entidade': tipo_entidade,
                                        'Sexo': cat_nome,
                                        'Taxa': taxa,
                                        'Profici√™ncia': proficiencia,
                                        'Numero': numero,
                                        'Cor': cor,
                                        'Label': f"{cat_nome}<br>{taxa:.1f}%".replace('.', ',')
                                    })
                
                # Criar DataFrame dos dados
                df_grafico_sexo = pd.DataFrame(dados_grafico_sexo)
                
                if not df_grafico_sexo.empty:
                    # Criar gr√°fico
                    fig_sexo = go.Figure()
                    
                    # Definir ordem dos tipos de entidade
                    ordem_tipos = ['Cear√°', 'CREDE', 'Munic√≠pio', 'Escola']
                    
                    # Adicionar barras para cada Sexo
                    categorias_sexo_grafico = df_grafico_sexo['Sexo'].unique()
                    
                    for sexo in categorias_sexo_grafico:
                        df_sexo_cat = df_grafico_sexo[df_grafico_sexo['Sexo'] == sexo].copy()
                        
                        # Ordenar pelo tipo de entidade
                        df_sexo_cat['Ordem'] = df_sexo_cat['Tipo de Entidade'].map({t: i for i, t in enumerate(ordem_tipos)})
                        df_sexo_cat = df_sexo_cat.sort_values('Ordem')
                        
                        fig_sexo.add_trace(go.Bar(
                            name=sexo,
                            x=df_sexo_cat['Tipo de Entidade'],
                            y=df_sexo_cat['Taxa'],
                            marker=dict(
                                color=df_sexo_cat['Cor'].tolist(),
                                line=dict(color='rgba(0,0,0,0.3)', width=1)
                            ),
                            text=[f"{s}<br>{t:.1f}%<br>Prof: {p:.0f}<br>N: {num:.0f}".replace('.', ',') for s, t, p, num in zip(df_sexo_cat['Sexo'], df_sexo_cat['Taxa'], df_sexo_cat['Profici√™ncia'], df_sexo_cat['Numero'])],
                            textposition='outside',
                            textfont=dict(size=12, family='Arial', color='black'),
                            textangle=-90,
                            hovertemplate='<b style="font-size:18px">Tipo: %{x}</b><br><span style="font-size:16px">Sexo: ' + sexo + '<br>Taxa: %{y:.1f}%<br>Profici√™ncia: %{customdata:.1f}</span><extra></extra>'.replace('%{y:.1f}%', '%{y:.1f}%').replace('%{customdata:.1f}', '%{customdata:.1f}').replace('.', ','),
                            customdata=df_sexo_cat['Profici√™ncia'],
                            showlegend=False
                        ))
                    
                    # Tipos dispon√≠veis na ordem correta
                    tipos_disponiveis_sexo = [t for t in ordem_tipos if t in df_grafico_sexo['Tipo de Entidade'].unique()]
                    
                    # Configurar o layout do gr√°fico
                    fig_sexo.update_layout(
                        title=dict(
                            text=f'üë´ Taxa (altura) e Profici√™ncia (cor) por Sexo<br><sub style="font-size:14px;">üü† Laranja = Profici√™ncia Baixa | üü° Amarelo = Profici√™ncia M√©dia | üü¢ Verde = Profici√™ncia Alta | Escala: {prof_min_sexo:.0f} - {prof_max_sexo:.0f}</sub>',
                            font=dict(size=18, family='Arial Black')
                        ),
                        xaxis_title=dict(
                            text='Tipo de Entidade',
                            font=dict(size=18)
                        ),
                        yaxis_title=dict(
                            text='Taxa (%)',
                            font=dict(size=18)
                        ),
                        font=dict(size=14),
                        height=450,
                        barmode='group',
                        bargap=0.2,
                        bargroupgap=0.15,
                        yaxis=dict(
                            range=[0, 110],
                            tickfont=dict(size=14)
                        ),
                        showlegend=False,
                        xaxis=dict(
                            categoryorder='array',
                            categoryarray=tipos_disponiveis_sexo,
                            tickfont=dict(size=14)
                        ),
                        hoverlabel=dict(
                            font_size=20,
                            font_family="Arial"
                        )
                    )
                    
                    # Exibir o gr√°fico
                    st.plotly_chart(fig_sexo, use_container_width=True)
                else:
                    st.info("N√£o foi poss√≠vel gerar o gr√°fico com os dados dispon√≠veis")
            else:
                st.info("Dados de taxa e profici√™ncia por sexo insuficientes para gerar o gr√°fico ou coluna de tipo de entidade n√£o dispon√≠vel")
            
            csv_sexo = df_sexo.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• Baixar Dados de Sexo",
                data=csv_sexo,
                file_name="proficiencia_sexo.csv",
                mime="text/csv",
                key="download_sexo"
            )
            
            # An√°lise com Groq
            with st.expander("ü§ñ An√°lise Inteligente - Profici√™ncia por Sexo", expanded=False):
                if st.session_state.get('documentos_carregados', False) and st.session_state.get('ia_ativa', True):
                    st.error("‚ö†Ô∏è **Lembrete:** Esta an√°lise √© gerada por intelig√™ncia artificial e pode conter erros ou imprecis√µes. **Esta funcionalidade est√° em fase de testes.** Use sempre seu julgamento profissional para validar as informa√ß√µes.")
                    
                    # Criar chave √∫nica baseada nos filtros atuais
                    etapa_filtro = st.session_state.get('etapa_selecionada', 'Todas')
                    disciplina_filtro = st.session_state.get('disciplina_selecionada', 'Todas')
                    key_analise = f"analise_sexo_{etapa_filtro}_{disciplina_filtro}"
                    
                    if st.button("üîç Analisar Dados com IA", key=key_analise):
                        with st.spinner("ü§ñ Analisando dados com IA..."):
                            analise = analisar_dataframe_com_groq(
                                df_sexo, 
                                "Profici√™ncia por Sexo", 
                            "An√°lise das diferen√ßas de profici√™ncia entre g√™neros nas avalia√ß√µes SPAECE",
                            st.session_state.agregado_consultado,
                            st.session_state.df_concatenado
                        )
                        st.markdown(analise)
                elif not st.session_state.get('documentos_carregados', False):
                    st.warning("‚ö†Ô∏è **An√°lise IA indispon√≠vel:** Carregue as bases de dados (DCRC e BNCC) para ativar as an√°lises inteligentes.")
                else:
                    st.warning("‚ö†Ô∏è **An√°lise IA desativada:** Use o bot√£o no painel lateral para ativar as an√°lises inteligentes.")
        else:
            st.info("Sem dados v√°lidos de profici√™ncia por sexo ap√≥s limpeza")
    else:
        st.info("Colunas de sexo n√£o encontradas no conjunto de dados")
    
    # ==================== RESUMO EXECUTIVO ====================
    st.markdown("""
    <div class="report-header" style="background: linear-gradient(135deg, #2ca02c, #1e7e34, #155724);">
        üìã RESUMO EXECUTIVO
    </div>
    """, unsafe_allow_html=True)
    
    # Resumo executivo do relat√≥rio
    st.markdown("""
    <div class="report-card">
        <div class="report-card-header">
            üìä INFORMA√á√ïES GERAIS DO RELAT√ìRIO
        </div>
        <div style="
            font-size: 0.95rem;
            line-height: 1.6;
            color: #374151;
        ">
            <p><strong>Data de Gera√ß√£o:</strong> {}</p>
            <p><strong>Agregado Consultado:</strong> {}</p>
            <p><strong>Total de Registros:</strong> {}</p>
            <p><strong>Per√≠odo de Dados:</strong> Sistema Permanente de Avalia√ß√£o da Educa√ß√£o B√°sica do Cear√° (SPAECE)</p>
            <p><strong>Escopo:</strong> An√°lise educacional com foco em profici√™ncia, participa√ß√£o e desempenho dos estudantes</p>
        </div>
    </div>
    """.format(
        pd.Timestamp.now().strftime("%d/%m/%Y √†s %H:%M"),
        st.session_state.agregado_consultado if st.session_state.agregado_consultado else "N/A",
        f"{len(st.session_state.df_concatenado):,}".replace(',', '.') if st.session_state.df_concatenado is not None else 0
    ), unsafe_allow_html=True)
    
    # Instru√ß√µes de impress√£o
    st.markdown("""
    <div class="report-card">
        <div class="report-card-header" style="border-bottom-color: #f59c00;">
            üñ®Ô∏è INSTRU√á√ïES PARA IMPRESS√ÉO
        </div>
        <div style="
            font-size: 0.9rem;
            line-height: 1.6;
            color: #374151;
        ">
            <p><strong>Para salvar como PDF:</strong></p>
            <ul>
                <li>Use Ctrl+P (Windows/Linux) ou Cmd+P (Mac)</li>
                <li>Selecione "Salvar como PDF" como destino</li>
                <li><strong>Configura√ß√µes recomendadas:</strong></li>
                <li style="margin-left: 1rem;">‚Ä¢ Orienta√ß√£o: Paisagem (Landscape)</li>
                <li style="margin-left: 1rem;">‚Ä¢ Margens: M√≠nimas (0.5in)</li>
                <li style="margin-left: 1rem;">‚Ä¢ Escala: 100%</li>
                <li style="margin-left: 1rem;">‚Ä¢ Gr√°ficos de fundo: Ativado</li>
                <li style="margin-left: 1rem;">‚Ä¢ Op√ß√µes: Marcar "Mais configura√ß√µes" e ativar "Gr√°ficos de fundo"</li>
            </ul>

       </div>
    </div>
    """, unsafe_allow_html=True)
    
    

    st.markdown("<div style='text-align: center;'>Relat√≥rio SPAECE - CREDE 1 - Maracana√∫</div>", unsafe_allow_html=True)
    st.markdown("<div style='text-align: center;'>Equipe Cecom 1</div>", unsafe_allow_html=True)
